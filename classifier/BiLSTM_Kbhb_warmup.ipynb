{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7833326a-55bf-41bc-a5ea-37026c7d0812",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 17:58:38.723376: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-12 17:58:38.955173: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-12 17:58:39.817196: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Conv1D, GlobalAvgPool2D, GlobalAveragePooling1D, \\\n",
    "    Dropout, Dense, Activation, Concatenate, Multiply, MaxPool2D, Add,  \\\n",
    "    LSTM, Bidirectional, Conv2D, AveragePooling2D, BatchNormalization, Flatten, GlobalAveragePooling2D, \\\n",
    "    GlobalMaxPooling2D, Reshape, Permute, multiply, Lambda, add, subtract, MaxPooling2D, GRU, ReLU, MaxPooling1D \n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from keras.models import Model, load_model\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.layers import Embedding\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from Bio import SeqIO\n",
    "mpl.use('TkAgg')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import math\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from keras import initializers\n",
    "from tensorflow.keras.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc3bb05c-d74a-47d3-99c6-ab7cb1e432fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 18:05:07.879188: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8178 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:65:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # 不全部占满显存，按需分配当allow_growth设置为True时，分配器将不会指定所有的GPU内存，而是根据需求增长\n",
    "session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1951f23b-5e17-407a-98e7-c46ac036e7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fasta(file_path):\n",
    "    '''File_path: Path to the fasta file\n",
    "       Returns: List of sequence\n",
    "    '''\n",
    "    one=list(SeqIO.parse(file_path,'fasta'))\n",
    "    return one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a8174f6-9953-4069-95ad-44c863d1ebff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def protein_to_Kmer(seqs,K):\n",
    "    numeric_sequences = []\n",
    "    base_to_index = {'A': 0, 'C': 1, 'D': 2, 'E': 3,\n",
    "                     'F': 4, 'G': 5, 'H': 6, 'I': 7, 'K': 8, 'L': 9, 'M': 10,\n",
    "                     'N': 11, 'P': 12, 'Q': 13, 'R': 14, 'S': 15, 'T': 16, \n",
    "                     'V': 17, 'W': 18, 'Y': 19,'X': 20\n",
    "                     }\n",
    "    for dna_sequence in seqs:\n",
    "        numeric_sequence = []\n",
    "        for base in dna_sequence:\n",
    "            numeric_sequence.append(base_to_index[base])\n",
    "\n",
    "        kmer_sequence = []\n",
    "        for i in range(len(numeric_sequence) - (K - 1)):\n",
    "            kmer = numeric_sequence[i:i + K]\n",
    "            kmer_marge = [int(\"\".join(map(str, kmer)))]\n",
    "            kmer_sequence.append(kmer_marge)\n",
    "\n",
    "        numeric_sequences.append(kmer_sequence)\n",
    "    return numeric_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "626b090c-1748-43e7-82ea-6ff8a6024197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the training set\n",
    "    \n",
    "train_pos_seqs = np.array(read_fasta('./data_Kbhb/train_15/Kbhb_pos_15_train.txt'))\n",
    "train_neg_seqs = np.array(read_fasta('./data_Kbhb/train_15/Kbhb_neg_15_train.txt'))\n",
    "\n",
    "train_seqs = np.concatenate( (train_pos_seqs, train_neg_seqs), axis=0 )\n",
    "\n",
    "train = np.array(protein_to_Kmer(train_seqs,1)).astype(np.float32)\n",
    "\n",
    "train_label = np.array( [1] * 2866 + [0] * 2866 ).astype( np.float32 )\n",
    "train_label = to_categorical( train_label, num_classes=2 )\n",
    "\n",
    "# Read the testing set\n",
    "test_pos_seqs = np.array(read_fasta('./data_Kbhb/train_15/Kbhb_pos_15_test.txt'))\n",
    "test_neg_seqs = np.array(read_fasta('./data_Kbhb/train_15/Kbhb_neg_15_test.txt'))\n",
    "\n",
    "test_seqs = np.concatenate((test_pos_seqs, test_neg_seqs), axis=0)\n",
    "\n",
    "test = np.array(protein_to_Kmer(test_seqs,1)).astype(np.float32)\n",
    "\n",
    "test_label = np.array([1] * 318 + [0] * 318).astype(np.float32)\n",
    "test_label = to_categorical(test_label, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e539bd0-b68d-4723-8299-85954f14115f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance evaluation\n",
    "def show_performance(y_true, y_pred):\n",
    "\n",
    "    TP, FP, FN, TN = 0, 0, 0, 0\n",
    "\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i] == 1:\n",
    "            if y_pred[i] > 0.5:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "        if y_true[i] == 0:\n",
    "            if y_pred[i] > 0.5:\n",
    "                FP += 1\n",
    "            else:\n",
    "                TN += 1\n",
    "\n",
    "\n",
    "    Sn = TP / (TP + FN + 1e-06)\n",
    "\n",
    "    Sp = TN / (FP + TN + 1e-06)\n",
    "\n",
    "    Acc = (TP + TN) / len(y_true)\n",
    "\n",
    "    MCC = ((TP * TN) - (FP * FN)) / np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN) + 1e-06)\n",
    "\n",
    "    return Sn, Sp, Acc, MCC\n",
    "\n",
    "def performance_mean(performance):\n",
    "    print('Sn = %.4f ± %.4f' % (np.mean(performance[:, 0]), np.std(performance[:, 0])))\n",
    "    print('Sp = %.4f ± %.4f' % (np.mean(performance[:, 1]), np.std(performance[:, 1])))\n",
    "    print('Acc = %.4f ± %.4f' % (np.mean(performance[:, 2]), np.std(performance[:, 2])))\n",
    "    print('Mcc = %.4f ± %.4f' % (np.mean(performance[:, 3]), np.std(performance[:, 3])))\n",
    "    print('Auc = %.4f ± %.4f' % (np.mean(performance[:, 4]), np.std(performance[:, 4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "757a7911-c1f9-421c-9d96-5feffd1b62ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#带有warmup的指数衰减学习率\n",
    "class WarmupExponentialDecay(Callback):\n",
    "    def __init__(self,lr_base=0.0002,lr_min=0.0,decay=0,warmup_epochs=0):\n",
    "        self.num_passed_batchs = 0   #一个计数器\n",
    "        self.warmup_epochs=warmup_epochs  \n",
    "        self.lr=lr_base #learning_rate_base\n",
    "        self.lr_min=lr_min #最小的起始学习率\n",
    "        self.decay=decay  #指数衰减率\n",
    "        self.steps_per_epoch=0 #也是一个计数器\n",
    "    def on_batch_begin(self, batch, logs=None):\n",
    "        # params是模型自动传递给Callback的一些参数\n",
    "        if self.steps_per_epoch==0:\n",
    "            #防止跑验证集的时候呗更改了\n",
    "            if self.params['steps'] == None:\n",
    "                self.steps_per_epoch = np.ceil(1. * self.params['samples'] / self.params['batch_size'])\n",
    "            else:\n",
    "                self.steps_per_epoch = self.params['steps']\n",
    "        if self.num_passed_batchs < self.steps_per_epoch * self.warmup_epochs:\n",
    "            K.set_value(self.model.optimizer.lr,\n",
    "                        self.lr*(self.num_passed_batchs + 1) / self.steps_per_epoch / self.warmup_epochs)\n",
    "        else:\n",
    "            K.set_value(self.model.optimizer.lr,\n",
    "                        self.lr*((1-self.decay)**(self.num_passed_batchs-self.steps_per_epoch*self.warmup_epochs)))\n",
    "        self.num_passed_batchs += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad9e67fa-5775-4bc8-a60a-6a638586b793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model\n",
    "def build_model(windows=15,embed_dim=64, weight_decay=1e-4,num_heads=8,ff_dim=64):\n",
    "\n",
    "    print('*' * 30 + 'Warmup+embedding_64' + '*' * 30)\n",
    "    input_1 = Input(shape=(windows,))\n",
    "    # Word embedding coding\n",
    "    embedding = Embedding(21, embed_dim, input_length=15)\n",
    "    x_1 = embedding(input_1)\n",
    "    print(x_1.shape)\n",
    "    #transformer = TransformerBlock(embed_dim, num_heads, ff_dim)(x_1)\n",
    "    #print(transformer.shape)\n",
    "\n",
    "    x_1 = Bidirectional(LSTM(32,return_sequences=True,\n",
    "                             kernel_regularizer = l2(0.0001), \n",
    "                             recurrent_regularizer = l2(0.0001),\n",
    "                             bias_regularizer = l2(0.0001)))(x_1)\n",
    "    x_1 = Dropout(0.1)(x_1)\n",
    "    x_1 = Bidirectional(LSTM(24,return_sequences=True,\n",
    "                             kernel_regularizer = l2(0.01), \n",
    "                             recurrent_regularizer = l2(0.01),\n",
    "                             bias_regularizer = l2(0.01)))(x_1)\n",
    "    x_1 = Dropout(0.2)(x_1)\n",
    "    print(x_1.shape)\n",
    "    \n",
    "\n",
    "    #x_1 = SE_Block(x_1,16)\n",
    "    #x_1 = eca_block(x_1)\n",
    "     \n",
    "    #print(x_1.shape)\n",
    "    \n",
    "    x_1 = MaxPooling1D(pool_size = 2)(x_1)\n",
    "    x = Flatten()(x_1)\n",
    "\n",
    "    x = Dropout(0.2)(x)\n",
    "\n",
    "    x = Dense(units=2, activation=\"softmax\")(x)\n",
    "\n",
    "\n",
    "    inputs = [input_1]\n",
    "    outputs = [x]\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs, name=\"Kbhb\")\n",
    "\n",
    "    #optimizer = Adam(learning_rate=1e-4, epsilon=1e-7)\n",
    "    optimizer = Adam()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c75499e2-5741-48f5-9947-109274479ad7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************Warmup+embedding_64******************************\n",
      "(None, 15, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 18:06:23.816046: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8178 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:65:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 15, 48)\n",
      "****************************** the 1 fold ******************************\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 18:06:30.362296: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8800\n",
      "Could not load symbol cublasGetSmCountTarget from libcublas.so.11. Error: /usr/local/cuda/targets/x86_64-linux/lib/libcublas.so.11: undefined symbol: cublasGetSmCountTarget\n",
      "2024-06-12 18:06:30.691944: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-06-12 18:06:30.704631: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f21940160f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-12 18:06:30.704659: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-06-12 18:06:30.722979: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-06-12 18:06:30.853098: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-12 18:06:30.856862: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:231] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.6\n",
      "2024-06-12 18:06:30.856907: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:234] Used ptxas at ptxas\n",
      "2024-06-12 18:06:30.889073: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-06-12 18:06:30.943785: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/162 [..............................] - ETA: 18:28 - loss: 3.2008 - accuracy: 0.5312"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 18:06:31.399521: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-12 18:06:31.418856: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-12 18:06:31.419461: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-12 18:06:31.484679: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-12 18:06:31.510707: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8/162 [>.............................] - ETA: 6s - loss: 3.2013 - accuracy: 0.5078"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 18:06:31.637556: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 19/162 [==>...........................] - ETA: 5s - loss: 3.2002 - accuracy: 0.5164"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 18:06:32.183671: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-12 18:06:32.351591: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 12s 34ms/step - loss: 3.1170 - accuracy: 0.5456 - val_loss: 2.9512 - val_accuracy: 0.6254\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 2.6694 - accuracy: 0.6115 - val_loss: 2.3282 - val_accuracy: 0.6620\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 2.0384 - accuracy: 0.6580 - val_loss: 1.8045 - val_accuracy: 0.6359\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 1.6202 - accuracy: 0.6630 - val_loss: 1.4742 - val_accuracy: 0.6533\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 1.3549 - accuracy: 0.6660 - val_loss: 1.2648 - val_accuracy: 0.6707\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 1.1847 - accuracy: 0.6702 - val_loss: 1.1323 - val_accuracy: 0.6620\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - ETA: 0s - loss: 1.0733 - accuracy: 0.6710"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 18:07:01.429854: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 4s 26ms/step - loss: 1.0733 - accuracy: 0.6710 - val_loss: 1.0357 - val_accuracy: 0.6864\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.9988 - accuracy: 0.6679 - val_loss: 0.9830 - val_accuracy: 0.6690\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.9464 - accuracy: 0.6722 - val_loss: 0.9348 - val_accuracy: 0.6707\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.9068 - accuracy: 0.6735 - val_loss: 0.9073 - val_accuracy: 0.6725\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.8763 - accuracy: 0.6718 - val_loss: 0.8750 - val_accuracy: 0.6899\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.8491 - accuracy: 0.6735 - val_loss: 0.8538 - val_accuracy: 0.6812\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.8255 - accuracy: 0.6817 - val_loss: 0.8305 - val_accuracy: 0.7003\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.8044 - accuracy: 0.6840 - val_loss: 0.8016 - val_accuracy: 0.6986\n",
      "Epoch 15/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.7831 - accuracy: 0.6805 - val_loss: 0.7839 - val_accuracy: 0.7125\n",
      "Epoch 16/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.7638 - accuracy: 0.6937 - val_loss: 0.7611 - val_accuracy: 0.7003\n",
      "Epoch 17/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.7465 - accuracy: 0.6931 - val_loss: 0.7531 - val_accuracy: 0.6899\n",
      "Epoch 18/200\n",
      "162/162 [==============================] - ETA: 0s - loss: 0.7279 - accuracy: 0.7007"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 18:07:46.966236: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 4s 26ms/step - loss: 0.7279 - accuracy: 0.7007 - val_loss: 0.7305 - val_accuracy: 0.7056\n",
      "Epoch 19/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.7121 - accuracy: 0.7059 - val_loss: 0.7175 - val_accuracy: 0.7091\n",
      "Epoch 20/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.6951 - accuracy: 0.7100 - val_loss: 0.7011 - val_accuracy: 0.7038\n",
      "Epoch 21/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.6794 - accuracy: 0.7150 - val_loss: 0.6913 - val_accuracy: 0.7108\n",
      "Epoch 22/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.6666 - accuracy: 0.7189 - val_loss: 0.6755 - val_accuracy: 0.7247\n",
      "Epoch 23/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.6527 - accuracy: 0.7243 - val_loss: 0.6748 - val_accuracy: 0.7160\n",
      "Epoch 24/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.6396 - accuracy: 0.7228 - val_loss: 0.6589 - val_accuracy: 0.7143\n",
      "Epoch 25/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.6283 - accuracy: 0.7292 - val_loss: 0.6429 - val_accuracy: 0.7230\n",
      "Epoch 26/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.6142 - accuracy: 0.7383 - val_loss: 0.6440 - val_accuracy: 0.7178\n",
      "Epoch 27/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.6074 - accuracy: 0.7369 - val_loss: 0.6438 - val_accuracy: 0.7073\n",
      "Epoch 28/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5972 - accuracy: 0.7394 - val_loss: 0.6254 - val_accuracy: 0.7125\n",
      "Epoch 29/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5875 - accuracy: 0.7410 - val_loss: 0.6123 - val_accuracy: 0.7282\n",
      "Epoch 30/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5821 - accuracy: 0.7489 - val_loss: 0.6027 - val_accuracy: 0.7230\n",
      "Epoch 31/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5745 - accuracy: 0.7472 - val_loss: 0.6080 - val_accuracy: 0.7195\n",
      "Epoch 32/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.5685 - accuracy: 0.7462 - val_loss: 0.6026 - val_accuracy: 0.7143\n",
      "Epoch 33/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.5613 - accuracy: 0.7476 - val_loss: 0.5938 - val_accuracy: 0.7195\n",
      "Epoch 34/200\n",
      "162/162 [==============================] - ETA: 0s - loss: 0.5579 - accuracy: 0.7437"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 18:08:52.947401: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 4s 26ms/step - loss: 0.5579 - accuracy: 0.7437 - val_loss: 0.5805 - val_accuracy: 0.7352\n",
      "Epoch 35/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5528 - accuracy: 0.7480 - val_loss: 0.5683 - val_accuracy: 0.7474\n",
      "Epoch 36/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5490 - accuracy: 0.7482 - val_loss: 0.5703 - val_accuracy: 0.7404\n",
      "Epoch 37/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5431 - accuracy: 0.7524 - val_loss: 0.5774 - val_accuracy: 0.7265\n",
      "Epoch 38/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5367 - accuracy: 0.7536 - val_loss: 0.5631 - val_accuracy: 0.7404\n",
      "Epoch 39/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5353 - accuracy: 0.7553 - val_loss: 0.5589 - val_accuracy: 0.7491\n",
      "Epoch 40/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5316 - accuracy: 0.7586 - val_loss: 0.5586 - val_accuracy: 0.7404\n",
      "Epoch 41/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5313 - accuracy: 0.7569 - val_loss: 0.5514 - val_accuracy: 0.7544\n",
      "Epoch 42/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5262 - accuracy: 0.7606 - val_loss: 0.5609 - val_accuracy: 0.7387\n",
      "Epoch 43/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.5242 - accuracy: 0.7613 - val_loss: 0.5617 - val_accuracy: 0.7404\n",
      "Epoch 44/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5242 - accuracy: 0.7594 - val_loss: 0.5563 - val_accuracy: 0.7352\n",
      "Epoch 45/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5225 - accuracy: 0.7617 - val_loss: 0.5536 - val_accuracy: 0.7456\n",
      "Epoch 46/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5184 - accuracy: 0.7639 - val_loss: 0.5606 - val_accuracy: 0.7334\n",
      "Epoch 47/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5191 - accuracy: 0.7623 - val_loss: 0.5549 - val_accuracy: 0.7544\n",
      "Epoch 48/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5176 - accuracy: 0.7646 - val_loss: 0.5438 - val_accuracy: 0.7526\n",
      "Epoch 49/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5127 - accuracy: 0.7662 - val_loss: 0.5556 - val_accuracy: 0.7387\n",
      "Epoch 50/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5151 - accuracy: 0.7650 - val_loss: 0.5478 - val_accuracy: 0.7509\n",
      "Epoch 51/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.5144 - accuracy: 0.7654 - val_loss: 0.5509 - val_accuracy: 0.7404\n",
      "Epoch 52/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5122 - accuracy: 0.7654 - val_loss: 0.5432 - val_accuracy: 0.7544\n",
      "Epoch 53/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5120 - accuracy: 0.7652 - val_loss: 0.5429 - val_accuracy: 0.7509\n",
      "Epoch 54/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5097 - accuracy: 0.7701 - val_loss: 0.5600 - val_accuracy: 0.7265\n",
      "Epoch 55/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5087 - accuracy: 0.7685 - val_loss: 0.5623 - val_accuracy: 0.7265\n",
      "Epoch 56/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5091 - accuracy: 0.7670 - val_loss: 0.5520 - val_accuracy: 0.7282\n",
      "Epoch 57/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5090 - accuracy: 0.7658 - val_loss: 0.5437 - val_accuracy: 0.7456\n",
      "Epoch 58/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5049 - accuracy: 0.7705 - val_loss: 0.5602 - val_accuracy: 0.7230\n",
      "Epoch 59/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.5078 - accuracy: 0.7695 - val_loss: 0.5463 - val_accuracy: 0.7439\n",
      "Epoch 60/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5041 - accuracy: 0.7736 - val_loss: 0.5514 - val_accuracy: 0.7404\n",
      "Epoch 61/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5048 - accuracy: 0.7720 - val_loss: 0.5551 - val_accuracy: 0.7265\n",
      "Epoch 62/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5065 - accuracy: 0.7685 - val_loss: 0.5422 - val_accuracy: 0.7422\n",
      "Epoch 63/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5017 - accuracy: 0.7734 - val_loss: 0.5488 - val_accuracy: 0.7387\n",
      "Epoch 64/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5028 - accuracy: 0.7708 - val_loss: 0.5469 - val_accuracy: 0.7334\n",
      "Epoch 65/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5026 - accuracy: 0.7743 - val_loss: 0.5393 - val_accuracy: 0.7422\n",
      "Epoch 66/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.5013 - accuracy: 0.7722 - val_loss: 0.5486 - val_accuracy: 0.7352\n",
      "Epoch 67/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5013 - accuracy: 0.7691 - val_loss: 0.5557 - val_accuracy: 0.7230\n",
      "Epoch 68/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4986 - accuracy: 0.7767 - val_loss: 0.5470 - val_accuracy: 0.7352\n",
      "Epoch 69/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5017 - accuracy: 0.7714 - val_loss: 0.5453 - val_accuracy: 0.7352\n",
      "Epoch 70/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4995 - accuracy: 0.7743 - val_loss: 0.5461 - val_accuracy: 0.7404\n",
      "Epoch 71/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5003 - accuracy: 0.7757 - val_loss: 0.5424 - val_accuracy: 0.7422\n",
      "Epoch 72/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4998 - accuracy: 0.7701 - val_loss: 0.5346 - val_accuracy: 0.7561\n",
      "Epoch 73/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4974 - accuracy: 0.7724 - val_loss: 0.5386 - val_accuracy: 0.7387\n",
      "Epoch 74/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4969 - accuracy: 0.7761 - val_loss: 0.5493 - val_accuracy: 0.7230\n",
      "Epoch 75/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4981 - accuracy: 0.7743 - val_loss: 0.5542 - val_accuracy: 0.7178\n",
      "Epoch 76/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4953 - accuracy: 0.7780 - val_loss: 0.5420 - val_accuracy: 0.7369\n",
      "Epoch 77/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4964 - accuracy: 0.7769 - val_loss: 0.5501 - val_accuracy: 0.7247\n",
      "Epoch 78/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4961 - accuracy: 0.7751 - val_loss: 0.5346 - val_accuracy: 0.7491\n",
      "Epoch 79/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4961 - accuracy: 0.7767 - val_loss: 0.5405 - val_accuracy: 0.7369\n",
      "Epoch 80/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4915 - accuracy: 0.7790 - val_loss: 0.5375 - val_accuracy: 0.7439\n",
      "Epoch 81/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4934 - accuracy: 0.7819 - val_loss: 0.5346 - val_accuracy: 0.7439\n",
      "Epoch 82/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4934 - accuracy: 0.7757 - val_loss: 0.5466 - val_accuracy: 0.7317\n",
      "Epoch 83/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4906 - accuracy: 0.7792 - val_loss: 0.5322 - val_accuracy: 0.7509\n",
      "Epoch 84/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4921 - accuracy: 0.7782 - val_loss: 0.5480 - val_accuracy: 0.7282\n",
      "Epoch 85/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4884 - accuracy: 0.7809 - val_loss: 0.5342 - val_accuracy: 0.7526\n",
      "Epoch 86/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4914 - accuracy: 0.7836 - val_loss: 0.5292 - val_accuracy: 0.7509\n",
      "Epoch 87/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4881 - accuracy: 0.7784 - val_loss: 0.5321 - val_accuracy: 0.7456\n",
      "Epoch 88/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4889 - accuracy: 0.7788 - val_loss: 0.5393 - val_accuracy: 0.7404\n",
      "Epoch 89/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4871 - accuracy: 0.7825 - val_loss: 0.5466 - val_accuracy: 0.7317\n",
      "Epoch 90/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4882 - accuracy: 0.7829 - val_loss: 0.5332 - val_accuracy: 0.7439\n",
      "Epoch 91/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4875 - accuracy: 0.7829 - val_loss: 0.5499 - val_accuracy: 0.7247\n",
      "Epoch 92/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4865 - accuracy: 0.7819 - val_loss: 0.5356 - val_accuracy: 0.7404\n",
      "Epoch 93/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4869 - accuracy: 0.7796 - val_loss: 0.5404 - val_accuracy: 0.7387\n",
      "Epoch 94/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4841 - accuracy: 0.7809 - val_loss: 0.5264 - val_accuracy: 0.7544\n",
      "Epoch 95/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4878 - accuracy: 0.7811 - val_loss: 0.5278 - val_accuracy: 0.7422\n",
      "Epoch 96/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4862 - accuracy: 0.7815 - val_loss: 0.5248 - val_accuracy: 0.7474\n",
      "Epoch 97/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4842 - accuracy: 0.7838 - val_loss: 0.5415 - val_accuracy: 0.7369\n",
      "Epoch 98/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4824 - accuracy: 0.7807 - val_loss: 0.5238 - val_accuracy: 0.7474\n",
      "Epoch 99/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4824 - accuracy: 0.7838 - val_loss: 0.5468 - val_accuracy: 0.7334\n",
      "Epoch 100/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4837 - accuracy: 0.7825 - val_loss: 0.5352 - val_accuracy: 0.7369\n",
      "Epoch 101/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4823 - accuracy: 0.7831 - val_loss: 0.5236 - val_accuracy: 0.7456\n",
      "Epoch 102/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4827 - accuracy: 0.7858 - val_loss: 0.5341 - val_accuracy: 0.7352\n",
      "Epoch 103/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4796 - accuracy: 0.7865 - val_loss: 0.5388 - val_accuracy: 0.7300\n",
      "Epoch 104/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4825 - accuracy: 0.7831 - val_loss: 0.5373 - val_accuracy: 0.7422\n",
      "Epoch 105/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4795 - accuracy: 0.7840 - val_loss: 0.5333 - val_accuracy: 0.7387\n",
      "Epoch 106/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4822 - accuracy: 0.7850 - val_loss: 0.5278 - val_accuracy: 0.7439\n",
      "Epoch 107/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4808 - accuracy: 0.7842 - val_loss: 0.5278 - val_accuracy: 0.7369\n",
      "Epoch 108/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4791 - accuracy: 0.7844 - val_loss: 0.5288 - val_accuracy: 0.7474\n",
      "Epoch 109/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4787 - accuracy: 0.7836 - val_loss: 0.5226 - val_accuracy: 0.7509\n",
      "Epoch 110/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4794 - accuracy: 0.7840 - val_loss: 0.5392 - val_accuracy: 0.7334\n",
      "Epoch 111/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4757 - accuracy: 0.7896 - val_loss: 0.5229 - val_accuracy: 0.7474\n",
      "Epoch 112/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4775 - accuracy: 0.7854 - val_loss: 0.5210 - val_accuracy: 0.7526\n",
      "Epoch 113/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4741 - accuracy: 0.7862 - val_loss: 0.5367 - val_accuracy: 0.7369\n",
      "Epoch 114/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4775 - accuracy: 0.7852 - val_loss: 0.5175 - val_accuracy: 0.7509\n",
      "Epoch 115/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4754 - accuracy: 0.7840 - val_loss: 0.5429 - val_accuracy: 0.7369\n",
      "Epoch 116/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4755 - accuracy: 0.7838 - val_loss: 0.5252 - val_accuracy: 0.7404\n",
      "Epoch 117/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4750 - accuracy: 0.7885 - val_loss: 0.5186 - val_accuracy: 0.7491\n",
      "Epoch 118/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4764 - accuracy: 0.7846 - val_loss: 0.5414 - val_accuracy: 0.7334\n",
      "Epoch 119/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4755 - accuracy: 0.7883 - val_loss: 0.5265 - val_accuracy: 0.7474\n",
      "Epoch 120/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4727 - accuracy: 0.7937 - val_loss: 0.5427 - val_accuracy: 0.7334\n",
      "Epoch 121/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4738 - accuracy: 0.7893 - val_loss: 0.5355 - val_accuracy: 0.7369\n",
      "Epoch 122/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4764 - accuracy: 0.7852 - val_loss: 0.5204 - val_accuracy: 0.7561\n",
      "Epoch 123/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4734 - accuracy: 0.7887 - val_loss: 0.5353 - val_accuracy: 0.7334\n",
      "Epoch 124/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4749 - accuracy: 0.7871 - val_loss: 0.5201 - val_accuracy: 0.7544\n",
      "Epoch 125/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4731 - accuracy: 0.7862 - val_loss: 0.5443 - val_accuracy: 0.7369\n",
      "Epoch 126/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4740 - accuracy: 0.7898 - val_loss: 0.5390 - val_accuracy: 0.7369\n",
      "Epoch 127/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4722 - accuracy: 0.7908 - val_loss: 0.5408 - val_accuracy: 0.7369\n",
      "18/18 [==============================] - 1s 8ms/step\n",
      "Sn = 0.702875, Sp = 0.777778, Acc = 0.736934, MCC = 0.478912, AUC = 0.833548\n",
      "****************************** the 2 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 8s 33ms/step - loss: 0.4764 - accuracy: 0.7838 - val_loss: 0.4840 - val_accuracy: 0.7909\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4762 - accuracy: 0.7817 - val_loss: 0.4868 - val_accuracy: 0.7857\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4784 - accuracy: 0.7854 - val_loss: 0.4926 - val_accuracy: 0.7805\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4782 - accuracy: 0.7865 - val_loss: 0.4957 - val_accuracy: 0.7648\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4783 - accuracy: 0.7821 - val_loss: 0.4916 - val_accuracy: 0.7787\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4776 - accuracy: 0.7865 - val_loss: 0.5004 - val_accuracy: 0.7718\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4752 - accuracy: 0.7858 - val_loss: 0.4960 - val_accuracy: 0.7683\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4752 - accuracy: 0.7854 - val_loss: 0.4947 - val_accuracy: 0.7718\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4732 - accuracy: 0.7831 - val_loss: 0.4983 - val_accuracy: 0.7648\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4776 - accuracy: 0.7832 - val_loss: 0.5022 - val_accuracy: 0.7753\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4746 - accuracy: 0.7865 - val_loss: 0.5076 - val_accuracy: 0.7648\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4735 - accuracy: 0.7877 - val_loss: 0.4981 - val_accuracy: 0.7718\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4733 - accuracy: 0.7858 - val_loss: 0.5139 - val_accuracy: 0.7509\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4726 - accuracy: 0.7842 - val_loss: 0.5091 - val_accuracy: 0.7700\n",
      "18/18 [==============================] - 1s 8ms/step\n",
      "Sn = 0.747368, Sp = 0.792388, Acc = 0.770035, MCC = 0.540386, AUC = 0.847824\n",
      "****************************** the 3 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 8s 34ms/step - loss: 0.4712 - accuracy: 0.7901 - val_loss: 0.4735 - val_accuracy: 0.7749\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4701 - accuracy: 0.7914 - val_loss: 0.4768 - val_accuracy: 0.7801\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4724 - accuracy: 0.7874 - val_loss: 0.4813 - val_accuracy: 0.7644\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4756 - accuracy: 0.7864 - val_loss: 0.4799 - val_accuracy: 0.7679\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4713 - accuracy: 0.7930 - val_loss: 0.4939 - val_accuracy: 0.7644\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4744 - accuracy: 0.7907 - val_loss: 0.4916 - val_accuracy: 0.7644\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4705 - accuracy: 0.7910 - val_loss: 0.4894 - val_accuracy: 0.7661\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4714 - accuracy: 0.7912 - val_loss: 0.4959 - val_accuracy: 0.7644\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4732 - accuracy: 0.7858 - val_loss: 0.4883 - val_accuracy: 0.7627\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4717 - accuracy: 0.7883 - val_loss: 0.4898 - val_accuracy: 0.7696\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4692 - accuracy: 0.7922 - val_loss: 0.4882 - val_accuracy: 0.7661\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4677 - accuracy: 0.7885 - val_loss: 0.5009 - val_accuracy: 0.7592\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4700 - accuracy: 0.7947 - val_loss: 0.4915 - val_accuracy: 0.7627\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4693 - accuracy: 0.7924 - val_loss: 0.4997 - val_accuracy: 0.7592\n",
      "18/18 [==============================] - 1s 9ms/step\n",
      "Sn = 0.819113, Sp = 0.696429, Acc = 0.759162, MCC = 0.520126, AUC = 0.850463\n",
      "****************************** the 4 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 8s 33ms/step - loss: 0.4704 - accuracy: 0.7845 - val_loss: 0.4372 - val_accuracy: 0.8202\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4752 - accuracy: 0.7837 - val_loss: 0.4421 - val_accuracy: 0.8255\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4749 - accuracy: 0.7846 - val_loss: 0.4470 - val_accuracy: 0.8168\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4742 - accuracy: 0.7856 - val_loss: 0.4510 - val_accuracy: 0.8202\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4720 - accuracy: 0.7852 - val_loss: 0.4558 - val_accuracy: 0.8150\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4731 - accuracy: 0.7802 - val_loss: 0.4571 - val_accuracy: 0.8150\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4705 - accuracy: 0.7883 - val_loss: 0.4514 - val_accuracy: 0.8168\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4716 - accuracy: 0.7883 - val_loss: 0.4573 - val_accuracy: 0.8237\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4699 - accuracy: 0.7877 - val_loss: 0.4532 - val_accuracy: 0.8133\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4684 - accuracy: 0.7860 - val_loss: 0.4544 - val_accuracy: 0.8080\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4698 - accuracy: 0.7885 - val_loss: 0.4575 - val_accuracy: 0.8185\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4698 - accuracy: 0.7864 - val_loss: 0.4620 - val_accuracy: 0.8080\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4694 - accuracy: 0.7887 - val_loss: 0.4544 - val_accuracy: 0.8168\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4696 - accuracy: 0.7912 - val_loss: 0.4568 - val_accuracy: 0.8115\n",
      "18/18 [==============================] - 1s 8ms/step\n",
      "Sn = 0.807692, Sp = 0.815331, Acc = 0.811518, MCC = 0.623046, AUC = 0.879998\n",
      "****************************** the 5 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 8s 32ms/step - loss: 0.4616 - accuracy: 0.7965 - val_loss: 0.4496 - val_accuracy: 0.8098\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4668 - accuracy: 0.7971 - val_loss: 0.4573 - val_accuracy: 0.7976\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4676 - accuracy: 0.7870 - val_loss: 0.4635 - val_accuracy: 0.7906\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4672 - accuracy: 0.7889 - val_loss: 0.4672 - val_accuracy: 0.7923\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4671 - accuracy: 0.7951 - val_loss: 0.4621 - val_accuracy: 0.7976\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4664 - accuracy: 0.7926 - val_loss: 0.4652 - val_accuracy: 0.7993\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4644 - accuracy: 0.7909 - val_loss: 0.4715 - val_accuracy: 0.7784\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4657 - accuracy: 0.7907 - val_loss: 0.4656 - val_accuracy: 0.7906\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4645 - accuracy: 0.7928 - val_loss: 0.4654 - val_accuracy: 0.7871\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4652 - accuracy: 0.7969 - val_loss: 0.4695 - val_accuracy: 0.7801\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4641 - accuracy: 0.7920 - val_loss: 0.4743 - val_accuracy: 0.7906\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4627 - accuracy: 0.7965 - val_loss: 0.4698 - val_accuracy: 0.7888\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4638 - accuracy: 0.7943 - val_loss: 0.4750 - val_accuracy: 0.7801\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4630 - accuracy: 0.7949 - val_loss: 0.4768 - val_accuracy: 0.7801\n",
      "18/18 [==============================] - 1s 8ms/step\n",
      "Sn = 0.859155, Sp = 0.702422, Acc = 0.780105, MCC = 0.568143, AUC = 0.870449\n",
      "****************************** the 6 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 9s 33ms/step - loss: 0.4579 - accuracy: 0.7976 - val_loss: 0.4446 - val_accuracy: 0.8028\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4627 - accuracy: 0.7961 - val_loss: 0.4450 - val_accuracy: 0.8063\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4652 - accuracy: 0.7938 - val_loss: 0.4516 - val_accuracy: 0.8045\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4657 - accuracy: 0.7930 - val_loss: 0.4569 - val_accuracy: 0.7976\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4624 - accuracy: 0.7965 - val_loss: 0.4561 - val_accuracy: 0.8045\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4625 - accuracy: 0.7943 - val_loss: 0.4524 - val_accuracy: 0.8045\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4596 - accuracy: 0.7988 - val_loss: 0.4560 - val_accuracy: 0.8010\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4609 - accuracy: 0.7951 - val_loss: 0.4585 - val_accuracy: 0.7906\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4619 - accuracy: 0.7930 - val_loss: 0.4599 - val_accuracy: 0.7906\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4595 - accuracy: 0.7959 - val_loss: 0.4588 - val_accuracy: 0.8080\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4626 - accuracy: 0.7918 - val_loss: 0.4626 - val_accuracy: 0.8010\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4592 - accuracy: 0.7984 - val_loss: 0.4579 - val_accuracy: 0.7993\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4627 - accuracy: 0.7947 - val_loss: 0.4656 - val_accuracy: 0.7923\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4604 - accuracy: 0.7994 - val_loss: 0.4665 - val_accuracy: 0.7871\n",
      "18/18 [==============================] - 1s 8ms/step\n",
      "Sn = 0.860627, Sp = 0.713287, Acc = 0.787086, MCC = 0.580334, AUC = 0.875710\n",
      "****************************** the 7 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 8s 33ms/step - loss: 0.4570 - accuracy: 0.7969 - val_loss: 0.4358 - val_accuracy: 0.8028\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4596 - accuracy: 0.7982 - val_loss: 0.4443 - val_accuracy: 0.8063\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4606 - accuracy: 0.8005 - val_loss: 0.4421 - val_accuracy: 0.8010\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4605 - accuracy: 0.7971 - val_loss: 0.4576 - val_accuracy: 0.7818\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4595 - accuracy: 0.7986 - val_loss: 0.4510 - val_accuracy: 0.7958\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4597 - accuracy: 0.7984 - val_loss: 0.4570 - val_accuracy: 0.8028\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4569 - accuracy: 0.8031 - val_loss: 0.4523 - val_accuracy: 0.7958\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4570 - accuracy: 0.8027 - val_loss: 0.4511 - val_accuracy: 0.7976\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4577 - accuracy: 0.7965 - val_loss: 0.4543 - val_accuracy: 0.7941\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4560 - accuracy: 0.7976 - val_loss: 0.4595 - val_accuracy: 0.7993\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4566 - accuracy: 0.8000 - val_loss: 0.4604 - val_accuracy: 0.7888\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4585 - accuracy: 0.7967 - val_loss: 0.4572 - val_accuracy: 0.7906\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4552 - accuracy: 0.8048 - val_loss: 0.4647 - val_accuracy: 0.7801\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4527 - accuracy: 0.8035 - val_loss: 0.4632 - val_accuracy: 0.7906\n",
      "18/18 [==============================] - 1s 7ms/step\n",
      "Sn = 0.860215, Sp = 0.724490, Acc = 0.790576, MCC = 0.588789, AUC = 0.871772\n",
      "****************************** the 8 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 8s 36ms/step - loss: 0.4483 - accuracy: 0.8002 - val_loss: 0.4452 - val_accuracy: 0.8202\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4505 - accuracy: 0.8058 - val_loss: 0.4499 - val_accuracy: 0.8098\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4522 - accuracy: 0.8033 - val_loss: 0.4600 - val_accuracy: 0.8237\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4540 - accuracy: 0.8009 - val_loss: 0.4550 - val_accuracy: 0.8063\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4521 - accuracy: 0.8042 - val_loss: 0.4674 - val_accuracy: 0.7958\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4557 - accuracy: 0.7982 - val_loss: 0.4762 - val_accuracy: 0.8063\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4522 - accuracy: 0.7994 - val_loss: 0.4595 - val_accuracy: 0.8063\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4523 - accuracy: 0.7974 - val_loss: 0.4645 - val_accuracy: 0.8063\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4544 - accuracy: 0.7984 - val_loss: 0.4642 - val_accuracy: 0.8115\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4480 - accuracy: 0.8021 - val_loss: 0.4700 - val_accuracy: 0.7958\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4495 - accuracy: 0.8021 - val_loss: 0.4667 - val_accuracy: 0.8010\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4498 - accuracy: 0.8005 - val_loss: 0.4808 - val_accuracy: 0.7749\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4489 - accuracy: 0.8058 - val_loss: 0.4721 - val_accuracy: 0.7976\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4486 - accuracy: 0.8038 - val_loss: 0.4797 - val_accuracy: 0.7993\n",
      "18/18 [==============================] - 1s 8ms/step\n",
      "Sn = 0.881356, Sp = 0.712230, Acc = 0.799302, MCC = 0.603948, AUC = 0.868309\n",
      "****************************** the 9 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 8s 33ms/step - loss: 0.4454 - accuracy: 0.8093 - val_loss: 0.4358 - val_accuracy: 0.8342\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4499 - accuracy: 0.7974 - val_loss: 0.4395 - val_accuracy: 0.8202\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4497 - accuracy: 0.8052 - val_loss: 0.4445 - val_accuracy: 0.8220\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4485 - accuracy: 0.8013 - val_loss: 0.4483 - val_accuracy: 0.8290\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4477 - accuracy: 0.8029 - val_loss: 0.4532 - val_accuracy: 0.8185\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4494 - accuracy: 0.7976 - val_loss: 0.4484 - val_accuracy: 0.8168\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4459 - accuracy: 0.8046 - val_loss: 0.4617 - val_accuracy: 0.8063\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4469 - accuracy: 0.8033 - val_loss: 0.4537 - val_accuracy: 0.8150\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4471 - accuracy: 0.8056 - val_loss: 0.4549 - val_accuracy: 0.8168\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4454 - accuracy: 0.8056 - val_loss: 0.4599 - val_accuracy: 0.8098\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4444 - accuracy: 0.8040 - val_loss: 0.4542 - val_accuracy: 0.8150\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4422 - accuracy: 0.8071 - val_loss: 0.4569 - val_accuracy: 0.8133\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4448 - accuracy: 0.8141 - val_loss: 0.4573 - val_accuracy: 0.8028\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4429 - accuracy: 0.8060 - val_loss: 0.4742 - val_accuracy: 0.8168\n",
      "18/18 [==============================] - 1s 8ms/step\n",
      "Sn = 0.916667, Sp = 0.723906, Acc = 0.816754, MCC = 0.649516, AUC = 0.877629\n",
      "****************************** the 10 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 8s 32ms/step - loss: 0.4371 - accuracy: 0.8147 - val_loss: 0.4364 - val_accuracy: 0.8010\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4405 - accuracy: 0.8120 - val_loss: 0.4457 - val_accuracy: 0.8045\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4452 - accuracy: 0.8067 - val_loss: 0.4515 - val_accuracy: 0.7958\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4407 - accuracy: 0.8091 - val_loss: 0.4503 - val_accuracy: 0.7923\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4428 - accuracy: 0.8058 - val_loss: 0.4507 - val_accuracy: 0.7993\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4426 - accuracy: 0.8069 - val_loss: 0.4679 - val_accuracy: 0.7836\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4387 - accuracy: 0.8129 - val_loss: 0.4672 - val_accuracy: 0.7784\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4406 - accuracy: 0.8093 - val_loss: 0.4612 - val_accuracy: 0.7871\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4405 - accuracy: 0.8097 - val_loss: 0.4599 - val_accuracy: 0.7871\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4399 - accuracy: 0.8137 - val_loss: 0.4676 - val_accuracy: 0.7871\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4384 - accuracy: 0.8093 - val_loss: 0.4609 - val_accuracy: 0.7888\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4401 - accuracy: 0.8071 - val_loss: 0.4577 - val_accuracy: 0.7941\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4379 - accuracy: 0.8073 - val_loss: 0.4588 - val_accuracy: 0.7923\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.4351 - accuracy: 0.8133 - val_loss: 0.4753 - val_accuracy: 0.7836\n",
      "18/18 [==============================] - 1s 8ms/step\n",
      "Sn = 0.858209, Sp = 0.718033, Acc = 0.783595, MCC = 0.578112, AUC = 0.873917\n",
      "10 fold result: [[0.7028754  0.77777777 0.7369338  0.47891229 0.83354755]\n",
      " [0.74736842 0.79238754 0.77003484 0.54038618 0.84782371]\n",
      " [0.81911263 0.69642857 0.7591623  0.52012614 0.85046319]\n",
      " [0.8076923  0.81533101 0.81151832 0.62304609 0.87999805]\n",
      " [0.85915493 0.70242214 0.78010471 0.5681426  0.87044934]\n",
      " [0.86062717 0.71328671 0.78708551 0.58033376 0.87570966]\n",
      " [0.86021505 0.72448979 0.79057592 0.58878898 0.87177236]\n",
      " [0.88135593 0.71223021 0.79930192 0.60394827 0.86830874]\n",
      " [0.91666666 0.72390572 0.81675393 0.64951637 0.87762895]\n",
      " [0.85820895 0.71803278 0.78359511 0.57811193 0.8739173 ]]\n",
      "Sn = 0.8313 ± 0.0610\n",
      "Sp = 0.7376 ± 0.0395\n",
      "Acc = 0.7835 ± 0.0227\n",
      "Mcc = 0.5731 ± 0.0473\n",
      "Auc = 0.8650 ± 0.0147\n",
      "Epoch 1/200\n",
      "180/180 [==============================] - 9s 31ms/step - loss: 0.4399 - accuracy: 0.8105 - val_loss: 0.4763 - val_accuracy: 0.7987\n",
      "Epoch 2/200\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.4369 - accuracy: 0.8133"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 18:25:06.163919: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 4s 24ms/step - loss: 0.4369 - accuracy: 0.8133 - val_loss: 0.4618 - val_accuracy: 0.8145\n",
      "Epoch 3/200\n",
      "180/180 [==============================] - 4s 25ms/step - loss: 0.4413 - accuracy: 0.8107 - val_loss: 0.4603 - val_accuracy: 0.8145\n",
      "Epoch 4/200\n",
      "180/180 [==============================] - 4s 24ms/step - loss: 0.4387 - accuracy: 0.8125 - val_loss: 0.4761 - val_accuracy: 0.8035\n",
      "Epoch 5/200\n",
      "180/180 [==============================] - 4s 24ms/step - loss: 0.4369 - accuracy: 0.8144 - val_loss: 0.4589 - val_accuracy: 0.8176\n",
      "Epoch 6/200\n",
      "180/180 [==============================] - 4s 24ms/step - loss: 0.4385 - accuracy: 0.8098 - val_loss: 0.4640 - val_accuracy: 0.8113\n",
      "Epoch 7/200\n",
      "180/180 [==============================] - 4s 24ms/step - loss: 0.4330 - accuracy: 0.8139 - val_loss: 0.4647 - val_accuracy: 0.8050\n",
      "Epoch 8/200\n",
      "180/180 [==============================] - 4s 24ms/step - loss: 0.4377 - accuracy: 0.8137 - val_loss: 0.4742 - val_accuracy: 0.8003\n",
      "Epoch 9/200\n",
      "180/180 [==============================] - 4s 24ms/step - loss: 0.4352 - accuracy: 0.8142 - val_loss: 0.4720 - val_accuracy: 0.7972\n",
      "Epoch 10/200\n",
      "180/180 [==============================] - 4s 24ms/step - loss: 0.4334 - accuracy: 0.8152 - val_loss: 0.4672 - val_accuracy: 0.8145\n",
      "Epoch 11/200\n",
      "180/180 [==============================] - 4s 24ms/step - loss: 0.4345 - accuracy: 0.8119 - val_loss: 0.4621 - val_accuracy: 0.8129\n",
      "Epoch 12/200\n",
      "180/180 [==============================] - 4s 24ms/step - loss: 0.4353 - accuracy: 0.8163 - val_loss: 0.4645 - val_accuracy: 0.8113\n",
      "Epoch 13/200\n",
      "180/180 [==============================] - 4s 24ms/step - loss: 0.4321 - accuracy: 0.8140 - val_loss: 0.4623 - val_accuracy: 0.8176\n",
      "Epoch 14/200\n",
      "180/180 [==============================] - 4s 24ms/step - loss: 0.4352 - accuracy: 0.8158 - val_loss: 0.4707 - val_accuracy: 0.8066\n",
      "Epoch 15/200\n",
      "180/180 [==============================] - 4s 24ms/step - loss: 0.4351 - accuracy: 0.8147 - val_loss: 0.4640 - val_accuracy: 0.8097\n",
      "Epoch 16/200\n",
      "180/180 [==============================] - 4s 24ms/step - loss: 0.4321 - accuracy: 0.8132 - val_loss: 0.4720 - val_accuracy: 0.8145\n",
      "Epoch 17/200\n",
      "180/180 [==============================] - 4s 24ms/step - loss: 0.4335 - accuracy: 0.8151 - val_loss: 0.4677 - val_accuracy: 0.8066\n",
      "Epoch 18/200\n",
      "180/180 [==============================] - 4s 24ms/step - loss: 0.4317 - accuracy: 0.8201 - val_loss: 0.4690 - val_accuracy: 0.8097\n",
      "Epoch 19/200\n",
      "180/180 [==============================] - 4s 24ms/step - loss: 0.4280 - accuracy: 0.8175 - val_loss: 0.4670 - val_accuracy: 0.8176\n",
      "Epoch 20/200\n",
      "180/180 [==============================] - 4s 24ms/step - loss: 0.4328 - accuracy: 0.8186 - val_loss: 0.4771 - val_accuracy: 0.7987\n",
      "Epoch 21/200\n",
      "180/180 [==============================] - 4s 24ms/step - loss: 0.4307 - accuracy: 0.8191 - val_loss: 0.4695 - val_accuracy: 0.8097\n",
      "Epoch 22/200\n",
      "180/180 [==============================] - 4s 24ms/step - loss: 0.4286 - accuracy: 0.8184 - val_loss: 0.4632 - val_accuracy: 0.8129\n",
      "Epoch 23/200\n",
      "180/180 [==============================] - 4s 24ms/step - loss: 0.4297 - accuracy: 0.8215 - val_loss: 0.4741 - val_accuracy: 0.8113\n",
      "Epoch 24/200\n",
      "180/180 [==============================] - 4s 23ms/step - loss: 0.4300 - accuracy: 0.8170 - val_loss: 0.4629 - val_accuracy: 0.8176\n",
      "Epoch 25/200\n",
      "180/180 [==============================] - 4s 24ms/step - loss: 0.4271 - accuracy: 0.8182 - val_loss: 0.4864 - val_accuracy: 0.7972\n",
      "20/20 [==============================] - 1s 8ms/step\n",
      "-----------------------------------------------test---------------------------------------\n",
      "Sn = 0.798742, Sp = 0.795597, Acc = 0.797170, MCC = 0.594343, AUC = 0.869190\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "tf.random.set_seed(1)  # for reproducibility\n",
    "# reading model\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 200\n",
    "\n",
    "# # Cross-validation\n",
    "n = 10\n",
    "k_fold = KFold(n_splits=n, shuffle=True, random_state=42)\n",
    "\n",
    "all_performance = []\n",
    "tprs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "for fold_count, (train_index, val_index) in enumerate(k_fold.split(train)):\n",
    "    print('*' * 30 + ' the ' + str(fold_count + 1) + ' fold ' + '*' * 30)\n",
    "    trains, val = train[train_index], train[val_index]\n",
    "    trains_label, val_label = train_label[train_index], train_label[val_index]\n",
    "    zaoting = EarlyStopping(monitor='val_loss', patience=13, mode='auto')\n",
    "    xuexilv = WarmupExponentialDecay(lr_base=0.0002,decay=0.00002,warmup_epochs=2)\n",
    "    callback_lists=[xuexilv,zaoting]\n",
    "    model.fit(x=trains, y=trains_label, validation_data=(val, val_label), epochs=EPOCHS,\n",
    "                batch_size=BATCH_SIZE, shuffle=True,\n",
    "                callbacks=callback_lists,\n",
    "                verbose=1)\n",
    "     # 保存模型\n",
    "\n",
    "    model.save('./warmup_embedding/model_fold' + str(fold_count+1) + '.h5')\n",
    "\n",
    "    del model\n",
    "\n",
    "    model = load_model('./warmup_embedding/model_fold' + str(fold_count+1) + '.h5')\n",
    "\n",
    "    val_pred = model.predict(val, verbose=1)\n",
    "\n",
    "    # Sn, Sp, Acc, MCC, AUC\n",
    "    Sn, Sp, Acc, MCC = show_performance(val_label[:, 1], val_pred[:, 1])\n",
    "    AUC = roc_auc_score(val_label[:, 1], val_pred[:, 1])\n",
    "    print('Sn = %f, Sp = %f, Acc = %f, MCC = %f, AUC = %f' % (Sn, Sp, Acc, MCC, AUC))\n",
    "\n",
    "    performance = [Sn, Sp, Acc, MCC, AUC]\n",
    "    all_performance.append(performance)\n",
    "    \n",
    "all_performance = np.array(all_performance)\n",
    "print('10 fold result:', all_performance)\n",
    "performance_mean = performance_mean(all_performance)\n",
    "\n",
    "model.fit(x=train, y=train_label, validation_data=(test, test_label), epochs=EPOCHS,\n",
    "                      batch_size=BATCH_SIZE, shuffle=True,\n",
    "                      callbacks=[EarlyStopping(monitor='val_loss', patience=20, mode='auto')],\n",
    "                      verbose=1)\n",
    "model.save('./warmup_embedding/model_test.h5')\n",
    "\n",
    "del model\n",
    "\n",
    "model = load_model('./warmup_embedding/model_test.h5')\n",
    "\n",
    "test_score = model.predict(test)\n",
    "\n",
    "\n",
    "# Sn, Sp, Acc, MCC, AUC\n",
    "Sn, Sp, Acc, MCC = show_performance(test_label[:,1], test_score[:,1])\n",
    "AUC = roc_auc_score(test_label[:,1], test_score[:,1])\n",
    "\n",
    "print('-----------------------------------------------test---------------------------------------')\n",
    "print('Sn = %f, Sp = %f, Acc = %f, MCC = %f, AUC = %f' % (Sn, Sp, Acc, MCC, AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb5e8000-8c39-4a02-8a35-f852b77551fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'true_label': test_label[:,1],\n",
    "    'predicted_probability': test_score[:, 1]  # 提取正类的预测概率\n",
    "})\n",
    "df.to_csv('./warmup_embedding/predictions_with_probabilities_bilstm.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91775726-fd00-4de1-97b9-fc427b21c586",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************Warmup+embedding_64******************************\n",
      "(None, 15, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 09:53:30.674327: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3954 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:65:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 15, 48)\n",
      "****************************** the 1 fold ******************************\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 09:53:38.745424: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8800\n",
      "Could not load symbol cublasGetSmCountTarget from libcublas.so.11. Error: /usr/local/cuda/targets/x86_64-linux/lib/libcublas.so.11: undefined symbol: cublasGetSmCountTarget\n",
      "2024-06-06 09:53:39.016807: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-06-06 09:53:39.056488: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe9340fc320 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-06 09:53:39.056528: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-06-06 09:53:39.061533: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-06-06 09:53:39.116690: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-06 09:53:39.119314: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:231] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.6\n",
      "2024-06-06 09:53:39.119333: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:234] Used ptxas at ptxas\n",
      "2024-06-06 09:53:39.132491: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-06-06 09:53:39.187590: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/162 [..............................] - ETA: 21:43 - loss: 3.2261 - accuracy: 0.4062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 09:53:39.609743: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-06 09:53:39.617636: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-06 09:53:39.636699: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-06 09:53:39.681631: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-06 09:53:39.714499: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4/162 [..............................] - ETA: 14s - loss: 3.2246 - accuracy: 0.4844 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 09:53:39.904876: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 20/162 [==>...........................] - ETA: 8s - loss: 3.2228 - accuracy: 0.5016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 09:53:40.814775: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 23/162 [===>..........................] - ETA: 9s - loss: 3.2223 - accuracy: 0.5027"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 09:53:41.040589: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 18s 61ms/step - loss: 3.1392 - accuracy: 0.5363 - val_loss: 2.9728 - val_accuracy: 0.5784\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 2.6891 - accuracy: 0.6024 - val_loss: 2.3527 - val_accuracy: 0.6376\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 2.0499 - accuracy: 0.6568 - val_loss: 1.8202 - val_accuracy: 0.6411\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 1.6281 - accuracy: 0.6640 - val_loss: 1.4826 - val_accuracy: 0.6620\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 1.3611 - accuracy: 0.6648 - val_loss: 1.2699 - val_accuracy: 0.6707\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 1.1887 - accuracy: 0.6669 - val_loss: 1.1355 - val_accuracy: 0.6672\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - ETA: 0s - loss: 1.0753 - accuracy: 0.6679"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 09:54:40.124185: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 9s 53ms/step - loss: 1.0753 - accuracy: 0.6679 - val_loss: 1.0383 - val_accuracy: 0.6847\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 1.0003 - accuracy: 0.6681 - val_loss: 0.9847 - val_accuracy: 0.6638\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.9481 - accuracy: 0.6700 - val_loss: 0.9377 - val_accuracy: 0.6690\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.9087 - accuracy: 0.6714 - val_loss: 0.9113 - val_accuracy: 0.6638\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 8s 51ms/step - loss: 0.8799 - accuracy: 0.6694 - val_loss: 0.8789 - val_accuracy: 0.6847\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.8529 - accuracy: 0.6720 - val_loss: 0.8635 - val_accuracy: 0.6794\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.8325 - accuracy: 0.6745 - val_loss: 0.8338 - val_accuracy: 0.6899\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.8121 - accuracy: 0.6786 - val_loss: 0.8136 - val_accuracy: 0.7038\n",
      "Epoch 15/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.7919 - accuracy: 0.6834 - val_loss: 0.7953 - val_accuracy: 0.6951\n",
      "Epoch 16/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.7728 - accuracy: 0.6877 - val_loss: 0.7731 - val_accuracy: 0.6847\n",
      "Epoch 17/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.7543 - accuracy: 0.6906 - val_loss: 0.7630 - val_accuracy: 0.6812\n",
      "Epoch 18/200\n",
      "162/162 [==============================] - ETA: 0s - loss: 0.7368 - accuracy: 0.6931"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 09:56:13.828014: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 9s 54ms/step - loss: 0.7368 - accuracy: 0.6931 - val_loss: 0.7423 - val_accuracy: 0.6934\n",
      "Epoch 19/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.7225 - accuracy: 0.6950 - val_loss: 0.7245 - val_accuracy: 0.6916\n",
      "Epoch 20/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.7078 - accuracy: 0.6995 - val_loss: 0.7122 - val_accuracy: 0.6934\n",
      "Epoch 21/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.6945 - accuracy: 0.6968 - val_loss: 0.7006 - val_accuracy: 0.6934\n",
      "Epoch 22/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.6828 - accuracy: 0.7010 - val_loss: 0.6858 - val_accuracy: 0.7160\n",
      "Epoch 23/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.6709 - accuracy: 0.7009 - val_loss: 0.6800 - val_accuracy: 0.6951\n",
      "Epoch 24/200\n",
      "162/162 [==============================] - 8s 51ms/step - loss: 0.6587 - accuracy: 0.7067 - val_loss: 0.6678 - val_accuracy: 0.7056\n",
      "Epoch 25/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.6485 - accuracy: 0.7034 - val_loss: 0.6570 - val_accuracy: 0.7125\n",
      "Epoch 26/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.6350 - accuracy: 0.7094 - val_loss: 0.6517 - val_accuracy: 0.7178\n",
      "Epoch 27/200\n",
      "162/162 [==============================] - 8s 51ms/step - loss: 0.6266 - accuracy: 0.7168 - val_loss: 0.6419 - val_accuracy: 0.7195\n",
      "Epoch 28/200\n",
      "162/162 [==============================] - 9s 52ms/step - loss: 0.6158 - accuracy: 0.7212 - val_loss: 0.6269 - val_accuracy: 0.7178\n",
      "Epoch 29/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.6050 - accuracy: 0.7222 - val_loss: 0.6176 - val_accuracy: 0.7230\n",
      "Epoch 30/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.5967 - accuracy: 0.7326 - val_loss: 0.6089 - val_accuracy: 0.7300\n",
      "Epoch 31/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5891 - accuracy: 0.7336 - val_loss: 0.6120 - val_accuracy: 0.7213\n",
      "Epoch 32/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5804 - accuracy: 0.7328 - val_loss: 0.6072 - val_accuracy: 0.7265\n",
      "Epoch 33/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5750 - accuracy: 0.7367 - val_loss: 0.6012 - val_accuracy: 0.7334\n",
      "Epoch 34/200\n",
      "162/162 [==============================] - ETA: 0s - loss: 0.5683 - accuracy: 0.7394"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 09:58:30.045486: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5683 - accuracy: 0.7394 - val_loss: 0.5859 - val_accuracy: 0.7369\n",
      "Epoch 35/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.5624 - accuracy: 0.7410 - val_loss: 0.5750 - val_accuracy: 0.7474\n",
      "Epoch 36/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5590 - accuracy: 0.7379 - val_loss: 0.5751 - val_accuracy: 0.7544\n",
      "Epoch 37/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.5533 - accuracy: 0.7534 - val_loss: 0.5842 - val_accuracy: 0.7387\n",
      "Epoch 38/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.5484 - accuracy: 0.7530 - val_loss: 0.5688 - val_accuracy: 0.7526\n",
      "Epoch 39/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.5452 - accuracy: 0.7516 - val_loss: 0.5664 - val_accuracy: 0.7561\n",
      "Epoch 40/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5391 - accuracy: 0.7557 - val_loss: 0.5622 - val_accuracy: 0.7544\n",
      "Epoch 41/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.5381 - accuracy: 0.7557 - val_loss: 0.5589 - val_accuracy: 0.7578\n",
      "Epoch 42/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.5354 - accuracy: 0.7538 - val_loss: 0.5658 - val_accuracy: 0.7439\n",
      "Epoch 43/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5320 - accuracy: 0.7563 - val_loss: 0.5651 - val_accuracy: 0.7491\n",
      "Epoch 44/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.5311 - accuracy: 0.7575 - val_loss: 0.5603 - val_accuracy: 0.7526\n",
      "Epoch 45/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5300 - accuracy: 0.7598 - val_loss: 0.5620 - val_accuracy: 0.7491\n",
      "Epoch 46/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.5275 - accuracy: 0.7582 - val_loss: 0.5678 - val_accuracy: 0.7439\n",
      "Epoch 47/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5267 - accuracy: 0.7561 - val_loss: 0.5549 - val_accuracy: 0.7561\n",
      "Epoch 48/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5242 - accuracy: 0.7586 - val_loss: 0.5512 - val_accuracy: 0.7526\n",
      "Epoch 49/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.5220 - accuracy: 0.7610 - val_loss: 0.5592 - val_accuracy: 0.7491\n",
      "Epoch 50/200\n",
      "162/162 [==============================] - 8s 50ms/step - loss: 0.5205 - accuracy: 0.7590 - val_loss: 0.5523 - val_accuracy: 0.7404\n",
      "Epoch 51/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.5201 - accuracy: 0.7629 - val_loss: 0.5515 - val_accuracy: 0.7491\n",
      "Epoch 52/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5197 - accuracy: 0.7615 - val_loss: 0.5493 - val_accuracy: 0.7526\n",
      "Epoch 53/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.5169 - accuracy: 0.7675 - val_loss: 0.5480 - val_accuracy: 0.7526\n",
      "Epoch 54/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5158 - accuracy: 0.7683 - val_loss: 0.5635 - val_accuracy: 0.7439\n",
      "Epoch 55/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.5151 - accuracy: 0.7656 - val_loss: 0.5623 - val_accuracy: 0.7404\n",
      "Epoch 56/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.5144 - accuracy: 0.7668 - val_loss: 0.5518 - val_accuracy: 0.7456\n",
      "Epoch 57/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.5134 - accuracy: 0.7621 - val_loss: 0.5474 - val_accuracy: 0.7422\n",
      "Epoch 58/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.5110 - accuracy: 0.7623 - val_loss: 0.5587 - val_accuracy: 0.7352\n",
      "Epoch 59/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5123 - accuracy: 0.7685 - val_loss: 0.5534 - val_accuracy: 0.7369\n",
      "Epoch 60/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5104 - accuracy: 0.7687 - val_loss: 0.5525 - val_accuracy: 0.7422\n",
      "Epoch 61/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.5088 - accuracy: 0.7703 - val_loss: 0.5581 - val_accuracy: 0.7300\n",
      "Epoch 62/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5109 - accuracy: 0.7650 - val_loss: 0.5498 - val_accuracy: 0.7422\n",
      "Epoch 63/200\n",
      "162/162 [==============================] - 8s 51ms/step - loss: 0.5093 - accuracy: 0.7666 - val_loss: 0.5513 - val_accuracy: 0.7439\n",
      "Epoch 64/200\n",
      "162/162 [==============================] - 8s 51ms/step - loss: 0.5089 - accuracy: 0.7724 - val_loss: 0.5562 - val_accuracy: 0.7352\n",
      "Epoch 65/200\n",
      "162/162 [==============================] - 8s 51ms/step - loss: 0.5052 - accuracy: 0.7724 - val_loss: 0.5484 - val_accuracy: 0.7387\n",
      "Epoch 66/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.5077 - accuracy: 0.7666 - val_loss: 0.5553 - val_accuracy: 0.7300\n",
      "Epoch 67/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.5066 - accuracy: 0.7668 - val_loss: 0.5645 - val_accuracy: 0.7387\n",
      "Epoch 68/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5073 - accuracy: 0.7685 - val_loss: 0.5538 - val_accuracy: 0.7334\n",
      "Epoch 69/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5057 - accuracy: 0.7730 - val_loss: 0.5507 - val_accuracy: 0.7404\n",
      "Epoch 70/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5027 - accuracy: 0.7747 - val_loss: 0.5571 - val_accuracy: 0.7317\n",
      "18/18 [==============================] - 1s 16ms/step\n",
      "Sn = 0.709265, Sp = 0.758621, Acc = 0.731707, MCC = 0.465973, AUC = 0.814696\n",
      "****************************** the 2 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 13s 61ms/step - loss: 0.5050 - accuracy: 0.7732 - val_loss: 0.5108 - val_accuracy: 0.7648\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.5042 - accuracy: 0.7739 - val_loss: 0.5134 - val_accuracy: 0.7718\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5071 - accuracy: 0.7710 - val_loss: 0.5184 - val_accuracy: 0.7753\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.5070 - accuracy: 0.7695 - val_loss: 0.5180 - val_accuracy: 0.7631\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5046 - accuracy: 0.7683 - val_loss: 0.5161 - val_accuracy: 0.7596\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5035 - accuracy: 0.7701 - val_loss: 0.5189 - val_accuracy: 0.7666\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5037 - accuracy: 0.7726 - val_loss: 0.5195 - val_accuracy: 0.7666\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5021 - accuracy: 0.7722 - val_loss: 0.5174 - val_accuracy: 0.7683\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.5011 - accuracy: 0.7691 - val_loss: 0.5236 - val_accuracy: 0.7596\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5030 - accuracy: 0.7642 - val_loss: 0.5221 - val_accuracy: 0.7700\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4997 - accuracy: 0.7734 - val_loss: 0.5283 - val_accuracy: 0.7596\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4980 - accuracy: 0.7728 - val_loss: 0.5212 - val_accuracy: 0.7718\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4975 - accuracy: 0.7743 - val_loss: 0.5314 - val_accuracy: 0.7683\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4984 - accuracy: 0.7732 - val_loss: 0.5317 - val_accuracy: 0.7596\n",
      "18/18 [==============================] - 1s 14ms/step\n",
      "Sn = 0.740351, Sp = 0.778547, Acc = 0.759582, MCC = 0.519339, AUC = 0.834626\n",
      "****************************** the 3 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 13s 62ms/step - loss: 0.4959 - accuracy: 0.7769 - val_loss: 0.4999 - val_accuracy: 0.7644\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4957 - accuracy: 0.7804 - val_loss: 0.5041 - val_accuracy: 0.7679\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4981 - accuracy: 0.7763 - val_loss: 0.5041 - val_accuracy: 0.7609\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 8s 51ms/step - loss: 0.4980 - accuracy: 0.7740 - val_loss: 0.5048 - val_accuracy: 0.7574\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4945 - accuracy: 0.7767 - val_loss: 0.5113 - val_accuracy: 0.7592\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4965 - accuracy: 0.7767 - val_loss: 0.5141 - val_accuracy: 0.7574\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4958 - accuracy: 0.7784 - val_loss: 0.5130 - val_accuracy: 0.7627\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4934 - accuracy: 0.7784 - val_loss: 0.5095 - val_accuracy: 0.7557\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4946 - accuracy: 0.7784 - val_loss: 0.5042 - val_accuracy: 0.7574\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4913 - accuracy: 0.7812 - val_loss: 0.5049 - val_accuracy: 0.7627\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4917 - accuracy: 0.7810 - val_loss: 0.5059 - val_accuracy: 0.7574\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4895 - accuracy: 0.7779 - val_loss: 0.5130 - val_accuracy: 0.7522\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4919 - accuracy: 0.7757 - val_loss: 0.5074 - val_accuracy: 0.7574\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4892 - accuracy: 0.7788 - val_loss: 0.5090 - val_accuracy: 0.7557\n",
      "18/18 [==============================] - 1s 16ms/step\n",
      "Sn = 0.788396, Sp = 0.721429, Acc = 0.755672, MCC = 0.511272, AUC = 0.844551\n",
      "****************************** the 4 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 13s 61ms/step - loss: 0.4895 - accuracy: 0.7777 - val_loss: 0.4659 - val_accuracy: 0.8098\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4922 - accuracy: 0.7784 - val_loss: 0.4719 - val_accuracy: 0.8045\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4931 - accuracy: 0.7786 - val_loss: 0.4715 - val_accuracy: 0.8028\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4915 - accuracy: 0.7726 - val_loss: 0.4742 - val_accuracy: 0.8028\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 8s 50ms/step - loss: 0.4882 - accuracy: 0.7753 - val_loss: 0.4775 - val_accuracy: 0.7958\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4914 - accuracy: 0.7740 - val_loss: 0.4820 - val_accuracy: 0.7888\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4888 - accuracy: 0.7775 - val_loss: 0.4753 - val_accuracy: 0.7958\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4888 - accuracy: 0.7763 - val_loss: 0.4754 - val_accuracy: 0.7941\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4877 - accuracy: 0.7765 - val_loss: 0.4725 - val_accuracy: 0.8010\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4848 - accuracy: 0.7744 - val_loss: 0.4721 - val_accuracy: 0.8010\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4891 - accuracy: 0.7784 - val_loss: 0.4749 - val_accuracy: 0.7941\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4864 - accuracy: 0.7740 - val_loss: 0.4801 - val_accuracy: 0.8010\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4859 - accuracy: 0.7806 - val_loss: 0.4751 - val_accuracy: 0.7993\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4846 - accuracy: 0.7792 - val_loss: 0.4733 - val_accuracy: 0.8028\n",
      "18/18 [==============================] - 1s 15ms/step\n",
      "Sn = 0.800699, Sp = 0.804878, Acc = 0.802792, MCC = 0.605585, AUC = 0.871921\n",
      "****************************** the 5 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 12s 60ms/step - loss: 0.4791 - accuracy: 0.7858 - val_loss: 0.4656 - val_accuracy: 0.7941\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4814 - accuracy: 0.7823 - val_loss: 0.4729 - val_accuracy: 0.7976\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4828 - accuracy: 0.7812 - val_loss: 0.4741 - val_accuracy: 0.7958\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4823 - accuracy: 0.7866 - val_loss: 0.4782 - val_accuracy: 0.7923\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4818 - accuracy: 0.7827 - val_loss: 0.4766 - val_accuracy: 0.7958\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4840 - accuracy: 0.7843 - val_loss: 0.4766 - val_accuracy: 0.7871\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4798 - accuracy: 0.7874 - val_loss: 0.4801 - val_accuracy: 0.7818\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4790 - accuracy: 0.7856 - val_loss: 0.4766 - val_accuracy: 0.7871\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4805 - accuracy: 0.7874 - val_loss: 0.4771 - val_accuracy: 0.7871\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4790 - accuracy: 0.7852 - val_loss: 0.4780 - val_accuracy: 0.7836\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4792 - accuracy: 0.7895 - val_loss: 0.4841 - val_accuracy: 0.7766\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4771 - accuracy: 0.7899 - val_loss: 0.4782 - val_accuracy: 0.7801\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 8s 50ms/step - loss: 0.4768 - accuracy: 0.7843 - val_loss: 0.4802 - val_accuracy: 0.7871\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4764 - accuracy: 0.7860 - val_loss: 0.4863 - val_accuracy: 0.7749\n",
      "18/18 [==============================] - 1s 18ms/step\n",
      "Sn = 0.848592, Sp = 0.702422, Acc = 0.774869, MCC = 0.556582, AUC = 0.865320\n",
      "****************************** the 6 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 13s 62ms/step - loss: 0.4728 - accuracy: 0.7916 - val_loss: 0.4566 - val_accuracy: 0.7941\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4763 - accuracy: 0.7872 - val_loss: 0.4579 - val_accuracy: 0.7923\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4786 - accuracy: 0.7850 - val_loss: 0.4646 - val_accuracy: 0.7871\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4777 - accuracy: 0.7901 - val_loss: 0.4679 - val_accuracy: 0.7941\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4733 - accuracy: 0.7907 - val_loss: 0.4714 - val_accuracy: 0.7888\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4754 - accuracy: 0.7864 - val_loss: 0.4666 - val_accuracy: 0.7888\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4717 - accuracy: 0.7909 - val_loss: 0.4721 - val_accuracy: 0.7941\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4720 - accuracy: 0.7922 - val_loss: 0.4684 - val_accuracy: 0.7836\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4717 - accuracy: 0.7916 - val_loss: 0.4725 - val_accuracy: 0.7906\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4700 - accuracy: 0.7926 - val_loss: 0.4764 - val_accuracy: 0.7923\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4733 - accuracy: 0.7868 - val_loss: 0.4745 - val_accuracy: 0.7923\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4679 - accuracy: 0.7936 - val_loss: 0.4727 - val_accuracy: 0.7836\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4716 - accuracy: 0.7951 - val_loss: 0.4732 - val_accuracy: 0.7818\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4738 - accuracy: 0.7856 - val_loss: 0.4780 - val_accuracy: 0.7801\n",
      "18/18 [==============================] - 1s 14ms/step\n",
      "Sn = 0.857143, Sp = 0.702797, Acc = 0.780105, MCC = 0.566818, AUC = 0.869094\n",
      "****************************** the 7 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 13s 59ms/step - loss: 0.4674 - accuracy: 0.7949 - val_loss: 0.4444 - val_accuracy: 0.7976\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4700 - accuracy: 0.7947 - val_loss: 0.4499 - val_accuracy: 0.7993\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4714 - accuracy: 0.7899 - val_loss: 0.4518 - val_accuracy: 0.8063\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4716 - accuracy: 0.7934 - val_loss: 0.4636 - val_accuracy: 0.7801\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4693 - accuracy: 0.7957 - val_loss: 0.4585 - val_accuracy: 0.7958\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4716 - accuracy: 0.7938 - val_loss: 0.4585 - val_accuracy: 0.7976\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4686 - accuracy: 0.7922 - val_loss: 0.4597 - val_accuracy: 0.7976\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4676 - accuracy: 0.7965 - val_loss: 0.4600 - val_accuracy: 0.7871\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4674 - accuracy: 0.7938 - val_loss: 0.4635 - val_accuracy: 0.7888\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4658 - accuracy: 0.7936 - val_loss: 0.4674 - val_accuracy: 0.7941\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4684 - accuracy: 0.7959 - val_loss: 0.4686 - val_accuracy: 0.7871\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4664 - accuracy: 0.7953 - val_loss: 0.4656 - val_accuracy: 0.7801\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4649 - accuracy: 0.7986 - val_loss: 0.4706 - val_accuracy: 0.7766\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4612 - accuracy: 0.7988 - val_loss: 0.4701 - val_accuracy: 0.7853\n",
      "18/18 [==============================] - 1s 18ms/step\n",
      "Sn = 0.842294, Sp = 0.731293, Acc = 0.785340, MCC = 0.576050, AUC = 0.868895\n",
      "****************************** the 8 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 13s 60ms/step - loss: 0.4588 - accuracy: 0.8002 - val_loss: 0.4565 - val_accuracy: 0.8045\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4604 - accuracy: 0.7984 - val_loss: 0.4623 - val_accuracy: 0.7976\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4619 - accuracy: 0.7953 - val_loss: 0.4668 - val_accuracy: 0.8098\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4610 - accuracy: 0.7992 - val_loss: 0.4619 - val_accuracy: 0.8028\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4629 - accuracy: 0.7940 - val_loss: 0.4729 - val_accuracy: 0.7853\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4652 - accuracy: 0.7971 - val_loss: 0.4797 - val_accuracy: 0.7888\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4603 - accuracy: 0.7959 - val_loss: 0.4678 - val_accuracy: 0.7958\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 8s 51ms/step - loss: 0.4594 - accuracy: 0.7959 - val_loss: 0.4714 - val_accuracy: 0.7923\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4612 - accuracy: 0.7959 - val_loss: 0.4709 - val_accuracy: 0.8045\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4587 - accuracy: 0.8003 - val_loss: 0.4811 - val_accuracy: 0.7853\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4625 - accuracy: 0.7967 - val_loss: 0.4753 - val_accuracy: 0.7871\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4594 - accuracy: 0.8011 - val_loss: 0.4874 - val_accuracy: 0.7784\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4563 - accuracy: 0.7992 - val_loss: 0.4801 - val_accuracy: 0.7871\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4562 - accuracy: 0.8019 - val_loss: 0.4841 - val_accuracy: 0.7993\n",
      "18/18 [==============================] - 1s 14ms/step\n",
      "Sn = 0.864407, Sp = 0.730216, Acc = 0.799302, MCC = 0.601333, AUC = 0.866980\n",
      "****************************** the 9 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 13s 64ms/step - loss: 0.4545 - accuracy: 0.8050 - val_loss: 0.4465 - val_accuracy: 0.8185\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4577 - accuracy: 0.8009 - val_loss: 0.4465 - val_accuracy: 0.8220\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4590 - accuracy: 0.8000 - val_loss: 0.4558 - val_accuracy: 0.8237\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4577 - accuracy: 0.7994 - val_loss: 0.4579 - val_accuracy: 0.8185\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4559 - accuracy: 0.8013 - val_loss: 0.4635 - val_accuracy: 0.7958\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4584 - accuracy: 0.7996 - val_loss: 0.4581 - val_accuracy: 0.8150\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4550 - accuracy: 0.8062 - val_loss: 0.4685 - val_accuracy: 0.8133\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4565 - accuracy: 0.8019 - val_loss: 0.4622 - val_accuracy: 0.8133\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4546 - accuracy: 0.8002 - val_loss: 0.4622 - val_accuracy: 0.8115\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4543 - accuracy: 0.8029 - val_loss: 0.4681 - val_accuracy: 0.8098\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4541 - accuracy: 0.8013 - val_loss: 0.4632 - val_accuracy: 0.8063\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4527 - accuracy: 0.8052 - val_loss: 0.4638 - val_accuracy: 0.8115\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4525 - accuracy: 0.8052 - val_loss: 0.4629 - val_accuracy: 0.8080\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4509 - accuracy: 0.8038 - val_loss: 0.4814 - val_accuracy: 0.7976\n",
      "18/18 [==============================] - 1s 17ms/step\n",
      "Sn = 0.894928, Sp = 0.707071, Acc = 0.797557, MCC = 0.610036, AUC = 0.875311\n",
      "****************************** the 10 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 12s 60ms/step - loss: 0.4465 - accuracy: 0.8118 - val_loss: 0.4531 - val_accuracy: 0.7993\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4513 - accuracy: 0.8058 - val_loss: 0.4593 - val_accuracy: 0.7976\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4540 - accuracy: 0.8069 - val_loss: 0.4621 - val_accuracy: 0.7976\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4508 - accuracy: 0.8079 - val_loss: 0.4663 - val_accuracy: 0.7853\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4506 - accuracy: 0.8083 - val_loss: 0.4658 - val_accuracy: 0.7993\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4500 - accuracy: 0.8048 - val_loss: 0.4792 - val_accuracy: 0.7871\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4488 - accuracy: 0.8075 - val_loss: 0.4829 - val_accuracy: 0.7731\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4500 - accuracy: 0.8075 - val_loss: 0.4767 - val_accuracy: 0.7888\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4479 - accuracy: 0.8093 - val_loss: 0.4789 - val_accuracy: 0.7801\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4467 - accuracy: 0.8116 - val_loss: 0.4799 - val_accuracy: 0.7853\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4488 - accuracy: 0.8071 - val_loss: 0.4724 - val_accuracy: 0.7923\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4468 - accuracy: 0.8108 - val_loss: 0.4771 - val_accuracy: 0.7906\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4468 - accuracy: 0.8089 - val_loss: 0.4749 - val_accuracy: 0.7958\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4439 - accuracy: 0.8087 - val_loss: 0.4905 - val_accuracy: 0.7784\n",
      "18/18 [==============================] - 1s 15ms/step\n",
      "Sn = 0.839552, Sp = 0.724590, Acc = 0.778360, MCC = 0.564709, AUC = 0.865708\n",
      "10 fold result: [[0.70926517 0.75862069 0.73170732 0.46597326 0.81469649]\n",
      " [0.74035087 0.77854671 0.75958188 0.51933915 0.83462636]\n",
      " [0.7883959  0.72142857 0.7556719  0.51127235 0.84455144]\n",
      " [0.8006993  0.80487805 0.80279232 0.60558473 0.87192076]\n",
      " [0.84859155 0.70242214 0.77486911 0.55658187 0.86531995]\n",
      " [0.85714285 0.7027972  0.78010471 0.56681825 0.86909432]\n",
      " [0.8422939  0.73129251 0.78534031 0.57604966 0.86889523]\n",
      " [0.86440678 0.73021582 0.79930192 0.60133255 0.86697964]\n",
      " [0.89492753 0.7070707  0.79755672 0.61003648 0.87531108]\n",
      " [0.83955224 0.72459016 0.77835951 0.56470919 0.86570834]]\n",
      "Sn = 0.8186 ± 0.0553\n",
      "Sp = 0.7362 ± 0.0325\n",
      "Acc = 0.7765 ± 0.0212\n",
      "Mcc = 0.5578 ± 0.0441\n",
      "Auc = 0.8577 ± 0.0188\n",
      "Epoch 1/200\n",
      "180/180 [==============================] - 12s 53ms/step - loss: 0.4501 - accuracy: 0.8072 - val_loss: 0.4740 - val_accuracy: 0.8035\n",
      "Epoch 2/200\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.4464 - accuracy: 0.8104"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 10:22:54.372437: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 8s 45ms/step - loss: 0.4464 - accuracy: 0.8104 - val_loss: 0.4720 - val_accuracy: 0.8066\n",
      "Epoch 3/200\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.4506 - accuracy: 0.8057 - val_loss: 0.4733 - val_accuracy: 0.8003\n",
      "Epoch 4/200\n",
      "180/180 [==============================] - 9s 48ms/step - loss: 0.4460 - accuracy: 0.8069 - val_loss: 0.4768 - val_accuracy: 0.8050\n",
      "Epoch 5/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.4466 - accuracy: 0.8102 - val_loss: 0.4734 - val_accuracy: 0.7956\n",
      "Epoch 6/200\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.4450 - accuracy: 0.8077 - val_loss: 0.4759 - val_accuracy: 0.7940\n",
      "Epoch 7/200\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.4465 - accuracy: 0.8098 - val_loss: 0.4698 - val_accuracy: 0.8050\n",
      "Epoch 8/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.4458 - accuracy: 0.8086 - val_loss: 0.4744 - val_accuracy: 0.7956\n",
      "Epoch 9/200\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.4435 - accuracy: 0.8084 - val_loss: 0.4739 - val_accuracy: 0.7972\n",
      "Epoch 10/200\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.4449 - accuracy: 0.8070 - val_loss: 0.4749 - val_accuracy: 0.7940\n",
      "Epoch 11/200\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.4436 - accuracy: 0.8076 - val_loss: 0.4695 - val_accuracy: 0.8019\n",
      "Epoch 12/200\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.4412 - accuracy: 0.8125 - val_loss: 0.4731 - val_accuracy: 0.7925\n",
      "Epoch 13/200\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.4409 - accuracy: 0.8100 - val_loss: 0.4706 - val_accuracy: 0.7972\n",
      "Epoch 14/200\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.4406 - accuracy: 0.8095 - val_loss: 0.4789 - val_accuracy: 0.7972\n",
      "Epoch 15/200\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.4444 - accuracy: 0.8109 - val_loss: 0.4721 - val_accuracy: 0.8066\n",
      "Epoch 16/200\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.4407 - accuracy: 0.8081 - val_loss: 0.4813 - val_accuracy: 0.7925\n",
      "Epoch 17/200\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.4407 - accuracy: 0.8126 - val_loss: 0.4746 - val_accuracy: 0.7972\n",
      "Epoch 18/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.4385 - accuracy: 0.8132 - val_loss: 0.4811 - val_accuracy: 0.7862\n",
      "Epoch 19/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.4387 - accuracy: 0.8147 - val_loss: 0.4739 - val_accuracy: 0.8035\n",
      "Epoch 20/200\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.4397 - accuracy: 0.8133 - val_loss: 0.4792 - val_accuracy: 0.7987\n",
      "Epoch 21/200\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.4395 - accuracy: 0.8156 - val_loss: 0.4775 - val_accuracy: 0.7940\n",
      "Epoch 22/200\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.4372 - accuracy: 0.8179 - val_loss: 0.4781 - val_accuracy: 0.7972\n",
      "Epoch 23/200\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.4380 - accuracy: 0.8156 - val_loss: 0.4834 - val_accuracy: 0.8035\n",
      "Epoch 24/200\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.4388 - accuracy: 0.8144 - val_loss: 0.4740 - val_accuracy: 0.7956\n",
      "Epoch 25/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.4383 - accuracy: 0.8111 - val_loss: 0.4865 - val_accuracy: 0.7877\n",
      "Epoch 26/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.4373 - accuracy: 0.8159 - val_loss: 0.4731 - val_accuracy: 0.7909\n",
      "Epoch 27/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.4374 - accuracy: 0.8114 - val_loss: 0.4896 - val_accuracy: 0.7877\n",
      "Epoch 28/200\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.4375 - accuracy: 0.8072 - val_loss: 0.4754 - val_accuracy: 0.8003\n",
      "Epoch 29/200\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.4368 - accuracy: 0.8144 - val_loss: 0.4799 - val_accuracy: 0.8050\n",
      "Epoch 30/200\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.4370 - accuracy: 0.8128 - val_loss: 0.4726 - val_accuracy: 0.7940\n",
      "Epoch 31/200\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.4339 - accuracy: 0.8179 - val_loss: 0.4775 - val_accuracy: 0.7940\n",
      "20/20 [==============================] - 1s 14ms/step\n",
      "-----------------------------------------------test---------------------------------------\n",
      "Sn = 0.795597, Sp = 0.792453, Acc = 0.794025, MCC = 0.588053, AUC = 0.869892\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "tf.random.set_seed(1)  # for reproducibility\n",
    "# reading model\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 200\n",
    "\n",
    "# # Cross-validation\n",
    "n = 10\n",
    "k_fold = KFold(n_splits=n, shuffle=True, random_state=42)\n",
    "\n",
    "all_performance = []\n",
    "tprs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "for fold_count, (train_index, val_index) in enumerate(k_fold.split(train)):\n",
    "    print('*' * 30 + ' the ' + str(fold_count + 1) + ' fold ' + '*' * 30)\n",
    "    trains, val = train[train_index], train[val_index]\n",
    "    trains_label, val_label = train_label[train_index], train_label[val_index]\n",
    "    zaoting = EarlyStopping(monitor='val_loss', patience=13, mode='auto')\n",
    "    xuexilv = WarmupExponentialDecay(lr_base=0.0002,decay=0.00002,warmup_epochs=2)\n",
    "    callback_lists=[xuexilv,zaoting]\n",
    "    model.fit(x=trains, y=trains_label, validation_data=(val, val_label), epochs=EPOCHS,\n",
    "                batch_size=BATCH_SIZE, shuffle=True,\n",
    "                callbacks=callback_lists,\n",
    "                verbose=1)\n",
    "     # 保存模型\n",
    "\n",
    "    model.save('./warmup_embedding/model_fold' + str(fold_count+1) + '.h5')\n",
    "\n",
    "    del model\n",
    "\n",
    "    model = load_model('./warmup_embedding/model_fold' + str(fold_count+1) + '.h5')\n",
    "\n",
    "    val_pred = model.predict(val, verbose=1)\n",
    "\n",
    "    # Sn, Sp, Acc, MCC, AUC\n",
    "    Sn, Sp, Acc, MCC = show_performance(val_label[:, 1], val_pred[:, 1])\n",
    "    AUC = roc_auc_score(val_label[:, 1], val_pred[:, 1])\n",
    "    print('Sn = %f, Sp = %f, Acc = %f, MCC = %f, AUC = %f' % (Sn, Sp, Acc, MCC, AUC))\n",
    "\n",
    "    performance = [Sn, Sp, Acc, MCC, AUC]\n",
    "    all_performance.append(performance)\n",
    "    \n",
    "all_performance = np.array(all_performance)\n",
    "print('10 fold result:', all_performance)\n",
    "performance_mean = performance_mean(all_performance)\n",
    "\n",
    "model.fit(x=train, y=train_label, validation_data=(test, test_label), epochs=EPOCHS,\n",
    "                      batch_size=BATCH_SIZE, shuffle=True,\n",
    "                      callbacks=[EarlyStopping(monitor='val_loss', patience=20, mode='auto')],\n",
    "                      verbose=1)\n",
    "model.save('./warmup_embedding/model_test.h5')\n",
    "\n",
    "del model\n",
    "\n",
    "model = load_model('./warmup_embedding/model_test.h5')\n",
    "\n",
    "test_score = model.predict(test)\n",
    "\n",
    "\n",
    "# Sn, Sp, Acc, MCC, AUC\n",
    "Sn, Sp, Acc, MCC = show_performance(test_label[:,1], test_score[:,1])\n",
    "AUC = roc_auc_score(test_label[:,1], test_score[:,1])\n",
    "\n",
    "print('-----------------------------------------------test---------------------------------------')\n",
    "print('Sn = %f, Sp = %f, Acc = %f, MCC = %f, AUC = %f' % (Sn, Sp, Acc, MCC, AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b128f9b1-d780-45ce-bbed-0fdc346d18ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************Warmup+embedding_64******************************\n",
      "(None, 15, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 08:42:14.780925: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5110 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:65:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 15, 48)\n",
      "****************************** the 1 fold ******************************\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 08:42:21.853236: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8800\n",
      "Could not load symbol cublasGetSmCountTarget from libcublas.so.11. Error: /usr/local/cuda/targets/x86_64-linux/lib/libcublas.so.11: undefined symbol: cublasGetSmCountTarget\n",
      "2024-06-06 08:42:22.065724: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-06-06 08:42:22.092370: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f5fec04fe80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-06 08:42:22.092411: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-06-06 08:42:22.100465: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-06-06 08:42:22.158911: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-06 08:42:22.161589: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:231] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.6\n",
      "2024-06-06 08:42:22.161608: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:234] Used ptxas at ptxas\n",
      "2024-06-06 08:42:22.176214: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-06-06 08:42:22.236117: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/162 [..............................] - ETA: 18:49 - loss: 3.2254 - accuracy: 0.3750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 08:42:22.610140: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-06 08:42:22.631346: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-06 08:42:22.631989: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-06 08:42:22.689013: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-06 08:42:22.710522: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6/162 [>.............................] - ETA: 9s - loss: 3.2245 - accuracy: 0.4375 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 08:42:22.854900: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 19/162 [==>...........................] - ETA: 6s - loss: 3.2231 - accuracy: 0.4655"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 08:42:23.526990: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-06 08:42:23.715360: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 14s 45ms/step - loss: 3.1399 - accuracy: 0.5087 - val_loss: 2.9739 - val_accuracy: 0.5627\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 2.6948 - accuracy: 0.5903 - val_loss: 2.3687 - val_accuracy: 0.6516\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 2.0564 - accuracy: 0.6551 - val_loss: 1.8177 - val_accuracy: 0.6429\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 1.6292 - accuracy: 0.6621 - val_loss: 1.4805 - val_accuracy: 0.6655\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 1.3608 - accuracy: 0.6681 - val_loss: 1.2679 - val_accuracy: 0.6777\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 1.1882 - accuracy: 0.6702 - val_loss: 1.1339 - val_accuracy: 0.6760\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - ETA: 0s - loss: 1.0751 - accuracy: 0.6727"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 08:43:04.531237: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 6s 37ms/step - loss: 1.0751 - accuracy: 0.6727 - val_loss: 1.0360 - val_accuracy: 0.6794\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.9999 - accuracy: 0.6691 - val_loss: 0.9837 - val_accuracy: 0.6742\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.9475 - accuracy: 0.6747 - val_loss: 0.9357 - val_accuracy: 0.6794\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.9069 - accuracy: 0.6753 - val_loss: 0.9079 - val_accuracy: 0.6742\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.8769 - accuracy: 0.6753 - val_loss: 0.8756 - val_accuracy: 0.6899\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.8494 - accuracy: 0.6791 - val_loss: 0.8569 - val_accuracy: 0.6916\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.8254 - accuracy: 0.6846 - val_loss: 0.8270 - val_accuracy: 0.7056\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.8036 - accuracy: 0.6871 - val_loss: 0.8037 - val_accuracy: 0.6969\n",
      "Epoch 15/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.7825 - accuracy: 0.6894 - val_loss: 0.7863 - val_accuracy: 0.7003\n",
      "Epoch 16/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.7645 - accuracy: 0.6894 - val_loss: 0.7619 - val_accuracy: 0.7021\n",
      "Epoch 17/200\n",
      "162/162 [==============================] - 6s 34ms/step - loss: 0.7490 - accuracy: 0.6908 - val_loss: 0.7539 - val_accuracy: 0.6882\n",
      "Epoch 18/200\n",
      "162/162 [==============================] - ETA: 0s - loss: 0.7316 - accuracy: 0.6950"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 08:44:08.510246: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 6s 37ms/step - loss: 0.7316 - accuracy: 0.6950 - val_loss: 0.7339 - val_accuracy: 0.7056\n",
      "Epoch 19/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.7174 - accuracy: 0.6968 - val_loss: 0.7190 - val_accuracy: 0.7003\n",
      "Epoch 20/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.7031 - accuracy: 0.7001 - val_loss: 0.7054 - val_accuracy: 0.7056\n",
      "Epoch 21/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.6887 - accuracy: 0.7082 - val_loss: 0.6933 - val_accuracy: 0.7108\n",
      "Epoch 22/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.6780 - accuracy: 0.7043 - val_loss: 0.6831 - val_accuracy: 0.7143\n",
      "Epoch 23/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.6651 - accuracy: 0.7073 - val_loss: 0.6779 - val_accuracy: 0.7038\n",
      "Epoch 24/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.6528 - accuracy: 0.7076 - val_loss: 0.6662 - val_accuracy: 0.7056\n",
      "Epoch 25/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.6439 - accuracy: 0.7082 - val_loss: 0.6542 - val_accuracy: 0.7143\n",
      "Epoch 26/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.6313 - accuracy: 0.7177 - val_loss: 0.6522 - val_accuracy: 0.7125\n",
      "Epoch 27/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.6242 - accuracy: 0.7193 - val_loss: 0.6475 - val_accuracy: 0.7056\n",
      "Epoch 28/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.6147 - accuracy: 0.7208 - val_loss: 0.6298 - val_accuracy: 0.7091\n",
      "Epoch 29/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.6036 - accuracy: 0.7255 - val_loss: 0.6242 - val_accuracy: 0.7213\n",
      "Epoch 30/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5959 - accuracy: 0.7311 - val_loss: 0.6138 - val_accuracy: 0.7265\n",
      "Epoch 31/200\n",
      "162/162 [==============================] - 6s 37ms/step - loss: 0.5889 - accuracy: 0.7321 - val_loss: 0.6217 - val_accuracy: 0.7091\n",
      "Epoch 32/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5822 - accuracy: 0.7348 - val_loss: 0.6127 - val_accuracy: 0.7317\n",
      "Epoch 33/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5755 - accuracy: 0.7367 - val_loss: 0.6082 - val_accuracy: 0.7265\n",
      "Epoch 34/200\n",
      "162/162 [==============================] - ETA: 0s - loss: 0.5701 - accuracy: 0.7346"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 08:45:41.633016: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 6s 37ms/step - loss: 0.5701 - accuracy: 0.7346 - val_loss: 0.5946 - val_accuracy: 0.7300\n",
      "Epoch 35/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5638 - accuracy: 0.7451 - val_loss: 0.5819 - val_accuracy: 0.7404\n",
      "Epoch 36/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5615 - accuracy: 0.7334 - val_loss: 0.5833 - val_accuracy: 0.7334\n",
      "Epoch 37/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5549 - accuracy: 0.7445 - val_loss: 0.5946 - val_accuracy: 0.7160\n",
      "Epoch 38/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5506 - accuracy: 0.7462 - val_loss: 0.5770 - val_accuracy: 0.7282\n",
      "Epoch 39/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5479 - accuracy: 0.7460 - val_loss: 0.5740 - val_accuracy: 0.7422\n",
      "Epoch 40/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5429 - accuracy: 0.7487 - val_loss: 0.5683 - val_accuracy: 0.7456\n",
      "Epoch 41/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5428 - accuracy: 0.7470 - val_loss: 0.5639 - val_accuracy: 0.7456\n",
      "Epoch 42/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5351 - accuracy: 0.7503 - val_loss: 0.5738 - val_accuracy: 0.7387\n",
      "Epoch 43/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5323 - accuracy: 0.7555 - val_loss: 0.5715 - val_accuracy: 0.7352\n",
      "Epoch 44/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5333 - accuracy: 0.7509 - val_loss: 0.5717 - val_accuracy: 0.7317\n",
      "Epoch 45/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5301 - accuracy: 0.7569 - val_loss: 0.5650 - val_accuracy: 0.7404\n",
      "Epoch 46/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5272 - accuracy: 0.7577 - val_loss: 0.5745 - val_accuracy: 0.7317\n",
      "Epoch 47/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5278 - accuracy: 0.7610 - val_loss: 0.5633 - val_accuracy: 0.7369\n",
      "Epoch 48/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5285 - accuracy: 0.7536 - val_loss: 0.5524 - val_accuracy: 0.7526\n",
      "Epoch 49/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5230 - accuracy: 0.7660 - val_loss: 0.5642 - val_accuracy: 0.7422\n",
      "Epoch 50/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5207 - accuracy: 0.7604 - val_loss: 0.5551 - val_accuracy: 0.7422\n",
      "Epoch 51/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5213 - accuracy: 0.7596 - val_loss: 0.5610 - val_accuracy: 0.7369\n",
      "Epoch 52/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5206 - accuracy: 0.7598 - val_loss: 0.5500 - val_accuracy: 0.7526\n",
      "Epoch 53/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5177 - accuracy: 0.7579 - val_loss: 0.5496 - val_accuracy: 0.7526\n",
      "Epoch 54/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5162 - accuracy: 0.7613 - val_loss: 0.5693 - val_accuracy: 0.7334\n",
      "Epoch 55/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5146 - accuracy: 0.7644 - val_loss: 0.5723 - val_accuracy: 0.7282\n",
      "Epoch 56/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5146 - accuracy: 0.7633 - val_loss: 0.5586 - val_accuracy: 0.7387\n",
      "Epoch 57/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5142 - accuracy: 0.7619 - val_loss: 0.5465 - val_accuracy: 0.7526\n",
      "Epoch 58/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5104 - accuracy: 0.7660 - val_loss: 0.5667 - val_accuracy: 0.7352\n",
      "Epoch 59/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5124 - accuracy: 0.7660 - val_loss: 0.5518 - val_accuracy: 0.7369\n",
      "Epoch 60/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5104 - accuracy: 0.7666 - val_loss: 0.5581 - val_accuracy: 0.7352\n",
      "Epoch 61/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5089 - accuracy: 0.7695 - val_loss: 0.5660 - val_accuracy: 0.7334\n",
      "Epoch 62/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5121 - accuracy: 0.7662 - val_loss: 0.5475 - val_accuracy: 0.7456\n",
      "Epoch 63/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5102 - accuracy: 0.7652 - val_loss: 0.5508 - val_accuracy: 0.7404\n",
      "Epoch 64/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5060 - accuracy: 0.7677 - val_loss: 0.5574 - val_accuracy: 0.7282\n",
      "Epoch 65/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5085 - accuracy: 0.7689 - val_loss: 0.5438 - val_accuracy: 0.7509\n",
      "Epoch 66/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5058 - accuracy: 0.7664 - val_loss: 0.5578 - val_accuracy: 0.7282\n",
      "Epoch 67/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5076 - accuracy: 0.7646 - val_loss: 0.5574 - val_accuracy: 0.7352\n",
      "Epoch 68/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5082 - accuracy: 0.7695 - val_loss: 0.5531 - val_accuracy: 0.7317\n",
      "Epoch 69/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5053 - accuracy: 0.7737 - val_loss: 0.5495 - val_accuracy: 0.7352\n",
      "Epoch 70/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5039 - accuracy: 0.7724 - val_loss: 0.5527 - val_accuracy: 0.7439\n",
      "Epoch 71/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5030 - accuracy: 0.7716 - val_loss: 0.5462 - val_accuracy: 0.7422\n",
      "Epoch 72/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5064 - accuracy: 0.7674 - val_loss: 0.5396 - val_accuracy: 0.7578\n",
      "Epoch 73/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5015 - accuracy: 0.7683 - val_loss: 0.5420 - val_accuracy: 0.7474\n",
      "Epoch 74/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5034 - accuracy: 0.7718 - val_loss: 0.5529 - val_accuracy: 0.7369\n",
      "Epoch 75/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5018 - accuracy: 0.7737 - val_loss: 0.5615 - val_accuracy: 0.7317\n",
      "Epoch 76/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5012 - accuracy: 0.7705 - val_loss: 0.5487 - val_accuracy: 0.7404\n",
      "Epoch 77/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5011 - accuracy: 0.7778 - val_loss: 0.5556 - val_accuracy: 0.7317\n",
      "Epoch 78/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4987 - accuracy: 0.7751 - val_loss: 0.5398 - val_accuracy: 0.7526\n",
      "Epoch 79/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5007 - accuracy: 0.7705 - val_loss: 0.5492 - val_accuracy: 0.7317\n",
      "Epoch 80/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4941 - accuracy: 0.7769 - val_loss: 0.5439 - val_accuracy: 0.7474\n",
      "Epoch 81/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4974 - accuracy: 0.7780 - val_loss: 0.5417 - val_accuracy: 0.7456\n",
      "Epoch 82/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4974 - accuracy: 0.7763 - val_loss: 0.5556 - val_accuracy: 0.7300\n",
      "Epoch 83/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4975 - accuracy: 0.7739 - val_loss: 0.5377 - val_accuracy: 0.7491\n",
      "Epoch 84/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4961 - accuracy: 0.7786 - val_loss: 0.5628 - val_accuracy: 0.7247\n",
      "Epoch 85/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4931 - accuracy: 0.7790 - val_loss: 0.5431 - val_accuracy: 0.7474\n",
      "Epoch 86/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4947 - accuracy: 0.7743 - val_loss: 0.5385 - val_accuracy: 0.7596\n",
      "Epoch 87/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4952 - accuracy: 0.7770 - val_loss: 0.5445 - val_accuracy: 0.7439\n",
      "Epoch 88/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4923 - accuracy: 0.7788 - val_loss: 0.5466 - val_accuracy: 0.7422\n",
      "Epoch 89/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4904 - accuracy: 0.7831 - val_loss: 0.5508 - val_accuracy: 0.7369\n",
      "Epoch 90/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4920 - accuracy: 0.7780 - val_loss: 0.5369 - val_accuracy: 0.7578\n",
      "Epoch 91/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4906 - accuracy: 0.7798 - val_loss: 0.5694 - val_accuracy: 0.7125\n",
      "Epoch 92/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.4914 - accuracy: 0.7801 - val_loss: 0.5473 - val_accuracy: 0.7404\n",
      "Epoch 93/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4919 - accuracy: 0.7784 - val_loss: 0.5513 - val_accuracy: 0.7369\n",
      "Epoch 94/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4916 - accuracy: 0.7805 - val_loss: 0.5337 - val_accuracy: 0.7544\n",
      "Epoch 95/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.4909 - accuracy: 0.7840 - val_loss: 0.5331 - val_accuracy: 0.7631\n",
      "Epoch 96/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4899 - accuracy: 0.7780 - val_loss: 0.5293 - val_accuracy: 0.7544\n",
      "Epoch 97/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.4883 - accuracy: 0.7864 - val_loss: 0.5528 - val_accuracy: 0.7352\n",
      "Epoch 98/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.4869 - accuracy: 0.7827 - val_loss: 0.5290 - val_accuracy: 0.7474\n",
      "Epoch 99/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.4859 - accuracy: 0.7881 - val_loss: 0.5597 - val_accuracy: 0.7352\n",
      "Epoch 100/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.4871 - accuracy: 0.7834 - val_loss: 0.5428 - val_accuracy: 0.7404\n",
      "Epoch 101/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4875 - accuracy: 0.7825 - val_loss: 0.5297 - val_accuracy: 0.7491\n",
      "Epoch 102/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4880 - accuracy: 0.7844 - val_loss: 0.5389 - val_accuracy: 0.7317\n",
      "Epoch 103/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.4861 - accuracy: 0.7862 - val_loss: 0.5446 - val_accuracy: 0.7369\n",
      "Epoch 104/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.4881 - accuracy: 0.7831 - val_loss: 0.5461 - val_accuracy: 0.7369\n",
      "Epoch 105/200\n",
      "162/162 [==============================] - 5s 31ms/step - loss: 0.4867 - accuracy: 0.7836 - val_loss: 0.5399 - val_accuracy: 0.7474\n",
      "Epoch 106/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4845 - accuracy: 0.7829 - val_loss: 0.5421 - val_accuracy: 0.7387\n",
      "Epoch 107/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4849 - accuracy: 0.7871 - val_loss: 0.5352 - val_accuracy: 0.7544\n",
      "Epoch 108/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4844 - accuracy: 0.7864 - val_loss: 0.5364 - val_accuracy: 0.7456\n",
      "Epoch 109/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4853 - accuracy: 0.7836 - val_loss: 0.5249 - val_accuracy: 0.7578\n",
      "Epoch 110/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4837 - accuracy: 0.7865 - val_loss: 0.5443 - val_accuracy: 0.7404\n",
      "Epoch 111/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.4776 - accuracy: 0.7906 - val_loss: 0.5307 - val_accuracy: 0.7544\n",
      "Epoch 112/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4835 - accuracy: 0.7834 - val_loss: 0.5256 - val_accuracy: 0.7526\n",
      "Epoch 113/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4795 - accuracy: 0.7844 - val_loss: 0.5514 - val_accuracy: 0.7422\n",
      "Epoch 114/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4827 - accuracy: 0.7838 - val_loss: 0.5214 - val_accuracy: 0.7666\n",
      "Epoch 115/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4788 - accuracy: 0.7860 - val_loss: 0.5507 - val_accuracy: 0.7352\n",
      "Epoch 116/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4806 - accuracy: 0.7842 - val_loss: 0.5327 - val_accuracy: 0.7456\n",
      "Epoch 117/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4815 - accuracy: 0.7887 - val_loss: 0.5206 - val_accuracy: 0.7561\n",
      "Epoch 118/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4798 - accuracy: 0.7871 - val_loss: 0.5546 - val_accuracy: 0.7352\n",
      "Epoch 119/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4817 - accuracy: 0.7862 - val_loss: 0.5274 - val_accuracy: 0.7544\n",
      "Epoch 120/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4759 - accuracy: 0.7939 - val_loss: 0.5466 - val_accuracy: 0.7422\n",
      "Epoch 121/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4789 - accuracy: 0.7864 - val_loss: 0.5419 - val_accuracy: 0.7422\n",
      "Epoch 122/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4811 - accuracy: 0.7860 - val_loss: 0.5214 - val_accuracy: 0.7491\n",
      "Epoch 123/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4767 - accuracy: 0.7918 - val_loss: 0.5374 - val_accuracy: 0.7422\n",
      "Epoch 124/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4781 - accuracy: 0.7918 - val_loss: 0.5237 - val_accuracy: 0.7613\n",
      "Epoch 125/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4767 - accuracy: 0.7895 - val_loss: 0.5532 - val_accuracy: 0.7422\n",
      "Epoch 126/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4771 - accuracy: 0.7900 - val_loss: 0.5504 - val_accuracy: 0.7404\n",
      "Epoch 127/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4758 - accuracy: 0.7887 - val_loss: 0.5521 - val_accuracy: 0.7369\n",
      "Epoch 128/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.4761 - accuracy: 0.7889 - val_loss: 0.5211 - val_accuracy: 0.7491\n",
      "Epoch 129/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4766 - accuracy: 0.7869 - val_loss: 0.5326 - val_accuracy: 0.7526\n",
      "Epoch 130/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4752 - accuracy: 0.7912 - val_loss: 0.5200 - val_accuracy: 0.7509\n",
      "Epoch 131/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4752 - accuracy: 0.7871 - val_loss: 0.5460 - val_accuracy: 0.7439\n",
      "Epoch 132/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4747 - accuracy: 0.7926 - val_loss: 0.5312 - val_accuracy: 0.7561\n",
      "Epoch 133/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4747 - accuracy: 0.7900 - val_loss: 0.5278 - val_accuracy: 0.7491\n",
      "Epoch 134/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4753 - accuracy: 0.7902 - val_loss: 0.5186 - val_accuracy: 0.7526\n",
      "Epoch 135/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4740 - accuracy: 0.7885 - val_loss: 0.5398 - val_accuracy: 0.7509\n",
      "Epoch 136/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4724 - accuracy: 0.7912 - val_loss: 0.5311 - val_accuracy: 0.7561\n",
      "Epoch 137/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4735 - accuracy: 0.7873 - val_loss: 0.5273 - val_accuracy: 0.7474\n",
      "Epoch 138/200\n",
      "162/162 [==============================] - 5s 34ms/step - loss: 0.4713 - accuracy: 0.7902 - val_loss: 0.5167 - val_accuracy: 0.7666\n",
      "Epoch 139/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4730 - accuracy: 0.7875 - val_loss: 0.5259 - val_accuracy: 0.7578\n",
      "Epoch 140/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4727 - accuracy: 0.7895 - val_loss: 0.5333 - val_accuracy: 0.7491\n",
      "Epoch 141/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4704 - accuracy: 0.7896 - val_loss: 0.5320 - val_accuracy: 0.7526\n",
      "Epoch 142/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.4715 - accuracy: 0.7904 - val_loss: 0.5194 - val_accuracy: 0.7613\n",
      "Epoch 143/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4709 - accuracy: 0.7926 - val_loss: 0.5441 - val_accuracy: 0.7439\n",
      "Epoch 144/200\n",
      "162/162 [==============================] - 6s 34ms/step - loss: 0.4685 - accuracy: 0.7935 - val_loss: 0.5354 - val_accuracy: 0.7596\n",
      "Epoch 145/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4696 - accuracy: 0.7910 - val_loss: 0.5377 - val_accuracy: 0.7456\n",
      "Epoch 146/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4713 - accuracy: 0.7920 - val_loss: 0.5294 - val_accuracy: 0.7561\n",
      "Epoch 147/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4675 - accuracy: 0.7941 - val_loss: 0.5236 - val_accuracy: 0.7509\n",
      "Epoch 148/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4689 - accuracy: 0.7898 - val_loss: 0.5297 - val_accuracy: 0.7509\n",
      "Epoch 149/200\n",
      "162/162 [==============================] - 6s 37ms/step - loss: 0.4681 - accuracy: 0.7879 - val_loss: 0.5174 - val_accuracy: 0.7509\n",
      "Epoch 150/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4714 - accuracy: 0.7935 - val_loss: 0.5273 - val_accuracy: 0.7544\n",
      "Epoch 151/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4681 - accuracy: 0.7947 - val_loss: 0.5276 - val_accuracy: 0.7578\n",
      "18/18 [==============================] - 1s 10ms/step\n",
      "Sn = 0.753994, Sp = 0.762452, Acc = 0.757840, MCC = 0.514700, AUC = 0.837709\n",
      "****************************** the 2 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 10s 44ms/step - loss: 0.4689 - accuracy: 0.7891 - val_loss: 0.4806 - val_accuracy: 0.7962\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 6s 37ms/step - loss: 0.4724 - accuracy: 0.7871 - val_loss: 0.4816 - val_accuracy: 0.7875\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4767 - accuracy: 0.7873 - val_loss: 0.4897 - val_accuracy: 0.7718\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4745 - accuracy: 0.7893 - val_loss: 0.4966 - val_accuracy: 0.7753\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4733 - accuracy: 0.7881 - val_loss: 0.4909 - val_accuracy: 0.7857\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4743 - accuracy: 0.7898 - val_loss: 0.4998 - val_accuracy: 0.7770\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.4715 - accuracy: 0.7929 - val_loss: 0.4937 - val_accuracy: 0.7805\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4712 - accuracy: 0.7906 - val_loss: 0.4932 - val_accuracy: 0.7840\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4710 - accuracy: 0.7898 - val_loss: 0.4945 - val_accuracy: 0.7753\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4700 - accuracy: 0.7883 - val_loss: 0.5004 - val_accuracy: 0.7753\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.4680 - accuracy: 0.7922 - val_loss: 0.5093 - val_accuracy: 0.7613\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4676 - accuracy: 0.7844 - val_loss: 0.4957 - val_accuracy: 0.7822\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4674 - accuracy: 0.7920 - val_loss: 0.5128 - val_accuracy: 0.7666\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4694 - accuracy: 0.7955 - val_loss: 0.5049 - val_accuracy: 0.7666\n",
      "18/18 [==============================] - 1s 12ms/step\n",
      "Sn = 0.764912, Sp = 0.768166, Acc = 0.766551, MCC = 0.533078, AUC = 0.849050\n",
      "****************************** the 3 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 10s 45ms/step - loss: 0.4655 - accuracy: 0.7957 - val_loss: 0.4628 - val_accuracy: 0.7766\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4690 - accuracy: 0.7949 - val_loss: 0.4663 - val_accuracy: 0.7766\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4687 - accuracy: 0.7955 - val_loss: 0.4697 - val_accuracy: 0.7784\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.4736 - accuracy: 0.7893 - val_loss: 0.4693 - val_accuracy: 0.7801\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4668 - accuracy: 0.7932 - val_loss: 0.4795 - val_accuracy: 0.7818\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.4678 - accuracy: 0.7924 - val_loss: 0.4817 - val_accuracy: 0.7714\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4674 - accuracy: 0.7899 - val_loss: 0.4774 - val_accuracy: 0.7714\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4670 - accuracy: 0.7920 - val_loss: 0.4835 - val_accuracy: 0.7679\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4702 - accuracy: 0.7936 - val_loss: 0.4761 - val_accuracy: 0.7609\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.4663 - accuracy: 0.7928 - val_loss: 0.4780 - val_accuracy: 0.7784\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.4643 - accuracy: 0.7982 - val_loss: 0.4807 - val_accuracy: 0.7818\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4610 - accuracy: 0.7951 - val_loss: 0.4935 - val_accuracy: 0.7836\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4627 - accuracy: 0.7924 - val_loss: 0.4804 - val_accuracy: 0.7714\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4638 - accuracy: 0.7943 - val_loss: 0.4870 - val_accuracy: 0.7504\n",
      "18/18 [==============================] - 1s 12ms/step\n",
      "Sn = 0.798635, Sp = 0.700000, Acc = 0.750436, MCC = 0.501547, AUC = 0.857935\n",
      "****************************** the 4 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 9s 43ms/step - loss: 0.4652 - accuracy: 0.7914 - val_loss: 0.4284 - val_accuracy: 0.8202\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4697 - accuracy: 0.7912 - val_loss: 0.4344 - val_accuracy: 0.8168\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 6s 37ms/step - loss: 0.4687 - accuracy: 0.7883 - val_loss: 0.4398 - val_accuracy: 0.8115\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.4676 - accuracy: 0.7926 - val_loss: 0.4398 - val_accuracy: 0.8220\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4642 - accuracy: 0.7914 - val_loss: 0.4487 - val_accuracy: 0.7993\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4676 - accuracy: 0.7912 - val_loss: 0.4471 - val_accuracy: 0.8080\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4649 - accuracy: 0.7938 - val_loss: 0.4436 - val_accuracy: 0.8045\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4686 - accuracy: 0.7907 - val_loss: 0.4461 - val_accuracy: 0.8115\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 6s 37ms/step - loss: 0.4648 - accuracy: 0.7909 - val_loss: 0.4447 - val_accuracy: 0.7976\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4627 - accuracy: 0.7905 - val_loss: 0.4466 - val_accuracy: 0.7958\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4633 - accuracy: 0.7943 - val_loss: 0.4521 - val_accuracy: 0.8045\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4641 - accuracy: 0.7903 - val_loss: 0.4528 - val_accuracy: 0.8010\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4635 - accuracy: 0.7938 - val_loss: 0.4475 - val_accuracy: 0.8028\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4615 - accuracy: 0.7938 - val_loss: 0.4495 - val_accuracy: 0.8028\n",
      "18/18 [==============================] - 1s 10ms/step\n",
      "Sn = 0.790210, Sp = 0.815331, Acc = 0.802792, MCC = 0.605747, AUC = 0.884676\n",
      "****************************** the 5 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 10s 43ms/step - loss: 0.4559 - accuracy: 0.7941 - val_loss: 0.4455 - val_accuracy: 0.7976\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4606 - accuracy: 0.7969 - val_loss: 0.4512 - val_accuracy: 0.8010\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4603 - accuracy: 0.7957 - val_loss: 0.4554 - val_accuracy: 0.7888\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4601 - accuracy: 0.7969 - val_loss: 0.4651 - val_accuracy: 0.7958\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4599 - accuracy: 0.7940 - val_loss: 0.4546 - val_accuracy: 0.7906\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4587 - accuracy: 0.8038 - val_loss: 0.4616 - val_accuracy: 0.8010\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4580 - accuracy: 0.8000 - val_loss: 0.4650 - val_accuracy: 0.7923\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4585 - accuracy: 0.7982 - val_loss: 0.4625 - val_accuracy: 0.7853\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4592 - accuracy: 0.7978 - val_loss: 0.4639 - val_accuracy: 0.7941\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4583 - accuracy: 0.8013 - val_loss: 0.4675 - val_accuracy: 0.7853\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4588 - accuracy: 0.7990 - val_loss: 0.4691 - val_accuracy: 0.7906\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4567 - accuracy: 0.8000 - val_loss: 0.4654 - val_accuracy: 0.7941\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4541 - accuracy: 0.7978 - val_loss: 0.4719 - val_accuracy: 0.7871\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4548 - accuracy: 0.7953 - val_loss: 0.4726 - val_accuracy: 0.7906\n",
      "18/18 [==============================] - 1s 10ms/step\n",
      "Sn = 0.855634, Sp = 0.726644, Acc = 0.790576, MCC = 0.586777, AUC = 0.872557\n",
      "****************************** the 6 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 10s 44ms/step - loss: 0.4520 - accuracy: 0.8021 - val_loss: 0.4347 - val_accuracy: 0.7976\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4555 - accuracy: 0.8025 - val_loss: 0.4384 - val_accuracy: 0.8045\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4587 - accuracy: 0.7986 - val_loss: 0.4458 - val_accuracy: 0.7958\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 6s 37ms/step - loss: 0.4582 - accuracy: 0.7976 - val_loss: 0.4483 - val_accuracy: 0.8028\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.4536 - accuracy: 0.7988 - val_loss: 0.4476 - val_accuracy: 0.8010\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 6s 34ms/step - loss: 0.4550 - accuracy: 0.8013 - val_loss: 0.4436 - val_accuracy: 0.7958\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4520 - accuracy: 0.8048 - val_loss: 0.4515 - val_accuracy: 0.8080\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4552 - accuracy: 0.8002 - val_loss: 0.4527 - val_accuracy: 0.7976\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.4537 - accuracy: 0.8025 - val_loss: 0.4535 - val_accuracy: 0.7941\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.4520 - accuracy: 0.8000 - val_loss: 0.4520 - val_accuracy: 0.8098\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4552 - accuracy: 0.7986 - val_loss: 0.4551 - val_accuracy: 0.7958\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.4515 - accuracy: 0.8044 - val_loss: 0.4549 - val_accuracy: 0.7976\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4535 - accuracy: 0.8052 - val_loss: 0.4585 - val_accuracy: 0.7941\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4528 - accuracy: 0.8033 - val_loss: 0.4600 - val_accuracy: 0.7941\n",
      "18/18 [==============================] - 1s 12ms/step\n",
      "Sn = 0.864111, Sp = 0.723776, Acc = 0.794066, MCC = 0.593850, AUC = 0.879109\n",
      "****************************** the 7 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 10s 44ms/step - loss: 0.4475 - accuracy: 0.8046 - val_loss: 0.4326 - val_accuracy: 0.8080\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4519 - accuracy: 0.8040 - val_loss: 0.4394 - val_accuracy: 0.7976\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4532 - accuracy: 0.8042 - val_loss: 0.4399 - val_accuracy: 0.8010\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4519 - accuracy: 0.8021 - val_loss: 0.4578 - val_accuracy: 0.7906\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4499 - accuracy: 0.8035 - val_loss: 0.4513 - val_accuracy: 0.7906\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4502 - accuracy: 0.8011 - val_loss: 0.4526 - val_accuracy: 0.7888\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 6s 37ms/step - loss: 0.4510 - accuracy: 0.8025 - val_loss: 0.4509 - val_accuracy: 0.7993\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4503 - accuracy: 0.7978 - val_loss: 0.4516 - val_accuracy: 0.7923\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4519 - accuracy: 0.7996 - val_loss: 0.4529 - val_accuracy: 0.7958\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4478 - accuracy: 0.8038 - val_loss: 0.4585 - val_accuracy: 0.7906\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4529 - accuracy: 0.8050 - val_loss: 0.4577 - val_accuracy: 0.7853\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4515 - accuracy: 0.8027 - val_loss: 0.4569 - val_accuracy: 0.7958\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 6s 37ms/step - loss: 0.4490 - accuracy: 0.8036 - val_loss: 0.4613 - val_accuracy: 0.7836\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 6s 37ms/step - loss: 0.4448 - accuracy: 0.8062 - val_loss: 0.4662 - val_accuracy: 0.7888\n",
      "18/18 [==============================] - 1s 10ms/step\n",
      "Sn = 0.860215, Sp = 0.721088, Acc = 0.788831, MCC = 0.585617, AUC = 0.870370\n",
      "****************************** the 8 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 10s 44ms/step - loss: 0.4440 - accuracy: 0.8042 - val_loss: 0.4343 - val_accuracy: 0.8272\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4447 - accuracy: 0.8058 - val_loss: 0.4375 - val_accuracy: 0.8133\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4481 - accuracy: 0.8005 - val_loss: 0.4498 - val_accuracy: 0.8150\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 6s 37ms/step - loss: 0.4454 - accuracy: 0.8062 - val_loss: 0.4414 - val_accuracy: 0.8150\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4492 - accuracy: 0.8023 - val_loss: 0.4490 - val_accuracy: 0.8098\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4491 - accuracy: 0.8013 - val_loss: 0.4634 - val_accuracy: 0.8080\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4463 - accuracy: 0.8029 - val_loss: 0.4467 - val_accuracy: 0.8133\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4485 - accuracy: 0.8058 - val_loss: 0.4555 - val_accuracy: 0.8150\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4471 - accuracy: 0.8056 - val_loss: 0.4532 - val_accuracy: 0.8098\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4436 - accuracy: 0.8056 - val_loss: 0.4583 - val_accuracy: 0.8133\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4455 - accuracy: 0.8066 - val_loss: 0.4540 - val_accuracy: 0.8045\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4455 - accuracy: 0.8071 - val_loss: 0.4632 - val_accuracy: 0.8045\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4431 - accuracy: 0.8066 - val_loss: 0.4589 - val_accuracy: 0.8115\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4436 - accuracy: 0.8038 - val_loss: 0.4680 - val_accuracy: 0.8115\n",
      "18/18 [==============================] - 1s 10ms/step\n",
      "Sn = 0.891525, Sp = 0.726619, Acc = 0.811518, MCC = 0.628515, AUC = 0.876735\n",
      "****************************** the 9 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 10s 46ms/step - loss: 0.4423 - accuracy: 0.8098 - val_loss: 0.4180 - val_accuracy: 0.8342\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.4443 - accuracy: 0.8069 - val_loss: 0.4230 - val_accuracy: 0.8360\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.4460 - accuracy: 0.8027 - val_loss: 0.4277 - val_accuracy: 0.8290\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4463 - accuracy: 0.8044 - val_loss: 0.4348 - val_accuracy: 0.8290\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4447 - accuracy: 0.8077 - val_loss: 0.4378 - val_accuracy: 0.8133\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4460 - accuracy: 0.8056 - val_loss: 0.4319 - val_accuracy: 0.8255\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4447 - accuracy: 0.8075 - val_loss: 0.4463 - val_accuracy: 0.8115\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4434 - accuracy: 0.8067 - val_loss: 0.4358 - val_accuracy: 0.8237\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4435 - accuracy: 0.8079 - val_loss: 0.4361 - val_accuracy: 0.8255\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4439 - accuracy: 0.8067 - val_loss: 0.4508 - val_accuracy: 0.8360\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4425 - accuracy: 0.8089 - val_loss: 0.4357 - val_accuracy: 0.8290\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4412 - accuracy: 0.8128 - val_loss: 0.4431 - val_accuracy: 0.8412\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 6s 37ms/step - loss: 0.4445 - accuracy: 0.8110 - val_loss: 0.4385 - val_accuracy: 0.8272\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4400 - accuracy: 0.8124 - val_loss: 0.4585 - val_accuracy: 0.8098\n",
      "18/18 [==============================] - 1s 10ms/step\n",
      "Sn = 0.898551, Sp = 0.727273, Acc = 0.809773, MCC = 0.632400, AUC = 0.884387\n",
      "****************************** the 10 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 10s 43ms/step - loss: 0.4361 - accuracy: 0.8176 - val_loss: 0.4230 - val_accuracy: 0.8150\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4392 - accuracy: 0.8133 - val_loss: 0.4353 - val_accuracy: 0.8028\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4425 - accuracy: 0.8097 - val_loss: 0.4344 - val_accuracy: 0.8098\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4393 - accuracy: 0.8151 - val_loss: 0.4378 - val_accuracy: 0.8098\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4400 - accuracy: 0.8091 - val_loss: 0.4417 - val_accuracy: 0.8010\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4384 - accuracy: 0.8137 - val_loss: 0.4503 - val_accuracy: 0.7958\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4378 - accuracy: 0.8131 - val_loss: 0.4478 - val_accuracy: 0.7941\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 6s 37ms/step - loss: 0.4382 - accuracy: 0.8147 - val_loss: 0.4507 - val_accuracy: 0.7976\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4392 - accuracy: 0.8145 - val_loss: 0.4507 - val_accuracy: 0.7888\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4393 - accuracy: 0.8108 - val_loss: 0.4550 - val_accuracy: 0.7906\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 6s 37ms/step - loss: 0.4356 - accuracy: 0.8128 - val_loss: 0.4468 - val_accuracy: 0.8010\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4363 - accuracy: 0.8153 - val_loss: 0.4496 - val_accuracy: 0.7993\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4373 - accuracy: 0.8133 - val_loss: 0.4484 - val_accuracy: 0.8063\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 6s 37ms/step - loss: 0.4352 - accuracy: 0.8124 - val_loss: 0.4653 - val_accuracy: 0.7923\n",
      "18/18 [==============================] - 1s 11ms/step\n",
      "Sn = 0.865672, Sp = 0.727869, Acc = 0.792321, MCC = 0.595254, AUC = 0.878309\n",
      "10 fold result: [[0.75399361 0.7624521  0.75783972 0.51470031 0.83770947]\n",
      " [0.76491228 0.76816609 0.76655052 0.53307837 0.84904996]\n",
      " [0.79863481 0.7        0.7504363  0.50154715 0.85793515]\n",
      " [0.79020979 0.81533101 0.80279232 0.60574747 0.8846763 ]\n",
      " [0.8556338  0.7266436  0.79057592 0.5867772  0.87255714]\n",
      " [0.8641115  0.72377622 0.79406632 0.59385022 0.8791087 ]\n",
      " [0.86021505 0.72108843 0.78883072 0.5856173  0.87037037]\n",
      " [0.89152542 0.7266187  0.81151832 0.62851461 0.87673454]\n",
      " [0.89855072 0.72727272 0.80977312 0.63239982 0.88438735]\n",
      " [0.86567164 0.72786885 0.79232112 0.5952543  0.87830927]]\n",
      "Sn = 0.8343 ± 0.0499\n",
      "Sp = 0.7399 ± 0.0314\n",
      "Acc = 0.7865 ± 0.0202\n",
      "Mcc = 0.5777 ± 0.0434\n",
      "Auc = 0.8691 ± 0.0150\n",
      "Epoch 1/200\n",
      "180/180 [==============================] - 10s 39ms/step - loss: 0.4369 - accuracy: 0.8097 - val_loss: 0.4615 - val_accuracy: 0.8097\n",
      "Epoch 2/200\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.4371 - accuracy: 0.8137"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-06 09:10:28.492074: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4371 - accuracy: 0.8137 - val_loss: 0.4623 - val_accuracy: 0.8082\n",
      "Epoch 3/200\n",
      "180/180 [==============================] - 6s 33ms/step - loss: 0.4382 - accuracy: 0.8145 - val_loss: 0.4578 - val_accuracy: 0.8145\n",
      "Epoch 4/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4366 - accuracy: 0.8123 - val_loss: 0.4724 - val_accuracy: 0.8176\n",
      "Epoch 5/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4359 - accuracy: 0.8135 - val_loss: 0.4639 - val_accuracy: 0.8097\n",
      "Epoch 6/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4343 - accuracy: 0.8224 - val_loss: 0.4609 - val_accuracy: 0.8097\n",
      "Epoch 7/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4345 - accuracy: 0.8173 - val_loss: 0.4606 - val_accuracy: 0.8082\n",
      "Epoch 8/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4360 - accuracy: 0.8109 - val_loss: 0.4738 - val_accuracy: 0.8082\n",
      "Epoch 9/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4340 - accuracy: 0.8175 - val_loss: 0.4803 - val_accuracy: 0.8019\n",
      "Epoch 10/200\n",
      "180/180 [==============================] - 5s 30ms/step - loss: 0.4354 - accuracy: 0.8173 - val_loss: 0.4685 - val_accuracy: 0.8129\n",
      "Epoch 11/200\n",
      "180/180 [==============================] - 6s 31ms/step - loss: 0.4343 - accuracy: 0.8133 - val_loss: 0.4664 - val_accuracy: 0.8113\n",
      "Epoch 12/200\n",
      "180/180 [==============================] - 6s 31ms/step - loss: 0.4321 - accuracy: 0.8154 - val_loss: 0.4633 - val_accuracy: 0.8160\n",
      "Epoch 13/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4294 - accuracy: 0.8200 - val_loss: 0.4645 - val_accuracy: 0.8035\n",
      "Epoch 14/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4313 - accuracy: 0.8166 - val_loss: 0.4660 - val_accuracy: 0.8019\n",
      "Epoch 15/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4332 - accuracy: 0.8173 - val_loss: 0.4659 - val_accuracy: 0.8097\n",
      "Epoch 16/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4308 - accuracy: 0.8217 - val_loss: 0.4636 - val_accuracy: 0.8113\n",
      "Epoch 17/200\n",
      "180/180 [==============================] - 6s 31ms/step - loss: 0.4324 - accuracy: 0.8175 - val_loss: 0.4707 - val_accuracy: 0.8097\n",
      "Epoch 18/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4317 - accuracy: 0.8163 - val_loss: 0.4678 - val_accuracy: 0.8160\n",
      "Epoch 19/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4277 - accuracy: 0.8193 - val_loss: 0.4722 - val_accuracy: 0.8097\n",
      "Epoch 20/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4311 - accuracy: 0.8184 - val_loss: 0.4785 - val_accuracy: 0.8129\n",
      "Epoch 21/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4294 - accuracy: 0.8163 - val_loss: 0.4686 - val_accuracy: 0.8145\n",
      "Epoch 22/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4288 - accuracy: 0.8182 - val_loss: 0.4687 - val_accuracy: 0.8066\n",
      "Epoch 23/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4288 - accuracy: 0.8212 - val_loss: 0.4687 - val_accuracy: 0.8035\n",
      "20/20 [==============================] - 1s 12ms/step\n",
      "-----------------------------------------------test---------------------------------------\n",
      "Sn = 0.839623, Sp = 0.767296, Acc = 0.803459, MCC = 0.608512, AUC = 0.875272\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "tf.random.set_seed(1)  # for reproducibility\n",
    "# reading model\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 200\n",
    "\n",
    "# # Cross-validation\n",
    "n = 10\n",
    "k_fold = KFold(n_splits=n, shuffle=True, random_state=42)\n",
    "\n",
    "all_performance = []\n",
    "tprs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "for fold_count, (train_index, val_index) in enumerate(k_fold.split(train)):\n",
    "    print('*' * 30 + ' the ' + str(fold_count + 1) + ' fold ' + '*' * 30)\n",
    "    trains, val = train[train_index], train[val_index]\n",
    "    trains_label, val_label = train_label[train_index], train_label[val_index]\n",
    "    zaoting = EarlyStopping(monitor='val_loss', patience=13, mode='auto')\n",
    "    xuexilv = WarmupExponentialDecay(lr_base=0.0002,decay=0.00002,warmup_epochs=2)\n",
    "    callback_lists=[xuexilv,zaoting]\n",
    "    model.fit(x=trains, y=trains_label, validation_data=(val, val_label), epochs=EPOCHS,\n",
    "                batch_size=BATCH_SIZE, shuffle=True,\n",
    "                callbacks=callback_lists,\n",
    "                verbose=1)\n",
    "     # 保存模型\n",
    "\n",
    "    model.save('./warmup_embedding/model_fold' + str(fold_count+1) + '.h5')\n",
    "\n",
    "    del model\n",
    "\n",
    "    model = load_model('./warmup_embedding/model_fold' + str(fold_count+1) + '.h5')\n",
    "\n",
    "    val_pred = model.predict(val, verbose=1)\n",
    "\n",
    "    # Sn, Sp, Acc, MCC, AUC\n",
    "    Sn, Sp, Acc, MCC = show_performance(val_label[:, 1], val_pred[:, 1])\n",
    "    AUC = roc_auc_score(val_label[:, 1], val_pred[:, 1])\n",
    "    print('Sn = %f, Sp = %f, Acc = %f, MCC = %f, AUC = %f' % (Sn, Sp, Acc, MCC, AUC))\n",
    "\n",
    "    performance = [Sn, Sp, Acc, MCC, AUC]\n",
    "    all_performance.append(performance)\n",
    "    \n",
    "all_performance = np.array(all_performance)\n",
    "print('10 fold result:', all_performance)\n",
    "performance_mean = performance_mean(all_performance)\n",
    "\n",
    "model.fit(x=train, y=train_label, validation_data=(test, test_label), epochs=EPOCHS,\n",
    "                      batch_size=BATCH_SIZE, shuffle=True,\n",
    "                      callbacks=[EarlyStopping(monitor='val_loss', patience=20, mode='auto')],\n",
    "                      verbose=1)\n",
    "model.save('./warmup_embedding/model_test.h5')\n",
    "\n",
    "del model\n",
    "\n",
    "model = load_model('./warmup_embedding/model_test.h5')\n",
    "\n",
    "test_score = model.predict(test)\n",
    "\n",
    "\n",
    "# Sn, Sp, Acc, MCC, AUC\n",
    "Sn, Sp, Acc, MCC = show_performance(test_label[:,1], test_score[:,1])\n",
    "AUC = roc_auc_score(test_label[:,1], test_score[:,1])\n",
    "\n",
    "print('-----------------------------------------------test---------------------------------------')\n",
    "print('Sn = %f, Sp = %f, Acc = %f, MCC = %f, AUC = %f' % (Sn, Sp, Acc, MCC, AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5be2f272-0d78-483b-a794-78f713f51a25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************Warmup+embedding_256******************************\n",
      "(None, 15, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 19:13:22.348384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4226 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:65:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 15, 48)\n",
      "****************************** the 1 fold ******************************\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 19:13:30.496253: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8800\n",
      "Could not load symbol cublasGetSmCountTarget from libcublas.so.11. Error: /usr/local/cuda/targets/x86_64-linux/lib/libcublas.so.11: undefined symbol: cublasGetSmCountTarget\n",
      "2024-06-05 19:13:30.761179: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-06-05 19:13:30.799547: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f0dd800df80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-05 19:13:30.799577: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-06-05 19:13:30.805921: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-06-05 19:13:30.875386: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-05 19:13:30.878009: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:231] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.6\n",
      "2024-06-05 19:13:30.878027: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:234] Used ptxas at ptxas\n",
      "2024-06-05 19:13:30.891154: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-06-05 19:13:30.946441: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/162 [..............................] - ETA: 22:09 - loss: 3.2566 - accuracy: 0.7188"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 19:13:31.410818: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-05 19:13:31.434881: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-05 19:13:31.436749: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-05 19:13:31.486066: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-05 19:13:31.548704: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4/162 [..............................] - ETA: 13s - loss: 3.2589 - accuracy: 0.5234 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 19:13:31.701231: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 19/162 [==>...........................] - ETA: 9s - loss: 3.2581 - accuracy: 0.4885"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 19:13:32.666619: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 23/162 [===>..........................] - ETA: 9s - loss: 3.2573 - accuracy: 0.4959 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 19:13:32.948413: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 18s 62ms/step - loss: 3.1715 - accuracy: 0.5667 - val_loss: 2.9996 - val_accuracy: 0.6132\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 2.6932 - accuracy: 0.6442 - val_loss: 2.3532 - val_accuracy: 0.6463\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 2.0607 - accuracy: 0.6617 - val_loss: 1.8308 - val_accuracy: 0.6481\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 1.6390 - accuracy: 0.6640 - val_loss: 1.4923 - val_accuracy: 0.6725\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 1.3681 - accuracy: 0.6673 - val_loss: 1.2759 - val_accuracy: 0.6829\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 1.1931 - accuracy: 0.6710 - val_loss: 1.1382 - val_accuracy: 0.6777\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - ETA: 0s - loss: 1.0777 - accuracy: 0.6700"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 19:14:33.064017: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 9s 54ms/step - loss: 1.0777 - accuracy: 0.6700 - val_loss: 1.0389 - val_accuracy: 0.6847\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 1.0001 - accuracy: 0.6731 - val_loss: 0.9842 - val_accuracy: 0.6777\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.9455 - accuracy: 0.6776 - val_loss: 0.9324 - val_accuracy: 0.6986\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.9013 - accuracy: 0.6822 - val_loss: 0.8998 - val_accuracy: 0.6986\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.8650 - accuracy: 0.6890 - val_loss: 0.8640 - val_accuracy: 0.7021\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.8315 - accuracy: 0.6997 - val_loss: 0.8378 - val_accuracy: 0.7021\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.8038 - accuracy: 0.7053 - val_loss: 0.8109 - val_accuracy: 0.6986\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.7797 - accuracy: 0.7102 - val_loss: 0.7862 - val_accuracy: 0.7108\n",
      "Epoch 15/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.7564 - accuracy: 0.7202 - val_loss: 0.7677 - val_accuracy: 0.7160\n",
      "Epoch 16/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.7367 - accuracy: 0.7282 - val_loss: 0.7444 - val_accuracy: 0.7247\n",
      "Epoch 17/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.7200 - accuracy: 0.7218 - val_loss: 0.7403 - val_accuracy: 0.7195\n",
      "Epoch 18/200\n",
      "162/162 [==============================] - ETA: 0s - loss: 0.7001 - accuracy: 0.7336"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 19:16:08.474744: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 9s 55ms/step - loss: 0.7001 - accuracy: 0.7336 - val_loss: 0.7200 - val_accuracy: 0.7265\n",
      "Epoch 19/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.6823 - accuracy: 0.7358 - val_loss: 0.7082 - val_accuracy: 0.7195\n",
      "Epoch 20/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.6656 - accuracy: 0.7431 - val_loss: 0.6900 - val_accuracy: 0.7334\n",
      "Epoch 21/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.6510 - accuracy: 0.7451 - val_loss: 0.6809 - val_accuracy: 0.7369\n",
      "Epoch 22/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.6371 - accuracy: 0.7497 - val_loss: 0.6628 - val_accuracy: 0.7404\n",
      "Epoch 23/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.6253 - accuracy: 0.7499 - val_loss: 0.6669 - val_accuracy: 0.7230\n",
      "Epoch 24/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.6119 - accuracy: 0.7511 - val_loss: 0.6519 - val_accuracy: 0.7247\n",
      "Epoch 25/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.6019 - accuracy: 0.7579 - val_loss: 0.6339 - val_accuracy: 0.7282\n",
      "Epoch 26/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5906 - accuracy: 0.7596 - val_loss: 0.6427 - val_accuracy: 0.7195\n",
      "Epoch 27/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5819 - accuracy: 0.7625 - val_loss: 0.6248 - val_accuracy: 0.7369\n",
      "Epoch 28/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5728 - accuracy: 0.7627 - val_loss: 0.6162 - val_accuracy: 0.7422\n",
      "Epoch 29/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5643 - accuracy: 0.7639 - val_loss: 0.6022 - val_accuracy: 0.7352\n",
      "Epoch 30/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5572 - accuracy: 0.7650 - val_loss: 0.5997 - val_accuracy: 0.7352\n",
      "Epoch 31/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5487 - accuracy: 0.7706 - val_loss: 0.5983 - val_accuracy: 0.7387\n",
      "Epoch 32/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5426 - accuracy: 0.7710 - val_loss: 0.5999 - val_accuracy: 0.7352\n",
      "Epoch 33/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5374 - accuracy: 0.7706 - val_loss: 0.5913 - val_accuracy: 0.7352\n",
      "Epoch 34/200\n",
      "162/162 [==============================] - ETA: 0s - loss: 0.5310 - accuracy: 0.7761"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 19:18:26.477365: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5310 - accuracy: 0.7761 - val_loss: 0.5718 - val_accuracy: 0.7491\n",
      "Epoch 35/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5268 - accuracy: 0.7726 - val_loss: 0.5660 - val_accuracy: 0.7544\n",
      "Epoch 36/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5242 - accuracy: 0.7759 - val_loss: 0.5663 - val_accuracy: 0.7561\n",
      "Epoch 37/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5156 - accuracy: 0.7761 - val_loss: 0.5710 - val_accuracy: 0.7526\n",
      "Epoch 38/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5111 - accuracy: 0.7854 - val_loss: 0.5583 - val_accuracy: 0.7596\n",
      "Epoch 39/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5096 - accuracy: 0.7763 - val_loss: 0.5564 - val_accuracy: 0.7596\n",
      "Epoch 40/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5054 - accuracy: 0.7796 - val_loss: 0.5522 - val_accuracy: 0.7596\n",
      "Epoch 41/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5049 - accuracy: 0.7815 - val_loss: 0.5558 - val_accuracy: 0.7474\n",
      "Epoch 42/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5004 - accuracy: 0.7858 - val_loss: 0.5621 - val_accuracy: 0.7439\n",
      "Epoch 43/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4999 - accuracy: 0.7803 - val_loss: 0.5649 - val_accuracy: 0.7387\n",
      "Epoch 44/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4969 - accuracy: 0.7846 - val_loss: 0.5582 - val_accuracy: 0.7456\n",
      "Epoch 45/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4962 - accuracy: 0.7896 - val_loss: 0.5549 - val_accuracy: 0.7526\n",
      "Epoch 46/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4927 - accuracy: 0.7871 - val_loss: 0.5562 - val_accuracy: 0.7439\n",
      "Epoch 47/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4926 - accuracy: 0.7842 - val_loss: 0.5556 - val_accuracy: 0.7456\n",
      "Epoch 48/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4902 - accuracy: 0.7904 - val_loss: 0.5543 - val_accuracy: 0.7474\n",
      "Epoch 49/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4877 - accuracy: 0.7898 - val_loss: 0.5559 - val_accuracy: 0.7509\n",
      "Epoch 50/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4877 - accuracy: 0.7898 - val_loss: 0.5510 - val_accuracy: 0.7439\n",
      "Epoch 51/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4849 - accuracy: 0.7904 - val_loss: 0.5475 - val_accuracy: 0.7544\n",
      "Epoch 52/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4854 - accuracy: 0.7902 - val_loss: 0.5452 - val_accuracy: 0.7648\n",
      "Epoch 53/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4849 - accuracy: 0.7922 - val_loss: 0.5457 - val_accuracy: 0.7648\n",
      "Epoch 54/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4818 - accuracy: 0.7924 - val_loss: 0.5627 - val_accuracy: 0.7439\n",
      "Epoch 55/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4816 - accuracy: 0.7914 - val_loss: 0.5643 - val_accuracy: 0.7439\n",
      "Epoch 56/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4812 - accuracy: 0.7935 - val_loss: 0.5540 - val_accuracy: 0.7509\n",
      "Epoch 57/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4795 - accuracy: 0.7922 - val_loss: 0.5502 - val_accuracy: 0.7491\n",
      "Epoch 58/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4779 - accuracy: 0.7931 - val_loss: 0.5598 - val_accuracy: 0.7456\n",
      "Epoch 59/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4786 - accuracy: 0.7910 - val_loss: 0.5515 - val_accuracy: 0.7509\n",
      "Epoch 60/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4778 - accuracy: 0.7955 - val_loss: 0.5481 - val_accuracy: 0.7561\n",
      "Epoch 61/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4750 - accuracy: 0.7929 - val_loss: 0.5602 - val_accuracy: 0.7439\n",
      "Epoch 62/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4768 - accuracy: 0.7982 - val_loss: 0.5535 - val_accuracy: 0.7491\n",
      "Epoch 63/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4743 - accuracy: 0.7974 - val_loss: 0.5509 - val_accuracy: 0.7439\n",
      "Epoch 64/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4738 - accuracy: 0.7984 - val_loss: 0.5529 - val_accuracy: 0.7526\n",
      "Epoch 65/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4739 - accuracy: 0.7959 - val_loss: 0.5445 - val_accuracy: 0.7526\n",
      "Epoch 66/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4710 - accuracy: 0.7960 - val_loss: 0.5663 - val_accuracy: 0.7422\n",
      "Epoch 67/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4712 - accuracy: 0.7995 - val_loss: 0.5549 - val_accuracy: 0.7404\n",
      "Epoch 68/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4714 - accuracy: 0.7997 - val_loss: 0.5521 - val_accuracy: 0.7544\n",
      "Epoch 69/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4688 - accuracy: 0.8021 - val_loss: 0.5582 - val_accuracy: 0.7456\n",
      "Epoch 70/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4683 - accuracy: 0.7993 - val_loss: 0.5552 - val_accuracy: 0.7387\n",
      "Epoch 71/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4686 - accuracy: 0.7986 - val_loss: 0.5541 - val_accuracy: 0.7526\n",
      "Epoch 72/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4684 - accuracy: 0.7997 - val_loss: 0.5454 - val_accuracy: 0.7526\n",
      "Epoch 73/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4647 - accuracy: 0.8003 - val_loss: 0.5492 - val_accuracy: 0.7526\n",
      "Epoch 74/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4672 - accuracy: 0.8017 - val_loss: 0.5666 - val_accuracy: 0.7317\n",
      "Epoch 75/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4645 - accuracy: 0.8085 - val_loss: 0.5620 - val_accuracy: 0.7474\n",
      "Epoch 76/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4609 - accuracy: 0.8071 - val_loss: 0.5710 - val_accuracy: 0.7387\n",
      "Epoch 77/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4621 - accuracy: 0.8028 - val_loss: 0.5620 - val_accuracy: 0.7491\n",
      "Epoch 78/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4607 - accuracy: 0.8024 - val_loss: 0.5513 - val_accuracy: 0.7491\n",
      "18/18 [==============================] - 1s 14ms/step\n",
      "Sn = 0.747604, Sp = 0.750958, Acc = 0.749129, MCC = 0.496946, AUC = 0.824832\n",
      "****************************** the 2 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 13s 61ms/step - loss: 0.4644 - accuracy: 0.8015 - val_loss: 0.4671 - val_accuracy: 0.8066\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4686 - accuracy: 0.7995 - val_loss: 0.4696 - val_accuracy: 0.7997\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4702 - accuracy: 0.7964 - val_loss: 0.4765 - val_accuracy: 0.8118\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4682 - accuracy: 0.7980 - val_loss: 0.4770 - val_accuracy: 0.7927\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4663 - accuracy: 0.8024 - val_loss: 0.4784 - val_accuracy: 0.7962\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4647 - accuracy: 0.8013 - val_loss: 0.4836 - val_accuracy: 0.8101\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4642 - accuracy: 0.8034 - val_loss: 0.4821 - val_accuracy: 0.7892\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4625 - accuracy: 0.8022 - val_loss: 0.4867 - val_accuracy: 0.7962\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4610 - accuracy: 0.8030 - val_loss: 0.4846 - val_accuracy: 0.7944\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 55ms/step - loss: 0.4634 - accuracy: 0.8032 - val_loss: 0.4869 - val_accuracy: 0.7962\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4602 - accuracy: 0.8071 - val_loss: 0.4938 - val_accuracy: 0.7909\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4576 - accuracy: 0.8059 - val_loss: 0.4921 - val_accuracy: 0.7979\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4567 - accuracy: 0.8086 - val_loss: 0.4981 - val_accuracy: 0.7875\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4568 - accuracy: 0.8038 - val_loss: 0.4989 - val_accuracy: 0.7787\n",
      "18/18 [==============================] - 1s 13ms/step\n",
      "Sn = 0.768421, Sp = 0.788927, Acc = 0.778746, MCC = 0.557501, AUC = 0.862004\n",
      "****************************** the 3 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 13s 62ms/step - loss: 0.4529 - accuracy: 0.8126 - val_loss: 0.4450 - val_accuracy: 0.8185\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4567 - accuracy: 0.8081 - val_loss: 0.4530 - val_accuracy: 0.8150\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4588 - accuracy: 0.8060 - val_loss: 0.4511 - val_accuracy: 0.8098\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4561 - accuracy: 0.8106 - val_loss: 0.4566 - val_accuracy: 0.8028\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4542 - accuracy: 0.8011 - val_loss: 0.4639 - val_accuracy: 0.8028\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4526 - accuracy: 0.8054 - val_loss: 0.4753 - val_accuracy: 0.8010\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 8s 50ms/step - loss: 0.4530 - accuracy: 0.8075 - val_loss: 0.4709 - val_accuracy: 0.8010\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4502 - accuracy: 0.8124 - val_loss: 0.4715 - val_accuracy: 0.8028\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4523 - accuracy: 0.8087 - val_loss: 0.4638 - val_accuracy: 0.8045\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4505 - accuracy: 0.8044 - val_loss: 0.4679 - val_accuracy: 0.7958\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4467 - accuracy: 0.8116 - val_loss: 0.4722 - val_accuracy: 0.7888\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4456 - accuracy: 0.8155 - val_loss: 0.4759 - val_accuracy: 0.7941\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4489 - accuracy: 0.8116 - val_loss: 0.4670 - val_accuracy: 0.7993\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4470 - accuracy: 0.8133 - val_loss: 0.4707 - val_accuracy: 0.7923\n",
      "18/18 [==============================] - 1s 15ms/step\n",
      "Sn = 0.812287, Sp = 0.771429, Acc = 0.792321, MCC = 0.584421, AUC = 0.877462\n",
      "****************************** the 4 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 13s 61ms/step - loss: 0.4430 - accuracy: 0.8170 - val_loss: 0.4066 - val_accuracy: 0.8499\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4492 - accuracy: 0.8143 - val_loss: 0.4148 - val_accuracy: 0.8307\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4501 - accuracy: 0.8095 - val_loss: 0.4177 - val_accuracy: 0.8325\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4482 - accuracy: 0.8079 - val_loss: 0.4280 - val_accuracy: 0.8412\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4448 - accuracy: 0.8100 - val_loss: 0.4372 - val_accuracy: 0.8168\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4453 - accuracy: 0.8098 - val_loss: 0.4346 - val_accuracy: 0.8202\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4456 - accuracy: 0.8139 - val_loss: 0.4310 - val_accuracy: 0.8429\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4443 - accuracy: 0.8118 - val_loss: 0.4400 - val_accuracy: 0.8237\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4449 - accuracy: 0.8145 - val_loss: 0.4317 - val_accuracy: 0.8325\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4376 - accuracy: 0.8176 - val_loss: 0.4400 - val_accuracy: 0.8307\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4418 - accuracy: 0.8182 - val_loss: 0.4460 - val_accuracy: 0.8255\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4362 - accuracy: 0.8162 - val_loss: 0.4466 - val_accuracy: 0.8220\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4369 - accuracy: 0.8226 - val_loss: 0.4380 - val_accuracy: 0.8360\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4376 - accuracy: 0.8215 - val_loss: 0.4431 - val_accuracy: 0.8325\n",
      "18/18 [==============================] - 1s 15ms/step\n",
      "Sn = 0.846154, Sp = 0.818815, Acc = 0.832461, MCC = 0.665196, AUC = 0.895726\n",
      "****************************** the 5 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 12s 61ms/step - loss: 0.4314 - accuracy: 0.8219 - val_loss: 0.4114 - val_accuracy: 0.8290\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4345 - accuracy: 0.8186 - val_loss: 0.4144 - val_accuracy: 0.8307\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4381 - accuracy: 0.8159 - val_loss: 0.4219 - val_accuracy: 0.8307\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4360 - accuracy: 0.8184 - val_loss: 0.4296 - val_accuracy: 0.8202\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4362 - accuracy: 0.8178 - val_loss: 0.4240 - val_accuracy: 0.8325\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4313 - accuracy: 0.8238 - val_loss: 0.4251 - val_accuracy: 0.8255\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4329 - accuracy: 0.8217 - val_loss: 0.4353 - val_accuracy: 0.8115\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4313 - accuracy: 0.8242 - val_loss: 0.4408 - val_accuracy: 0.8080\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4294 - accuracy: 0.8224 - val_loss: 0.4380 - val_accuracy: 0.8168\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4274 - accuracy: 0.8232 - val_loss: 0.4345 - val_accuracy: 0.8168\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4278 - accuracy: 0.8242 - val_loss: 0.4514 - val_accuracy: 0.8098\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4234 - accuracy: 0.8265 - val_loss: 0.4431 - val_accuracy: 0.8185\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4224 - accuracy: 0.8285 - val_loss: 0.4407 - val_accuracy: 0.8202\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4239 - accuracy: 0.8279 - val_loss: 0.4446 - val_accuracy: 0.8098\n",
      "18/18 [==============================] - 1s 16ms/step\n",
      "Sn = 0.845070, Sp = 0.775087, Acc = 0.809773, MCC = 0.621430, AUC = 0.895256\n",
      "****************************** the 6 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 13s 61ms/step - loss: 0.4169 - accuracy: 0.8329 - val_loss: 0.3895 - val_accuracy: 0.8447\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 8s 51ms/step - loss: 0.4251 - accuracy: 0.8230 - val_loss: 0.3915 - val_accuracy: 0.8551\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 8s 48ms/step - loss: 0.4261 - accuracy: 0.8294 - val_loss: 0.4034 - val_accuracy: 0.8412\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 55ms/step - loss: 0.4252 - accuracy: 0.8312 - val_loss: 0.4026 - val_accuracy: 0.8447\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4220 - accuracy: 0.8281 - val_loss: 0.4068 - val_accuracy: 0.8307\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4194 - accuracy: 0.8290 - val_loss: 0.4021 - val_accuracy: 0.8482\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4224 - accuracy: 0.8300 - val_loss: 0.4114 - val_accuracy: 0.8342\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4186 - accuracy: 0.8321 - val_loss: 0.4070 - val_accuracy: 0.8394\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4167 - accuracy: 0.8329 - val_loss: 0.4081 - val_accuracy: 0.8412\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4157 - accuracy: 0.8358 - val_loss: 0.4094 - val_accuracy: 0.8360\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4172 - accuracy: 0.8333 - val_loss: 0.4122 - val_accuracy: 0.8360\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 9s 55ms/step - loss: 0.4099 - accuracy: 0.8383 - val_loss: 0.4155 - val_accuracy: 0.8360\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4130 - accuracy: 0.8385 - val_loss: 0.4164 - val_accuracy: 0.8360\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4156 - accuracy: 0.8370 - val_loss: 0.4116 - val_accuracy: 0.8377\n",
      "18/18 [==============================] - 1s 14ms/step\n",
      "Sn = 0.853659, Sp = 0.821678, Acc = 0.837696, MCC = 0.675707, AUC = 0.913538\n",
      "****************************** the 7 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 13s 62ms/step - loss: 0.4033 - accuracy: 0.8416 - val_loss: 0.3897 - val_accuracy: 0.8394\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4055 - accuracy: 0.8412 - val_loss: 0.4014 - val_accuracy: 0.8290\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4084 - accuracy: 0.8381 - val_loss: 0.4095 - val_accuracy: 0.8307\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4105 - accuracy: 0.8349 - val_loss: 0.4208 - val_accuracy: 0.8115\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4021 - accuracy: 0.8449 - val_loss: 0.4190 - val_accuracy: 0.8202\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4043 - accuracy: 0.8407 - val_loss: 0.4256 - val_accuracy: 0.8098\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4013 - accuracy: 0.8447 - val_loss: 0.4216 - val_accuracy: 0.8185\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4016 - accuracy: 0.8436 - val_loss: 0.4334 - val_accuracy: 0.8063\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.3995 - accuracy: 0.8445 - val_loss: 0.4347 - val_accuracy: 0.8080\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.3948 - accuracy: 0.8484 - val_loss: 0.4361 - val_accuracy: 0.8045\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 55ms/step - loss: 0.3934 - accuracy: 0.8498 - val_loss: 0.4442 - val_accuracy: 0.7958\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.3918 - accuracy: 0.8517 - val_loss: 0.4434 - val_accuracy: 0.8063\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.3915 - accuracy: 0.8494 - val_loss: 0.4414 - val_accuracy: 0.8098\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.3901 - accuracy: 0.8467 - val_loss: 0.4466 - val_accuracy: 0.8080\n",
      "18/18 [==============================] - 1s 15ms/step\n",
      "Sn = 0.831541, Sp = 0.785714, Acc = 0.808028, MCC = 0.617316, AUC = 0.894570\n",
      "****************************** the 8 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 13s 61ms/step - loss: 0.3887 - accuracy: 0.8498 - val_loss: 0.3611 - val_accuracy: 0.8691\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.3921 - accuracy: 0.8482 - val_loss: 0.3718 - val_accuracy: 0.8674\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.3912 - accuracy: 0.8498 - val_loss: 0.3865 - val_accuracy: 0.8621\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 55ms/step - loss: 0.3908 - accuracy: 0.8496 - val_loss: 0.3925 - val_accuracy: 0.8534\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.3922 - accuracy: 0.8463 - val_loss: 0.3916 - val_accuracy: 0.8551\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.3895 - accuracy: 0.8509 - val_loss: 0.4037 - val_accuracy: 0.8360\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.3849 - accuracy: 0.8550 - val_loss: 0.3945 - val_accuracy: 0.8569\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.3841 - accuracy: 0.8517 - val_loss: 0.3985 - val_accuracy: 0.8447\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.3817 - accuracy: 0.8554 - val_loss: 0.4099 - val_accuracy: 0.8482\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.3803 - accuracy: 0.8546 - val_loss: 0.4094 - val_accuracy: 0.8517\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.3789 - accuracy: 0.8548 - val_loss: 0.4201 - val_accuracy: 0.8377\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.3756 - accuracy: 0.8564 - val_loss: 0.4195 - val_accuracy: 0.8412\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 8s 51ms/step - loss: 0.3749 - accuracy: 0.8599 - val_loss: 0.4184 - val_accuracy: 0.8325\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.3734 - accuracy: 0.8620 - val_loss: 0.4200 - val_accuracy: 0.8377\n",
      "18/18 [==============================] - 1s 15ms/step\n",
      "Sn = 0.867797, Sp = 0.805755, Acc = 0.837696, MCC = 0.675532, AUC = 0.912108\n",
      "****************************** the 9 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 13s 63ms/step - loss: 0.3668 - accuracy: 0.8668 - val_loss: 0.3429 - val_accuracy: 0.8796\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.3737 - accuracy: 0.8637 - val_loss: 0.3624 - val_accuracy: 0.8709\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.3706 - accuracy: 0.8614 - val_loss: 0.3729 - val_accuracy: 0.8551\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.3756 - accuracy: 0.8568 - val_loss: 0.3771 - val_accuracy: 0.8604\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.3715 - accuracy: 0.8608 - val_loss: 0.3968 - val_accuracy: 0.8499\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.3685 - accuracy: 0.8632 - val_loss: 0.3852 - val_accuracy: 0.8517\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.3615 - accuracy: 0.8664 - val_loss: 0.3931 - val_accuracy: 0.8551\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.3638 - accuracy: 0.8690 - val_loss: 0.3942 - val_accuracy: 0.8482\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.3604 - accuracy: 0.8661 - val_loss: 0.3988 - val_accuracy: 0.8534\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.3593 - accuracy: 0.8694 - val_loss: 0.4263 - val_accuracy: 0.8255\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.3578 - accuracy: 0.8723 - val_loss: 0.4017 - val_accuracy: 0.8464\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.3519 - accuracy: 0.8717 - val_loss: 0.4263 - val_accuracy: 0.8342\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 9s 55ms/step - loss: 0.3550 - accuracy: 0.8682 - val_loss: 0.4135 - val_accuracy: 0.8360\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.3490 - accuracy: 0.8752 - val_loss: 0.4168 - val_accuracy: 0.8447\n",
      "18/18 [==============================] - 1s 15ms/step\n",
      "Sn = 0.880435, Sp = 0.811448, Acc = 0.844677, MCC = 0.692077, AUC = 0.916008\n",
      "****************************** the 10 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 12s 60ms/step - loss: 0.3456 - accuracy: 0.8763 - val_loss: 0.3511 - val_accuracy: 0.8778\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.3489 - accuracy: 0.8742 - val_loss: 0.3592 - val_accuracy: 0.8743\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.3517 - accuracy: 0.8754 - val_loss: 0.3730 - val_accuracy: 0.8604\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.3515 - accuracy: 0.8730 - val_loss: 0.3766 - val_accuracy: 0.8691\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.3442 - accuracy: 0.8769 - val_loss: 0.3833 - val_accuracy: 0.8621\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.3431 - accuracy: 0.8789 - val_loss: 0.3925 - val_accuracy: 0.8674\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.3417 - accuracy: 0.8820 - val_loss: 0.3903 - val_accuracy: 0.8639\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 55ms/step - loss: 0.3395 - accuracy: 0.8787 - val_loss: 0.4000 - val_accuracy: 0.8551\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.3355 - accuracy: 0.8816 - val_loss: 0.4124 - val_accuracy: 0.8569\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.3304 - accuracy: 0.8866 - val_loss: 0.4050 - val_accuracy: 0.8482\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.3265 - accuracy: 0.8862 - val_loss: 0.4120 - val_accuracy: 0.8517\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.3289 - accuracy: 0.8866 - val_loss: 0.4178 - val_accuracy: 0.8499\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.3276 - accuracy: 0.8895 - val_loss: 0.4242 - val_accuracy: 0.8447\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.3233 - accuracy: 0.8905 - val_loss: 0.4311 - val_accuracy: 0.8360\n",
      "18/18 [==============================] - 1s 14ms/step\n",
      "Sn = 0.847015, Sp = 0.826230, Acc = 0.835951, MCC = 0.672012, AUC = 0.915647\n",
      "10 fold result: [[0.74760383 0.75095785 0.74912892 0.49694621 0.82483199]\n",
      " [0.76842105 0.78892733 0.77874564 0.5575007  0.86200449]\n",
      " [0.81228669 0.77142857 0.79232112 0.58442092 0.87746221]\n",
      " [0.84615384 0.81881533 0.83246073 0.66519613 0.89572622]\n",
      " [0.84507042 0.7750865  0.80977312 0.62143023 0.89525562]\n",
      " [0.85365853 0.82167832 0.83769634 0.6757074  0.91353768]\n",
      " [0.83154122 0.78571428 0.80802792 0.61731571 0.89457001]\n",
      " [0.86779661 0.80575539 0.83769634 0.67553183 0.91210828]\n",
      " [0.88043478 0.81144781 0.84467714 0.69207681 0.91600791]\n",
      " [0.84701492 0.82622951 0.83595113 0.67201236 0.91564717]]\n",
      "Sn = 0.8300 ± 0.0403\n",
      "Sp = 0.7956 ± 0.0238\n",
      "Acc = 0.8126 ± 0.0297\n",
      "Mcc = 0.6258 ± 0.0601\n",
      "Auc = 0.8907 ± 0.0276\n",
      "Epoch 1/200\n",
      "180/180 [==============================] - 12s 54ms/step - loss: 0.3327 - accuracy: 0.8854 - val_loss: 0.6546 - val_accuracy: 0.7390\n",
      "Epoch 2/200\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.3324 - accuracy: 0.8843"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 19:44:19.602488: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 9s 49ms/step - loss: 0.3324 - accuracy: 0.8843 - val_loss: 0.6547 - val_accuracy: 0.7390\n",
      "Epoch 3/200\n",
      "180/180 [==============================] - 9s 48ms/step - loss: 0.3263 - accuracy: 0.8904 - val_loss: 0.6525 - val_accuracy: 0.7343\n",
      "Epoch 4/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3264 - accuracy: 0.8920 - val_loss: 0.6421 - val_accuracy: 0.7500\n",
      "Epoch 5/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3195 - accuracy: 0.8892 - val_loss: 0.6428 - val_accuracy: 0.7657\n",
      "Epoch 6/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3147 - accuracy: 0.8974 - val_loss: 0.6625 - val_accuracy: 0.7563\n",
      "Epoch 7/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3191 - accuracy: 0.8945 - val_loss: 0.6559 - val_accuracy: 0.7547\n",
      "Epoch 8/200\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.3154 - accuracy: 0.8938 - val_loss: 0.6704 - val_accuracy: 0.7327\n",
      "Epoch 9/200\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.3122 - accuracy: 0.8948 - val_loss: 0.6819 - val_accuracy: 0.7374\n",
      "Epoch 10/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3104 - accuracy: 0.8964 - val_loss: 0.6917 - val_accuracy: 0.7421\n",
      "Epoch 11/200\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.3068 - accuracy: 0.9009 - val_loss: 0.6846 - val_accuracy: 0.7311\n",
      "Epoch 12/200\n",
      "180/180 [==============================] - 9s 48ms/step - loss: 0.3075 - accuracy: 0.8972 - val_loss: 0.6890 - val_accuracy: 0.7358\n",
      "Epoch 13/200\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.3061 - accuracy: 0.8957 - val_loss: 0.6987 - val_accuracy: 0.7374\n",
      "Epoch 14/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.3046 - accuracy: 0.9033 - val_loss: 0.7205 - val_accuracy: 0.7233\n",
      "Epoch 15/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.2983 - accuracy: 0.8999 - val_loss: 0.7188 - val_accuracy: 0.7311\n",
      "Epoch 16/200\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.2966 - accuracy: 0.9046 - val_loss: 0.7401 - val_accuracy: 0.7469\n",
      "Epoch 17/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.2991 - accuracy: 0.9018 - val_loss: 0.7235 - val_accuracy: 0.7264\n",
      "Epoch 18/200\n",
      "180/180 [==============================] - 9s 47ms/step - loss: 0.2927 - accuracy: 0.9074 - val_loss: 0.7524 - val_accuracy: 0.7327\n",
      "Epoch 19/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.2852 - accuracy: 0.9096 - val_loss: 0.7415 - val_accuracy: 0.7437\n",
      "Epoch 20/200\n",
      "180/180 [==============================] - 9s 47ms/step - loss: 0.2869 - accuracy: 0.9138 - val_loss: 0.7519 - val_accuracy: 0.7453\n",
      "Epoch 21/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.2875 - accuracy: 0.9072 - val_loss: 0.7522 - val_accuracy: 0.7343\n",
      "Epoch 22/200\n",
      "180/180 [==============================] - 9s 48ms/step - loss: 0.2849 - accuracy: 0.9105 - val_loss: 0.7662 - val_accuracy: 0.7421\n",
      "Epoch 23/200\n",
      "180/180 [==============================] - 9s 48ms/step - loss: 0.2783 - accuracy: 0.9115 - val_loss: 0.7718 - val_accuracy: 0.7311\n",
      "Epoch 24/200\n",
      "180/180 [==============================] - 9s 48ms/step - loss: 0.2792 - accuracy: 0.9110 - val_loss: 0.7609 - val_accuracy: 0.7421\n",
      "20/20 [==============================] - 1s 14ms/step\n",
      "-----------------------------------------------test---------------------------------------\n",
      "Sn = 0.720126, Sp = 0.764151, Acc = 0.742138, MCC = 0.484747, AUC = 0.816977\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "tf.random.set_seed(1)  # for reproducibility\n",
    "# reading model\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 200\n",
    "\n",
    "# # Cross-validation\n",
    "n = 10\n",
    "k_fold = KFold(n_splits=n, shuffle=True, random_state=42)\n",
    "\n",
    "all_performance = []\n",
    "tprs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "for fold_count, (train_index, val_index) in enumerate(k_fold.split(train)):\n",
    "    print('*' * 30 + ' the ' + str(fold_count + 1) + ' fold ' + '*' * 30)\n",
    "    trains, val = train[train_index], train[val_index]\n",
    "    trains_label, val_label = train_label[train_index], train_label[val_index]\n",
    "    zaoting = EarlyStopping(monitor='val_loss', patience=13, mode='auto')\n",
    "    xuexilv = WarmupExponentialDecay(lr_base=0.0002,decay=0.00002,warmup_epochs=2)\n",
    "    callback_lists=[xuexilv,zaoting]\n",
    "    model.fit(x=trains, y=trains_label, validation_data=(val, val_label), epochs=EPOCHS,\n",
    "                batch_size=BATCH_SIZE, shuffle=True,\n",
    "                callbacks=callback_lists,\n",
    "                verbose=1)\n",
    "     # 保存模型\n",
    "\n",
    "    model.save('./warmup_embedding/model_fold' + str(fold_count+1) + '.h5')\n",
    "\n",
    "    del model\n",
    "\n",
    "    model = load_model('./warmup_embedding/model_fold' + str(fold_count+1) + '.h5')\n",
    "\n",
    "    val_pred = model.predict(val, verbose=1)\n",
    "\n",
    "    # Sn, Sp, Acc, MCC, AUC\n",
    "    Sn, Sp, Acc, MCC = show_performance(val_label[:, 1], val_pred[:, 1])\n",
    "    AUC = roc_auc_score(val_label[:, 1], val_pred[:, 1])\n",
    "    print('Sn = %f, Sp = %f, Acc = %f, MCC = %f, AUC = %f' % (Sn, Sp, Acc, MCC, AUC))\n",
    "\n",
    "    performance = [Sn, Sp, Acc, MCC, AUC]\n",
    "    all_performance.append(performance)\n",
    "    \n",
    "all_performance = np.array(all_performance)\n",
    "print('10 fold result:', all_performance)\n",
    "performance_mean = performance_mean(all_performance)\n",
    "\n",
    "model.fit(x=train, y=train_label, validation_data=(test, test_label), epochs=EPOCHS,\n",
    "                      batch_size=BATCH_SIZE, shuffle=True,\n",
    "                      callbacks=[EarlyStopping(monitor='val_loss', patience=20, mode='auto')],\n",
    "                      verbose=1)\n",
    "model.save('./warmup_embedding/model_test.h5')\n",
    "\n",
    "del model\n",
    "\n",
    "model = load_model('./warmup_embedding/model_test.h5')\n",
    "\n",
    "test_score = model.predict(test)\n",
    "\n",
    "\n",
    "# Sn, Sp, Acc, MCC, AUC\n",
    "Sn, Sp, Acc, MCC = show_performance(test_label[:,1], test_score[:,1])\n",
    "AUC = roc_auc_score(test_label[:,1], test_score[:,1])\n",
    "\n",
    "print('-----------------------------------------------test---------------------------------------')\n",
    "print('Sn = %f, Sp = %f, Acc = %f, MCC = %f, AUC = %f' % (Sn, Sp, Acc, MCC, AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d5f5ff1-9061-4fb0-b35c-599e5333fd90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************Warmup+embedding_128******************************\n",
      "(None, 15, 128)\n",
      "(None, 15, 48)\n",
      "****************************** the 1 fold ******************************\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 18:31:40.905151: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8800\n",
      "Could not load symbol cublasGetSmCountTarget from libcublas.so.11. Error: /usr/local/cuda/targets/x86_64-linux/lib/libcublas.so.11: undefined symbol: cublasGetSmCountTarget\n",
      "2024-06-05 18:31:41.187895: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-06-05 18:31:41.226247: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560efccbbef0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-05 18:31:41.226270: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-06-05 18:31:41.230228: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-06-05 18:31:41.283245: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-05 18:31:41.284555: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:231] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.6\n",
      "2024-06-05 18:31:41.284597: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:234] Used ptxas at ptxas\n",
      "2024-06-05 18:31:41.317175: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-06-05 18:31:41.386645: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/162 [..............................] - ETA: 22:21 - loss: 3.2359 - accuracy: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 18:31:41.878539: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-05 18:31:41.899499: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-05 18:31:41.901901: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-05 18:31:41.942265: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-05 18:31:42.013506: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4/162 [..............................] - ETA: 14s - loss: 3.2350 - accuracy: 0.5703 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 18:31:42.190365: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 19/162 [==>...........................] - ETA: 8s - loss: 3.2339 - accuracy: 0.5724"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 18:31:43.108112: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 23/162 [===>..........................] - ETA: 8s - loss: 3.2335 - accuracy: 0.5598"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 18:31:43.315177: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 18s 61ms/step - loss: 3.1501 - accuracy: 0.5675 - val_loss: 2.9816 - val_accuracy: 0.6185\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 2.6890 - accuracy: 0.6245 - val_loss: 2.3396 - val_accuracy: 0.6603\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 2.0486 - accuracy: 0.6605 - val_loss: 1.8185 - val_accuracy: 0.6533\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 1.6295 - accuracy: 0.6640 - val_loss: 1.4822 - val_accuracy: 0.6742\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 1.3620 - accuracy: 0.6677 - val_loss: 1.2695 - val_accuracy: 0.6847\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 1.1890 - accuracy: 0.6710 - val_loss: 1.1352 - val_accuracy: 0.6794\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - ETA: 0s - loss: 1.0752 - accuracy: 0.6687"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 18:32:43.152362: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 9s 55ms/step - loss: 1.0752 - accuracy: 0.6687 - val_loss: 1.0357 - val_accuracy: 0.6794\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.9990 - accuracy: 0.6716 - val_loss: 0.9830 - val_accuracy: 0.6794\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.9444 - accuracy: 0.6791 - val_loss: 0.9310 - val_accuracy: 0.6777\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.9012 - accuracy: 0.6807 - val_loss: 0.9015 - val_accuracy: 0.6812\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.8657 - accuracy: 0.6850 - val_loss: 0.8642 - val_accuracy: 0.6916\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.8321 - accuracy: 0.6927 - val_loss: 0.8364 - val_accuracy: 0.6847\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.8043 - accuracy: 0.7010 - val_loss: 0.8091 - val_accuracy: 0.6986\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.7804 - accuracy: 0.7080 - val_loss: 0.7840 - val_accuracy: 0.7108\n",
      "Epoch 15/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.7570 - accuracy: 0.7148 - val_loss: 0.7719 - val_accuracy: 0.7056\n",
      "Epoch 16/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.7368 - accuracy: 0.7241 - val_loss: 0.7430 - val_accuracy: 0.7317\n",
      "Epoch 17/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.7193 - accuracy: 0.7245 - val_loss: 0.7346 - val_accuracy: 0.7091\n",
      "Epoch 18/200\n",
      "162/162 [==============================] - ETA: 0s - loss: 0.7004 - accuracy: 0.7317"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 18:34:18.330185: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 9s 53ms/step - loss: 0.7004 - accuracy: 0.7317 - val_loss: 0.7189 - val_accuracy: 0.7230\n",
      "Epoch 19/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.6840 - accuracy: 0.7319 - val_loss: 0.7067 - val_accuracy: 0.7125\n",
      "Epoch 20/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.6691 - accuracy: 0.7373 - val_loss: 0.6877 - val_accuracy: 0.7230\n",
      "Epoch 21/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.6537 - accuracy: 0.7420 - val_loss: 0.6782 - val_accuracy: 0.7230\n",
      "Epoch 22/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.6431 - accuracy: 0.7439 - val_loss: 0.6595 - val_accuracy: 0.7265\n",
      "Epoch 23/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.6307 - accuracy: 0.7441 - val_loss: 0.6604 - val_accuracy: 0.7160\n",
      "Epoch 24/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.6196 - accuracy: 0.7458 - val_loss: 0.6452 - val_accuracy: 0.7404\n",
      "Epoch 25/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.6088 - accuracy: 0.7497 - val_loss: 0.6296 - val_accuracy: 0.7369\n",
      "Epoch 26/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5963 - accuracy: 0.7542 - val_loss: 0.6321 - val_accuracy: 0.7213\n",
      "Epoch 27/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5871 - accuracy: 0.7553 - val_loss: 0.6237 - val_accuracy: 0.7247\n",
      "Epoch 28/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5792 - accuracy: 0.7563 - val_loss: 0.6089 - val_accuracy: 0.7352\n",
      "Epoch 29/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5690 - accuracy: 0.7571 - val_loss: 0.6003 - val_accuracy: 0.7422\n",
      "Epoch 30/200\n",
      "162/162 [==============================] - 8s 51ms/step - loss: 0.5632 - accuracy: 0.7592 - val_loss: 0.5872 - val_accuracy: 0.7474\n",
      "Epoch 31/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5580 - accuracy: 0.7590 - val_loss: 0.5952 - val_accuracy: 0.7352\n",
      "Epoch 32/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5508 - accuracy: 0.7608 - val_loss: 0.5917 - val_accuracy: 0.7334\n",
      "Epoch 33/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5455 - accuracy: 0.7613 - val_loss: 0.5829 - val_accuracy: 0.7352\n",
      "Epoch 34/200\n",
      "162/162 [==============================] - ETA: 0s - loss: 0.5414 - accuracy: 0.7619"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 18:36:36.164591: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5414 - accuracy: 0.7619 - val_loss: 0.5687 - val_accuracy: 0.7544\n",
      "Epoch 35/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5370 - accuracy: 0.7625 - val_loss: 0.5566 - val_accuracy: 0.7613\n",
      "Epoch 36/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5325 - accuracy: 0.7631 - val_loss: 0.5617 - val_accuracy: 0.7491\n",
      "Epoch 37/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5278 - accuracy: 0.7658 - val_loss: 0.5696 - val_accuracy: 0.7317\n",
      "Epoch 38/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5240 - accuracy: 0.7637 - val_loss: 0.5565 - val_accuracy: 0.7544\n",
      "Epoch 39/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5235 - accuracy: 0.7652 - val_loss: 0.5497 - val_accuracy: 0.7578\n",
      "Epoch 40/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5187 - accuracy: 0.7660 - val_loss: 0.5491 - val_accuracy: 0.7561\n",
      "Epoch 41/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5170 - accuracy: 0.7675 - val_loss: 0.5472 - val_accuracy: 0.7544\n",
      "Epoch 42/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5152 - accuracy: 0.7697 - val_loss: 0.5599 - val_accuracy: 0.7439\n",
      "Epoch 43/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5101 - accuracy: 0.7712 - val_loss: 0.5570 - val_accuracy: 0.7422\n",
      "Epoch 44/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5110 - accuracy: 0.7679 - val_loss: 0.5535 - val_accuracy: 0.7352\n",
      "Epoch 45/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5099 - accuracy: 0.7705 - val_loss: 0.5421 - val_accuracy: 0.7456\n",
      "Epoch 46/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5059 - accuracy: 0.7747 - val_loss: 0.5575 - val_accuracy: 0.7282\n",
      "Epoch 47/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5061 - accuracy: 0.7770 - val_loss: 0.5473 - val_accuracy: 0.7387\n",
      "Epoch 48/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5075 - accuracy: 0.7767 - val_loss: 0.5380 - val_accuracy: 0.7561\n",
      "Epoch 49/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5018 - accuracy: 0.7800 - val_loss: 0.5515 - val_accuracy: 0.7404\n",
      "Epoch 50/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5042 - accuracy: 0.7759 - val_loss: 0.5411 - val_accuracy: 0.7439\n",
      "Epoch 51/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5005 - accuracy: 0.7739 - val_loss: 0.5462 - val_accuracy: 0.7456\n",
      "Epoch 52/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5006 - accuracy: 0.7774 - val_loss: 0.5384 - val_accuracy: 0.7474\n",
      "Epoch 53/200\n",
      "162/162 [==============================] - 9s 55ms/step - loss: 0.4985 - accuracy: 0.7772 - val_loss: 0.5369 - val_accuracy: 0.7509\n",
      "Epoch 54/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4970 - accuracy: 0.7854 - val_loss: 0.5562 - val_accuracy: 0.7352\n",
      "Epoch 55/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4975 - accuracy: 0.7770 - val_loss: 0.5658 - val_accuracy: 0.7195\n",
      "Epoch 56/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5001 - accuracy: 0.7772 - val_loss: 0.5498 - val_accuracy: 0.7317\n",
      "Epoch 57/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4977 - accuracy: 0.7784 - val_loss: 0.5388 - val_accuracy: 0.7474\n",
      "Epoch 58/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4945 - accuracy: 0.7807 - val_loss: 0.5556 - val_accuracy: 0.7369\n",
      "Epoch 59/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4950 - accuracy: 0.7788 - val_loss: 0.5401 - val_accuracy: 0.7509\n",
      "Epoch 60/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4928 - accuracy: 0.7813 - val_loss: 0.5539 - val_accuracy: 0.7422\n",
      "Epoch 61/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4910 - accuracy: 0.7829 - val_loss: 0.5556 - val_accuracy: 0.7317\n",
      "Epoch 62/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4920 - accuracy: 0.7803 - val_loss: 0.5383 - val_accuracy: 0.7526\n",
      "Epoch 63/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4886 - accuracy: 0.7850 - val_loss: 0.5457 - val_accuracy: 0.7404\n",
      "Epoch 64/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4917 - accuracy: 0.7819 - val_loss: 0.5445 - val_accuracy: 0.7491\n",
      "Epoch 65/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4899 - accuracy: 0.7838 - val_loss: 0.5321 - val_accuracy: 0.7544\n",
      "Epoch 66/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4901 - accuracy: 0.7788 - val_loss: 0.5442 - val_accuracy: 0.7456\n",
      "Epoch 67/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4881 - accuracy: 0.7811 - val_loss: 0.5477 - val_accuracy: 0.7422\n",
      "Epoch 68/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4897 - accuracy: 0.7850 - val_loss: 0.5457 - val_accuracy: 0.7491\n",
      "Epoch 69/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4881 - accuracy: 0.7827 - val_loss: 0.5454 - val_accuracy: 0.7439\n",
      "Epoch 70/200\n",
      "162/162 [==============================] - 8s 51ms/step - loss: 0.4845 - accuracy: 0.7862 - val_loss: 0.5380 - val_accuracy: 0.7474\n",
      "Epoch 71/200\n",
      "162/162 [==============================] - 8s 50ms/step - loss: 0.4867 - accuracy: 0.7865 - val_loss: 0.5360 - val_accuracy: 0.7561\n",
      "Epoch 72/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4862 - accuracy: 0.7844 - val_loss: 0.5307 - val_accuracy: 0.7683\n",
      "Epoch 73/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4864 - accuracy: 0.7834 - val_loss: 0.5316 - val_accuracy: 0.7456\n",
      "Epoch 74/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4857 - accuracy: 0.7873 - val_loss: 0.5442 - val_accuracy: 0.7474\n",
      "Epoch 75/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4862 - accuracy: 0.7898 - val_loss: 0.5471 - val_accuracy: 0.7456\n",
      "Epoch 76/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4830 - accuracy: 0.7844 - val_loss: 0.5394 - val_accuracy: 0.7422\n",
      "Epoch 77/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4831 - accuracy: 0.7873 - val_loss: 0.5454 - val_accuracy: 0.7509\n",
      "Epoch 78/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4826 - accuracy: 0.7887 - val_loss: 0.5289 - val_accuracy: 0.7491\n",
      "Epoch 79/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4838 - accuracy: 0.7838 - val_loss: 0.5418 - val_accuracy: 0.7474\n",
      "Epoch 80/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4802 - accuracy: 0.7854 - val_loss: 0.5390 - val_accuracy: 0.7509\n",
      "Epoch 81/200\n",
      "162/162 [==============================] - 8s 51ms/step - loss: 0.4823 - accuracy: 0.7891 - val_loss: 0.5283 - val_accuracy: 0.7526\n",
      "Epoch 82/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4803 - accuracy: 0.7867 - val_loss: 0.5527 - val_accuracy: 0.7491\n",
      "Epoch 83/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4804 - accuracy: 0.7848 - val_loss: 0.5258 - val_accuracy: 0.7491\n",
      "Epoch 84/200\n",
      "162/162 [==============================] - 9s 55ms/step - loss: 0.4810 - accuracy: 0.7873 - val_loss: 0.5446 - val_accuracy: 0.7509\n",
      "Epoch 85/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4759 - accuracy: 0.7949 - val_loss: 0.5291 - val_accuracy: 0.7561\n",
      "Epoch 86/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4781 - accuracy: 0.7871 - val_loss: 0.5294 - val_accuracy: 0.7613\n",
      "Epoch 87/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4792 - accuracy: 0.7865 - val_loss: 0.5306 - val_accuracy: 0.7544\n",
      "Epoch 88/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4761 - accuracy: 0.7914 - val_loss: 0.5304 - val_accuracy: 0.7474\n",
      "Epoch 89/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4749 - accuracy: 0.7896 - val_loss: 0.5425 - val_accuracy: 0.7561\n",
      "Epoch 90/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4765 - accuracy: 0.7883 - val_loss: 0.5307 - val_accuracy: 0.7561\n",
      "Epoch 91/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4747 - accuracy: 0.7885 - val_loss: 0.5494 - val_accuracy: 0.7387\n",
      "Epoch 92/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4742 - accuracy: 0.7912 - val_loss: 0.5349 - val_accuracy: 0.7544\n",
      "Epoch 93/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4763 - accuracy: 0.7900 - val_loss: 0.5355 - val_accuracy: 0.7509\n",
      "Epoch 94/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4729 - accuracy: 0.7898 - val_loss: 0.5207 - val_accuracy: 0.7578\n",
      "Epoch 95/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4736 - accuracy: 0.7914 - val_loss: 0.5268 - val_accuracy: 0.7544\n",
      "Epoch 96/200\n",
      "162/162 [==============================] - 9s 55ms/step - loss: 0.4732 - accuracy: 0.7922 - val_loss: 0.5212 - val_accuracy: 0.7474\n",
      "Epoch 97/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4724 - accuracy: 0.7912 - val_loss: 0.5486 - val_accuracy: 0.7422\n",
      "Epoch 98/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4689 - accuracy: 0.7914 - val_loss: 0.5244 - val_accuracy: 0.7474\n",
      "Epoch 99/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4694 - accuracy: 0.7935 - val_loss: 0.5499 - val_accuracy: 0.7474\n",
      "Epoch 100/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4699 - accuracy: 0.7891 - val_loss: 0.5359 - val_accuracy: 0.7456\n",
      "Epoch 101/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4682 - accuracy: 0.7922 - val_loss: 0.5253 - val_accuracy: 0.7526\n",
      "Epoch 102/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4704 - accuracy: 0.7914 - val_loss: 0.5323 - val_accuracy: 0.7526\n",
      "Epoch 103/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4691 - accuracy: 0.7926 - val_loss: 0.5353 - val_accuracy: 0.7474\n",
      "Epoch 104/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4684 - accuracy: 0.7941 - val_loss: 0.5402 - val_accuracy: 0.7509\n",
      "Epoch 105/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4685 - accuracy: 0.7922 - val_loss: 0.5349 - val_accuracy: 0.7561\n",
      "Epoch 106/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4683 - accuracy: 0.7935 - val_loss: 0.5307 - val_accuracy: 0.7526\n",
      "Epoch 107/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4682 - accuracy: 0.7964 - val_loss: 0.5247 - val_accuracy: 0.7509\n",
      "18/18 [==============================] - 1s 15ms/step\n",
      "Sn = 0.753994, Sp = 0.747126, Acc = 0.750871, MCC = 0.499742, AUC = 0.838138\n",
      "****************************** the 2 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 13s 61ms/step - loss: 0.4694 - accuracy: 0.7910 - val_loss: 0.4786 - val_accuracy: 0.7857\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4732 - accuracy: 0.7883 - val_loss: 0.4799 - val_accuracy: 0.7979\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4760 - accuracy: 0.7910 - val_loss: 0.4874 - val_accuracy: 0.7857\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4727 - accuracy: 0.7910 - val_loss: 0.4915 - val_accuracy: 0.7787\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4721 - accuracy: 0.7910 - val_loss: 0.4881 - val_accuracy: 0.7822\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4707 - accuracy: 0.7937 - val_loss: 0.5031 - val_accuracy: 0.7822\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4687 - accuracy: 0.7970 - val_loss: 0.4911 - val_accuracy: 0.7787\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4689 - accuracy: 0.7918 - val_loss: 0.4908 - val_accuracy: 0.7770\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4685 - accuracy: 0.7910 - val_loss: 0.4925 - val_accuracy: 0.7770\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 55ms/step - loss: 0.4695 - accuracy: 0.7900 - val_loss: 0.4987 - val_accuracy: 0.7718\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4684 - accuracy: 0.7931 - val_loss: 0.5027 - val_accuracy: 0.7683\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4638 - accuracy: 0.7960 - val_loss: 0.4967 - val_accuracy: 0.7700\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4665 - accuracy: 0.7914 - val_loss: 0.5105 - val_accuracy: 0.7561\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4670 - accuracy: 0.7937 - val_loss: 0.5033 - val_accuracy: 0.7683\n",
      "18/18 [==============================] - 1s 20ms/step\n",
      "Sn = 0.747368, Sp = 0.788927, Acc = 0.768293, MCC = 0.536834, AUC = 0.853785\n",
      "****************************** the 3 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 13s 61ms/step - loss: 0.4625 - accuracy: 0.7967 - val_loss: 0.4620 - val_accuracy: 0.7784\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4653 - accuracy: 0.7963 - val_loss: 0.4677 - val_accuracy: 0.7836\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4652 - accuracy: 0.8002 - val_loss: 0.4710 - val_accuracy: 0.7749\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4675 - accuracy: 0.7951 - val_loss: 0.4702 - val_accuracy: 0.7714\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4650 - accuracy: 0.7951 - val_loss: 0.4817 - val_accuracy: 0.7801\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4657 - accuracy: 0.7967 - val_loss: 0.4831 - val_accuracy: 0.7714\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4631 - accuracy: 0.7998 - val_loss: 0.4780 - val_accuracy: 0.7609\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4660 - accuracy: 0.7967 - val_loss: 0.4837 - val_accuracy: 0.7766\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4662 - accuracy: 0.7959 - val_loss: 0.4792 - val_accuracy: 0.7574\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4614 - accuracy: 0.7961 - val_loss: 0.4779 - val_accuracy: 0.7784\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4600 - accuracy: 0.8013 - val_loss: 0.4805 - val_accuracy: 0.7766\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4593 - accuracy: 0.7996 - val_loss: 0.4907 - val_accuracy: 0.7784\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4580 - accuracy: 0.7992 - val_loss: 0.4823 - val_accuracy: 0.7731\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4609 - accuracy: 0.8000 - val_loss: 0.4886 - val_accuracy: 0.7557\n",
      "18/18 [==============================] - 1s 14ms/step\n",
      "Sn = 0.795222, Sp = 0.714286, Acc = 0.755672, MCC = 0.511569, AUC = 0.859556\n",
      "****************************** the 4 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 13s 62ms/step - loss: 0.4582 - accuracy: 0.7996 - val_loss: 0.4249 - val_accuracy: 0.8220\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4648 - accuracy: 0.7947 - val_loss: 0.4317 - val_accuracy: 0.8185\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4630 - accuracy: 0.7949 - val_loss: 0.4352 - val_accuracy: 0.8185\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4634 - accuracy: 0.7943 - val_loss: 0.4377 - val_accuracy: 0.8237\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4601 - accuracy: 0.7943 - val_loss: 0.4481 - val_accuracy: 0.8045\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4624 - accuracy: 0.7945 - val_loss: 0.4469 - val_accuracy: 0.8133\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4587 - accuracy: 0.8003 - val_loss: 0.4430 - val_accuracy: 0.8115\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4621 - accuracy: 0.7972 - val_loss: 0.4437 - val_accuracy: 0.8133\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4607 - accuracy: 0.7957 - val_loss: 0.4428 - val_accuracy: 0.8133\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4556 - accuracy: 0.8021 - val_loss: 0.4452 - val_accuracy: 0.8063\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4580 - accuracy: 0.8054 - val_loss: 0.4497 - val_accuracy: 0.8115\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4579 - accuracy: 0.7984 - val_loss: 0.4498 - val_accuracy: 0.8028\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4576 - accuracy: 0.8046 - val_loss: 0.4457 - val_accuracy: 0.8150\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4577 - accuracy: 0.8011 - val_loss: 0.4472 - val_accuracy: 0.8080\n",
      "18/18 [==============================] - 1s 16ms/step\n",
      "Sn = 0.807692, Sp = 0.808362, Acc = 0.808028, MCC = 0.616055, AUC = 0.887198\n",
      "****************************** the 5 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 12s 60ms/step - loss: 0.4479 - accuracy: 0.8067 - val_loss: 0.4415 - val_accuracy: 0.8080\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 9s 55ms/step - loss: 0.4515 - accuracy: 0.8007 - val_loss: 0.4493 - val_accuracy: 0.8063\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4544 - accuracy: 0.8005 - val_loss: 0.4549 - val_accuracy: 0.7976\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4535 - accuracy: 0.8046 - val_loss: 0.4639 - val_accuracy: 0.7993\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4541 - accuracy: 0.8017 - val_loss: 0.4546 - val_accuracy: 0.8028\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4528 - accuracy: 0.8036 - val_loss: 0.4612 - val_accuracy: 0.8010\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4513 - accuracy: 0.8025 - val_loss: 0.4639 - val_accuracy: 0.7923\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4500 - accuracy: 0.8079 - val_loss: 0.4599 - val_accuracy: 0.8010\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4507 - accuracy: 0.8056 - val_loss: 0.4616 - val_accuracy: 0.7993\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4502 - accuracy: 0.8064 - val_loss: 0.4650 - val_accuracy: 0.8010\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4513 - accuracy: 0.8083 - val_loss: 0.4676 - val_accuracy: 0.7976\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4482 - accuracy: 0.8116 - val_loss: 0.4641 - val_accuracy: 0.7958\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4469 - accuracy: 0.8066 - val_loss: 0.4664 - val_accuracy: 0.7923\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4480 - accuracy: 0.8106 - val_loss: 0.4710 - val_accuracy: 0.7888\n",
      "18/18 [==============================] - 1s 14ms/step\n",
      "Sn = 0.852113, Sp = 0.726644, Acc = 0.788831, MCC = 0.582976, AUC = 0.875250\n",
      "****************************** the 6 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 13s 62ms/step - loss: 0.4449 - accuracy: 0.8110 - val_loss: 0.4245 - val_accuracy: 0.8168\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4466 - accuracy: 0.8097 - val_loss: 0.4274 - val_accuracy: 0.8115\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 9s 55ms/step - loss: 0.4514 - accuracy: 0.8083 - val_loss: 0.4378 - val_accuracy: 0.8150\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4502 - accuracy: 0.8064 - val_loss: 0.4409 - val_accuracy: 0.8098\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4471 - accuracy: 0.8114 - val_loss: 0.4389 - val_accuracy: 0.8150\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4477 - accuracy: 0.8104 - val_loss: 0.4368 - val_accuracy: 0.8045\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4442 - accuracy: 0.8178 - val_loss: 0.4434 - val_accuracy: 0.8150\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4460 - accuracy: 0.8104 - val_loss: 0.4424 - val_accuracy: 0.7958\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4457 - accuracy: 0.8128 - val_loss: 0.4471 - val_accuracy: 0.7993\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4437 - accuracy: 0.8052 - val_loss: 0.4443 - val_accuracy: 0.8185\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4439 - accuracy: 0.8114 - val_loss: 0.4461 - val_accuracy: 0.8133\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4425 - accuracy: 0.8126 - val_loss: 0.4461 - val_accuracy: 0.7976\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4456 - accuracy: 0.8147 - val_loss: 0.4513 - val_accuracy: 0.8045\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4431 - accuracy: 0.8126 - val_loss: 0.4513 - val_accuracy: 0.7958\n",
      "18/18 [==============================] - 1s 15ms/step\n",
      "Sn = 0.857143, Sp = 0.734266, Acc = 0.795812, MCC = 0.596001, AUC = 0.885480\n",
      "****************************** the 7 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 13s 62ms/step - loss: 0.4364 - accuracy: 0.8137 - val_loss: 0.4214 - val_accuracy: 0.8202\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4421 - accuracy: 0.8172 - val_loss: 0.4294 - val_accuracy: 0.8185\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4442 - accuracy: 0.8120 - val_loss: 0.4313 - val_accuracy: 0.8237\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4422 - accuracy: 0.8147 - val_loss: 0.4459 - val_accuracy: 0.7976\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4416 - accuracy: 0.8182 - val_loss: 0.4425 - val_accuracy: 0.8098\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4410 - accuracy: 0.8155 - val_loss: 0.4441 - val_accuracy: 0.8063\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4394 - accuracy: 0.8131 - val_loss: 0.4445 - val_accuracy: 0.8063\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 52ms/step - loss: 0.4406 - accuracy: 0.8143 - val_loss: 0.4413 - val_accuracy: 0.8202\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 8s 49ms/step - loss: 0.4426 - accuracy: 0.8133 - val_loss: 0.4445 - val_accuracy: 0.8028\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4364 - accuracy: 0.8192 - val_loss: 0.4505 - val_accuracy: 0.8185\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4392 - accuracy: 0.8205 - val_loss: 0.4533 - val_accuracy: 0.7958\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4386 - accuracy: 0.8147 - val_loss: 0.4499 - val_accuracy: 0.8133\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4367 - accuracy: 0.8182 - val_loss: 0.4576 - val_accuracy: 0.7941\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4351 - accuracy: 0.8238 - val_loss: 0.4547 - val_accuracy: 0.7993\n",
      "18/18 [==============================] - 1s 16ms/step\n",
      "Sn = 0.849462, Sp = 0.751701, Acc = 0.799302, MCC = 0.602989, AUC = 0.879599\n",
      "****************************** the 8 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 13s 61ms/step - loss: 0.4292 - accuracy: 0.8215 - val_loss: 0.4282 - val_accuracy: 0.8307\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4321 - accuracy: 0.8182 - val_loss: 0.4300 - val_accuracy: 0.8290\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4359 - accuracy: 0.8172 - val_loss: 0.4444 - val_accuracy: 0.8255\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4314 - accuracy: 0.8143 - val_loss: 0.4440 - val_accuracy: 0.8202\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4344 - accuracy: 0.8164 - val_loss: 0.4453 - val_accuracy: 0.8185\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4359 - accuracy: 0.8147 - val_loss: 0.4597 - val_accuracy: 0.8185\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4334 - accuracy: 0.8174 - val_loss: 0.4459 - val_accuracy: 0.8255\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4320 - accuracy: 0.8205 - val_loss: 0.4543 - val_accuracy: 0.8237\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4334 - accuracy: 0.8197 - val_loss: 0.4505 - val_accuracy: 0.8168\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4287 - accuracy: 0.8178 - val_loss: 0.4548 - val_accuracy: 0.8202\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4279 - accuracy: 0.8228 - val_loss: 0.4516 - val_accuracy: 0.8150\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4295 - accuracy: 0.8269 - val_loss: 0.4648 - val_accuracy: 0.8098\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4281 - accuracy: 0.8213 - val_loss: 0.4574 - val_accuracy: 0.8168\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4269 - accuracy: 0.8248 - val_loss: 0.4651 - val_accuracy: 0.8098\n",
      "18/18 [==============================] - 1s 14ms/step\n",
      "Sn = 0.884746, Sp = 0.730216, Acc = 0.809773, MCC = 0.624076, AUC = 0.881222\n",
      "****************************** the 9 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 13s 63ms/step - loss: 0.4246 - accuracy: 0.8277 - val_loss: 0.4087 - val_accuracy: 0.8586\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4286 - accuracy: 0.8224 - val_loss: 0.4201 - val_accuracy: 0.8464\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4290 - accuracy: 0.8195 - val_loss: 0.4252 - val_accuracy: 0.8447\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4304 - accuracy: 0.8215 - val_loss: 0.4260 - val_accuracy: 0.8482\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4269 - accuracy: 0.8250 - val_loss: 0.4347 - val_accuracy: 0.8412\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4305 - accuracy: 0.8219 - val_loss: 0.4303 - val_accuracy: 0.8360\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4271 - accuracy: 0.8205 - val_loss: 0.4480 - val_accuracy: 0.8133\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4241 - accuracy: 0.8232 - val_loss: 0.4348 - val_accuracy: 0.8412\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4256 - accuracy: 0.8232 - val_loss: 0.4303 - val_accuracy: 0.8412\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4232 - accuracy: 0.8244 - val_loss: 0.4445 - val_accuracy: 0.8377\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4225 - accuracy: 0.8207 - val_loss: 0.4353 - val_accuracy: 0.8325\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 9s 55ms/step - loss: 0.4219 - accuracy: 0.8281 - val_loss: 0.4452 - val_accuracy: 0.8342\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4254 - accuracy: 0.8261 - val_loss: 0.4366 - val_accuracy: 0.8290\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4189 - accuracy: 0.8302 - val_loss: 0.4589 - val_accuracy: 0.8220\n",
      "18/18 [==============================] - 1s 17ms/step\n",
      "Sn = 0.902174, Sp = 0.747475, Acc = 0.821990, MCC = 0.654846, AUC = 0.888682\n",
      "****************************** the 10 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 13s 61ms/step - loss: 0.4182 - accuracy: 0.8288 - val_loss: 0.4060 - val_accuracy: 0.8377\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4184 - accuracy: 0.8329 - val_loss: 0.4119 - val_accuracy: 0.8342\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4252 - accuracy: 0.8232 - val_loss: 0.4203 - val_accuracy: 0.8342\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4200 - accuracy: 0.8271 - val_loss: 0.4235 - val_accuracy: 0.8377\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4187 - accuracy: 0.8294 - val_loss: 0.4253 - val_accuracy: 0.8290\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4195 - accuracy: 0.8323 - val_loss: 0.4412 - val_accuracy: 0.8202\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4195 - accuracy: 0.8349 - val_loss: 0.4324 - val_accuracy: 0.8255\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 55ms/step - loss: 0.4193 - accuracy: 0.8318 - val_loss: 0.4379 - val_accuracy: 0.8185\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4190 - accuracy: 0.8298 - val_loss: 0.4371 - val_accuracy: 0.8307\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4165 - accuracy: 0.8294 - val_loss: 0.4387 - val_accuracy: 0.8237\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4141 - accuracy: 0.8323 - val_loss: 0.4339 - val_accuracy: 0.8237\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4160 - accuracy: 0.8343 - val_loss: 0.4390 - val_accuracy: 0.8220\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4146 - accuracy: 0.8337 - val_loss: 0.4366 - val_accuracy: 0.8290\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4112 - accuracy: 0.8308 - val_loss: 0.4521 - val_accuracy: 0.8098\n",
      "18/18 [==============================] - 2s 16ms/step\n",
      "Sn = 0.858209, Sp = 0.767213, Acc = 0.809773, MCC = 0.624918, AUC = 0.888916\n",
      "10 fold result: [[0.75399361 0.74712643 0.75087108 0.49974249 0.83813791]\n",
      " [0.74736842 0.78892733 0.76829268 0.53683374 0.85378498]\n",
      " [0.79522184 0.71428571 0.7556719  0.51156946 0.85955631]\n",
      " [0.8076923  0.80836237 0.80802792 0.61605468 0.88719817]\n",
      " [0.85211267 0.7266436  0.78883072 0.58297646 0.87524977]\n",
      " [0.85714285 0.73426573 0.79581152 0.59600074 0.88548037]\n",
      " [0.84946236 0.75170068 0.79930192 0.60298891 0.87959915]\n",
      " [0.88474576 0.73021582 0.80977312 0.62407615 0.8812218 ]\n",
      " [0.90217391 0.74747474 0.82198953 0.65484593 0.8886815 ]\n",
      " [0.85820895 0.76721311 0.80977312 0.62491769 0.88891608]]\n",
      "Sn = 0.8308 ± 0.0499\n",
      "Sp = 0.7516 ± 0.0277\n",
      "Acc = 0.7908 ± 0.0233\n",
      "Mcc = 0.5850 ± 0.0494\n",
      "Auc = 0.8738 ± 0.0165\n",
      "Epoch 1/200\n",
      "180/180 [==============================] - 13s 54ms/step - loss: 0.4163 - accuracy: 0.8297 - val_loss: 0.4937 - val_accuracy: 0.7893\n",
      "Epoch 2/200\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.4130 - accuracy: 0.8343"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 19:06:42.411074: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 9s 48ms/step - loss: 0.4130 - accuracy: 0.8343 - val_loss: 0.4971 - val_accuracy: 0.7925\n",
      "Epoch 3/200\n",
      "180/180 [==============================] - 9s 49ms/step - loss: 0.4158 - accuracy: 0.8304 - val_loss: 0.4854 - val_accuracy: 0.7956\n",
      "Epoch 4/200\n",
      "180/180 [==============================] - 9s 48ms/step - loss: 0.4135 - accuracy: 0.8334 - val_loss: 0.5059 - val_accuracy: 0.7862\n",
      "Epoch 5/200\n",
      "180/180 [==============================] - 9s 47ms/step - loss: 0.4105 - accuracy: 0.8341 - val_loss: 0.4934 - val_accuracy: 0.7893\n",
      "Epoch 6/200\n",
      "180/180 [==============================] - 9s 48ms/step - loss: 0.4132 - accuracy: 0.8346 - val_loss: 0.4908 - val_accuracy: 0.8003\n",
      "Epoch 7/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.4108 - accuracy: 0.8355 - val_loss: 0.4881 - val_accuracy: 0.7956\n",
      "Epoch 8/200\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.4125 - accuracy: 0.8332 - val_loss: 0.5043 - val_accuracy: 0.7877\n",
      "Epoch 9/200\n",
      "180/180 [==============================] - 9s 47ms/step - loss: 0.4092 - accuracy: 0.8364 - val_loss: 0.5115 - val_accuracy: 0.7862\n",
      "Epoch 10/200\n",
      "180/180 [==============================] - 9s 48ms/step - loss: 0.4077 - accuracy: 0.8341 - val_loss: 0.5054 - val_accuracy: 0.7956\n",
      "Epoch 11/200\n",
      "180/180 [==============================] - 9s 47ms/step - loss: 0.4105 - accuracy: 0.8358 - val_loss: 0.5023 - val_accuracy: 0.7972\n",
      "Epoch 12/200\n",
      "180/180 [==============================] - 9s 48ms/step - loss: 0.4061 - accuracy: 0.8364 - val_loss: 0.5063 - val_accuracy: 0.7877\n",
      "Epoch 13/200\n",
      "180/180 [==============================] - 9s 48ms/step - loss: 0.4034 - accuracy: 0.8416 - val_loss: 0.5044 - val_accuracy: 0.7972\n",
      "Epoch 14/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.4063 - accuracy: 0.8355 - val_loss: 0.4951 - val_accuracy: 0.7940\n",
      "Epoch 15/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.4037 - accuracy: 0.8391 - val_loss: 0.5084 - val_accuracy: 0.7877\n",
      "Epoch 16/200\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.4064 - accuracy: 0.8362 - val_loss: 0.5009 - val_accuracy: 0.7846\n",
      "Epoch 17/200\n",
      "180/180 [==============================] - 9s 48ms/step - loss: 0.4033 - accuracy: 0.8400 - val_loss: 0.5106 - val_accuracy: 0.7877\n",
      "Epoch 18/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.4015 - accuracy: 0.8416 - val_loss: 0.5047 - val_accuracy: 0.7940\n",
      "Epoch 19/200\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.4001 - accuracy: 0.8419 - val_loss: 0.5140 - val_accuracy: 0.7909\n",
      "Epoch 20/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.4027 - accuracy: 0.8400 - val_loss: 0.5230 - val_accuracy: 0.7893\n",
      "Epoch 21/200\n",
      "180/180 [==============================] - 9s 47ms/step - loss: 0.4011 - accuracy: 0.8378 - val_loss: 0.5111 - val_accuracy: 0.7846\n",
      "Epoch 22/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.4003 - accuracy: 0.8386 - val_loss: 0.5129 - val_accuracy: 0.7909\n",
      "Epoch 23/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.4002 - accuracy: 0.8418 - val_loss: 0.5110 - val_accuracy: 0.7814\n",
      "20/20 [==============================] - 1s 17ms/step\n",
      "-----------------------------------------------test---------------------------------------\n",
      "Sn = 0.798742, Sp = 0.764151, Acc = 0.781447, MCC = 0.563230, AUC = 0.861873\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "tf.random.set_seed(1)  # for reproducibility\n",
    "# reading model\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 200\n",
    "\n",
    "# # Cross-validation\n",
    "n = 10\n",
    "k_fold = KFold(n_splits=n, shuffle=True, random_state=42)\n",
    "\n",
    "all_performance = []\n",
    "tprs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "for fold_count, (train_index, val_index) in enumerate(k_fold.split(train)):\n",
    "    print('*' * 30 + ' the ' + str(fold_count + 1) + ' fold ' + '*' * 30)\n",
    "    trains, val = train[train_index], train[val_index]\n",
    "    trains_label, val_label = train_label[train_index], train_label[val_index]\n",
    "    zaoting = EarlyStopping(monitor='val_loss', patience=13, mode='auto')\n",
    "    xuexilv = WarmupExponentialDecay(lr_base=0.0002,decay=0.00002,warmup_epochs=2)\n",
    "    callback_lists=[xuexilv,zaoting]\n",
    "    model.fit(x=trains, y=trains_label, validation_data=(val, val_label), epochs=EPOCHS,\n",
    "                batch_size=BATCH_SIZE, shuffle=True,\n",
    "                callbacks=callback_lists,\n",
    "                verbose=1)\n",
    "     # 保存模型\n",
    "\n",
    "    model.save('./warmup_embedding/model_fold' + str(fold_count+1) + '.h5')\n",
    "\n",
    "    del model\n",
    "\n",
    "    model = load_model('./warmup_embedding/model_fold' + str(fold_count+1) + '.h5')\n",
    "\n",
    "    val_pred = model.predict(val, verbose=1)\n",
    "\n",
    "    # Sn, Sp, Acc, MCC, AUC\n",
    "    Sn, Sp, Acc, MCC = show_performance(val_label[:, 1], val_pred[:, 1])\n",
    "    AUC = roc_auc_score(val_label[:, 1], val_pred[:, 1])\n",
    "    print('Sn = %f, Sp = %f, Acc = %f, MCC = %f, AUC = %f' % (Sn, Sp, Acc, MCC, AUC))\n",
    "\n",
    "    performance = [Sn, Sp, Acc, MCC, AUC]\n",
    "    all_performance.append(performance)\n",
    "    \n",
    "all_performance = np.array(all_performance)\n",
    "print('10 fold result:', all_performance)\n",
    "performance_mean = performance_mean(all_performance)\n",
    "\n",
    "model.fit(x=train, y=train_label, validation_data=(test, test_label), epochs=EPOCHS,\n",
    "                      batch_size=BATCH_SIZE, shuffle=True,\n",
    "                      callbacks=[EarlyStopping(monitor='val_loss', patience=20, mode='auto')],\n",
    "                      verbose=1)\n",
    "model.save('./warmup_embedding/model_test.h5')\n",
    "\n",
    "del model\n",
    "\n",
    "model = load_model('./warmup_embedding/model_test.h5')\n",
    "\n",
    "test_score = model.predict(test)\n",
    "\n",
    "\n",
    "# Sn, Sp, Acc, MCC, AUC\n",
    "Sn, Sp, Acc, MCC = show_performance(test_label[:,1], test_score[:,1])\n",
    "AUC = roc_auc_score(test_label[:,1], test_score[:,1])\n",
    "\n",
    "print('-----------------------------------------------test---------------------------------------')\n",
    "print('Sn = %f, Sp = %f, Acc = %f, MCC = %f, AUC = %f' % (Sn, Sp, Acc, MCC, AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d83d6e9c-56c4-40fc-b229-37d4a3299c8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************Warmup+embedding_64******************************\n",
      "(None, 15, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 16:01:18.060290: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4227 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:65:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 15, 48)\n",
      "****************************** the 1 fold ******************************\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 16:01:26.173254: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8800\n",
      "Could not load symbol cublasGetSmCountTarget from libcublas.so.11. Error: /usr/local/cuda/targets/x86_64-linux/lib/libcublas.so.11: undefined symbol: cublasGetSmCountTarget\n",
      "2024-06-05 16:01:26.466588: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-06-05 16:01:26.506313: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f39b427efa0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-05 16:01:26.506337: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-06-05 16:01:26.509974: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-06-05 16:01:26.562990: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-05 16:01:26.565673: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:231] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.6\n",
      "2024-06-05 16:01:26.565692: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:234] Used ptxas at ptxas\n",
      "2024-06-05 16:01:26.582395: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-06-05 16:01:26.651754: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/162 [..............................] - ETA: 22:01 - loss: 3.2462 - accuracy: 0.4375"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 16:01:27.092665: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-05 16:01:27.111537: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-05 16:01:27.134710: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-05 16:01:27.148807: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-05 16:01:27.184993: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4/162 [..............................] - ETA: 14s - loss: 3.2465 - accuracy: 0.4844 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 16:01:27.357976: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 19/162 [==>...........................] - ETA: 9s - loss: 3.2447 - accuracy: 0.5181"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 16:01:28.306433: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 22/162 [===>..........................] - ETA: 9s - loss: 3.2444 - accuracy: 0.5142"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 16:01:28.566656: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 18s 62ms/step - loss: 3.1605 - accuracy: 0.5417 - val_loss: 2.9931 - val_accuracy: 0.5348\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 2.7095 - accuracy: 0.5954 - val_loss: 2.3782 - val_accuracy: 0.6376\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 2.0661 - accuracy: 0.6561 - val_loss: 1.8308 - val_accuracy: 0.6411\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 1.6358 - accuracy: 0.6630 - val_loss: 1.4877 - val_accuracy: 0.6603\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 1.3644 - accuracy: 0.6642 - val_loss: 1.2726 - val_accuracy: 0.6707\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 1.1900 - accuracy: 0.6708 - val_loss: 1.1362 - val_accuracy: 0.6655\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - ETA: 0s - loss: 1.0746 - accuracy: 0.6712"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 16:02:28.686585: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 9s 55ms/step - loss: 1.0746 - accuracy: 0.6712 - val_loss: 1.0371 - val_accuracy: 0.6829\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.9987 - accuracy: 0.6675 - val_loss: 0.9841 - val_accuracy: 0.6760\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.9462 - accuracy: 0.6725 - val_loss: 0.9343 - val_accuracy: 0.6794\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.9056 - accuracy: 0.6724 - val_loss: 0.9068 - val_accuracy: 0.6777\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.8753 - accuracy: 0.6753 - val_loss: 0.8733 - val_accuracy: 0.6916\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.8471 - accuracy: 0.6741 - val_loss: 0.8527 - val_accuracy: 0.6969\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 9s 55ms/step - loss: 0.8237 - accuracy: 0.6817 - val_loss: 0.8232 - val_accuracy: 0.6916\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.8020 - accuracy: 0.6850 - val_loss: 0.8002 - val_accuracy: 0.7021\n",
      "Epoch 15/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.7808 - accuracy: 0.6851 - val_loss: 0.7850 - val_accuracy: 0.6986\n",
      "Epoch 16/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.7629 - accuracy: 0.6910 - val_loss: 0.7606 - val_accuracy: 0.7143\n",
      "Epoch 17/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.7448 - accuracy: 0.6915 - val_loss: 0.7521 - val_accuracy: 0.6812\n",
      "Epoch 18/200\n",
      "162/162 [==============================] - ETA: 0s - loss: 0.7270 - accuracy: 0.6997"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 16:04:04.786871: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 9s 54ms/step - loss: 0.7270 - accuracy: 0.6997 - val_loss: 0.7333 - val_accuracy: 0.6969\n",
      "Epoch 19/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.7108 - accuracy: 0.7045 - val_loss: 0.7173 - val_accuracy: 0.7073\n",
      "Epoch 20/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.6942 - accuracy: 0.7125 - val_loss: 0.7014 - val_accuracy: 0.7056\n",
      "Epoch 21/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.6780 - accuracy: 0.7142 - val_loss: 0.6902 - val_accuracy: 0.7160\n",
      "Epoch 22/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.6664 - accuracy: 0.7179 - val_loss: 0.6786 - val_accuracy: 0.7195\n",
      "Epoch 23/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.6525 - accuracy: 0.7202 - val_loss: 0.6764 - val_accuracy: 0.7091\n",
      "Epoch 24/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.6398 - accuracy: 0.7272 - val_loss: 0.6647 - val_accuracy: 0.7091\n",
      "Epoch 25/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.6273 - accuracy: 0.7307 - val_loss: 0.6473 - val_accuracy: 0.7213\n",
      "Epoch 26/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.6145 - accuracy: 0.7319 - val_loss: 0.6478 - val_accuracy: 0.7091\n",
      "Epoch 27/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.6050 - accuracy: 0.7377 - val_loss: 0.6501 - val_accuracy: 0.7108\n",
      "Epoch 28/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5963 - accuracy: 0.7371 - val_loss: 0.6263 - val_accuracy: 0.7108\n",
      "Epoch 29/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5868 - accuracy: 0.7377 - val_loss: 0.6156 - val_accuracy: 0.7300\n",
      "Epoch 30/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5799 - accuracy: 0.7443 - val_loss: 0.6031 - val_accuracy: 0.7213\n",
      "Epoch 31/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5732 - accuracy: 0.7480 - val_loss: 0.6133 - val_accuracy: 0.7195\n",
      "Epoch 32/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5660 - accuracy: 0.7458 - val_loss: 0.6092 - val_accuracy: 0.7178\n",
      "Epoch 33/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5604 - accuracy: 0.7489 - val_loss: 0.5956 - val_accuracy: 0.7282\n",
      "Epoch 34/200\n",
      "162/162 [==============================] - ETA: 0s - loss: 0.5559 - accuracy: 0.7460"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 16:06:23.755051: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5559 - accuracy: 0.7460 - val_loss: 0.5836 - val_accuracy: 0.7334\n",
      "Epoch 35/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5496 - accuracy: 0.7536 - val_loss: 0.5697 - val_accuracy: 0.7439\n",
      "Epoch 36/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5456 - accuracy: 0.7518 - val_loss: 0.5727 - val_accuracy: 0.7369\n",
      "Epoch 37/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5404 - accuracy: 0.7561 - val_loss: 0.5825 - val_accuracy: 0.7230\n",
      "Epoch 38/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5378 - accuracy: 0.7544 - val_loss: 0.5647 - val_accuracy: 0.7334\n",
      "Epoch 39/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5361 - accuracy: 0.7579 - val_loss: 0.5596 - val_accuracy: 0.7474\n",
      "Epoch 40/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5296 - accuracy: 0.7631 - val_loss: 0.5571 - val_accuracy: 0.7491\n",
      "Epoch 41/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5284 - accuracy: 0.7571 - val_loss: 0.5514 - val_accuracy: 0.7578\n",
      "Epoch 42/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5260 - accuracy: 0.7623 - val_loss: 0.5611 - val_accuracy: 0.7404\n",
      "Epoch 43/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5223 - accuracy: 0.7606 - val_loss: 0.5612 - val_accuracy: 0.7404\n",
      "Epoch 44/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5220 - accuracy: 0.7637 - val_loss: 0.5570 - val_accuracy: 0.7439\n",
      "Epoch 45/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5201 - accuracy: 0.7648 - val_loss: 0.5480 - val_accuracy: 0.7456\n",
      "Epoch 46/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5182 - accuracy: 0.7679 - val_loss: 0.5591 - val_accuracy: 0.7369\n",
      "Epoch 47/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5177 - accuracy: 0.7656 - val_loss: 0.5503 - val_accuracy: 0.7422\n",
      "Epoch 48/200\n",
      "162/162 [==============================] - 9s 55ms/step - loss: 0.5164 - accuracy: 0.7619 - val_loss: 0.5397 - val_accuracy: 0.7561\n",
      "Epoch 49/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5120 - accuracy: 0.7672 - val_loss: 0.5500 - val_accuracy: 0.7422\n",
      "Epoch 50/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5129 - accuracy: 0.7637 - val_loss: 0.5446 - val_accuracy: 0.7526\n",
      "Epoch 51/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5113 - accuracy: 0.7681 - val_loss: 0.5491 - val_accuracy: 0.7422\n",
      "Epoch 52/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5113 - accuracy: 0.7734 - val_loss: 0.5379 - val_accuracy: 0.7561\n",
      "Epoch 53/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5085 - accuracy: 0.7693 - val_loss: 0.5371 - val_accuracy: 0.7613\n",
      "Epoch 54/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5067 - accuracy: 0.7757 - val_loss: 0.5566 - val_accuracy: 0.7352\n",
      "Epoch 55/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.5070 - accuracy: 0.7722 - val_loss: 0.5615 - val_accuracy: 0.7230\n",
      "Epoch 56/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5095 - accuracy: 0.7654 - val_loss: 0.5496 - val_accuracy: 0.7387\n",
      "Epoch 57/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5068 - accuracy: 0.7689 - val_loss: 0.5379 - val_accuracy: 0.7561\n",
      "Epoch 58/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5039 - accuracy: 0.7749 - val_loss: 0.5539 - val_accuracy: 0.7300\n",
      "Epoch 59/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5038 - accuracy: 0.7737 - val_loss: 0.5387 - val_accuracy: 0.7509\n",
      "Epoch 60/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5032 - accuracy: 0.7747 - val_loss: 0.5532 - val_accuracy: 0.7300\n",
      "Epoch 61/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5016 - accuracy: 0.7737 - val_loss: 0.5550 - val_accuracy: 0.7247\n",
      "Epoch 62/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5048 - accuracy: 0.7734 - val_loss: 0.5380 - val_accuracy: 0.7474\n",
      "Epoch 63/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5017 - accuracy: 0.7720 - val_loss: 0.5416 - val_accuracy: 0.7404\n",
      "Epoch 64/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5023 - accuracy: 0.7720 - val_loss: 0.5421 - val_accuracy: 0.7317\n",
      "Epoch 65/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5012 - accuracy: 0.7770 - val_loss: 0.5330 - val_accuracy: 0.7474\n",
      "Epoch 66/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4984 - accuracy: 0.7780 - val_loss: 0.5472 - val_accuracy: 0.7369\n",
      "Epoch 67/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4993 - accuracy: 0.7767 - val_loss: 0.5450 - val_accuracy: 0.7369\n",
      "Epoch 68/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4981 - accuracy: 0.7782 - val_loss: 0.5408 - val_accuracy: 0.7404\n",
      "Epoch 69/200\n",
      "162/162 [==============================] - 9s 52ms/step - loss: 0.4986 - accuracy: 0.7753 - val_loss: 0.5442 - val_accuracy: 0.7334\n",
      "Epoch 70/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4952 - accuracy: 0.7801 - val_loss: 0.5385 - val_accuracy: 0.7456\n",
      "Epoch 71/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4976 - accuracy: 0.7786 - val_loss: 0.5340 - val_accuracy: 0.7456\n",
      "Epoch 72/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4974 - accuracy: 0.7749 - val_loss: 0.5292 - val_accuracy: 0.7544\n",
      "Epoch 73/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4961 - accuracy: 0.7741 - val_loss: 0.5316 - val_accuracy: 0.7474\n",
      "Epoch 74/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4949 - accuracy: 0.7786 - val_loss: 0.5460 - val_accuracy: 0.7334\n",
      "Epoch 75/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4959 - accuracy: 0.7825 - val_loss: 0.5446 - val_accuracy: 0.7404\n",
      "Epoch 76/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4923 - accuracy: 0.7821 - val_loss: 0.5330 - val_accuracy: 0.7474\n",
      "Epoch 77/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4942 - accuracy: 0.7825 - val_loss: 0.5407 - val_accuracy: 0.7456\n",
      "Epoch 78/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4935 - accuracy: 0.7796 - val_loss: 0.5270 - val_accuracy: 0.7491\n",
      "Epoch 79/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4938 - accuracy: 0.7784 - val_loss: 0.5402 - val_accuracy: 0.7404\n",
      "Epoch 80/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4916 - accuracy: 0.7838 - val_loss: 0.5358 - val_accuracy: 0.7439\n",
      "Epoch 81/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4916 - accuracy: 0.7821 - val_loss: 0.5268 - val_accuracy: 0.7526\n",
      "Epoch 82/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4922 - accuracy: 0.7805 - val_loss: 0.5436 - val_accuracy: 0.7422\n",
      "Epoch 83/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4890 - accuracy: 0.7803 - val_loss: 0.5282 - val_accuracy: 0.7491\n",
      "Epoch 84/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4911 - accuracy: 0.7786 - val_loss: 0.5455 - val_accuracy: 0.7439\n",
      "Epoch 85/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4886 - accuracy: 0.7844 - val_loss: 0.5271 - val_accuracy: 0.7613\n",
      "Epoch 86/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4908 - accuracy: 0.7803 - val_loss: 0.5257 - val_accuracy: 0.7561\n",
      "Epoch 87/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4901 - accuracy: 0.7801 - val_loss: 0.5287 - val_accuracy: 0.7491\n",
      "Epoch 88/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4873 - accuracy: 0.7829 - val_loss: 0.5303 - val_accuracy: 0.7474\n",
      "Epoch 89/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4880 - accuracy: 0.7869 - val_loss: 0.5382 - val_accuracy: 0.7456\n",
      "Epoch 90/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4895 - accuracy: 0.7800 - val_loss: 0.5230 - val_accuracy: 0.7456\n",
      "Epoch 91/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4870 - accuracy: 0.7832 - val_loss: 0.5495 - val_accuracy: 0.7334\n",
      "Epoch 92/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4845 - accuracy: 0.7856 - val_loss: 0.5350 - val_accuracy: 0.7369\n",
      "Epoch 93/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4862 - accuracy: 0.7848 - val_loss: 0.5346 - val_accuracy: 0.7456\n",
      "Epoch 94/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4844 - accuracy: 0.7873 - val_loss: 0.5236 - val_accuracy: 0.7474\n",
      "Epoch 95/200\n",
      "162/162 [==============================] - 9s 55ms/step - loss: 0.4871 - accuracy: 0.7838 - val_loss: 0.5226 - val_accuracy: 0.7544\n",
      "Epoch 96/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4852 - accuracy: 0.7821 - val_loss: 0.5193 - val_accuracy: 0.7561\n",
      "Epoch 97/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4820 - accuracy: 0.7846 - val_loss: 0.5408 - val_accuracy: 0.7439\n",
      "Epoch 98/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4821 - accuracy: 0.7858 - val_loss: 0.5197 - val_accuracy: 0.7509\n",
      "Epoch 99/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4818 - accuracy: 0.7875 - val_loss: 0.5472 - val_accuracy: 0.7404\n",
      "Epoch 100/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4826 - accuracy: 0.7871 - val_loss: 0.5340 - val_accuracy: 0.7474\n",
      "Epoch 101/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4807 - accuracy: 0.7875 - val_loss: 0.5209 - val_accuracy: 0.7474\n",
      "Epoch 102/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4802 - accuracy: 0.7881 - val_loss: 0.5309 - val_accuracy: 0.7439\n",
      "Epoch 103/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4817 - accuracy: 0.7900 - val_loss: 0.5352 - val_accuracy: 0.7509\n",
      "Epoch 104/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4822 - accuracy: 0.7879 - val_loss: 0.5349 - val_accuracy: 0.7509\n",
      "Epoch 105/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4812 - accuracy: 0.7864 - val_loss: 0.5350 - val_accuracy: 0.7561\n",
      "Epoch 106/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4806 - accuracy: 0.7877 - val_loss: 0.5297 - val_accuracy: 0.7474\n",
      "Epoch 107/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4802 - accuracy: 0.7916 - val_loss: 0.5196 - val_accuracy: 0.7491\n",
      "Epoch 108/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4781 - accuracy: 0.7893 - val_loss: 0.5220 - val_accuracy: 0.7561\n",
      "Epoch 109/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4786 - accuracy: 0.7904 - val_loss: 0.5141 - val_accuracy: 0.7666\n",
      "Epoch 110/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4791 - accuracy: 0.7862 - val_loss: 0.5324 - val_accuracy: 0.7544\n",
      "Epoch 111/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4766 - accuracy: 0.7895 - val_loss: 0.5197 - val_accuracy: 0.7561\n",
      "Epoch 112/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4804 - accuracy: 0.7838 - val_loss: 0.5171 - val_accuracy: 0.7561\n",
      "Epoch 113/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4773 - accuracy: 0.7883 - val_loss: 0.5458 - val_accuracy: 0.7422\n",
      "Epoch 114/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4752 - accuracy: 0.7906 - val_loss: 0.5127 - val_accuracy: 0.7666\n",
      "Epoch 115/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4763 - accuracy: 0.7933 - val_loss: 0.5489 - val_accuracy: 0.7404\n",
      "Epoch 116/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4770 - accuracy: 0.7881 - val_loss: 0.5226 - val_accuracy: 0.7544\n",
      "Epoch 117/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4767 - accuracy: 0.7922 - val_loss: 0.5126 - val_accuracy: 0.7596\n",
      "Epoch 118/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4749 - accuracy: 0.7929 - val_loss: 0.5463 - val_accuracy: 0.7422\n",
      "Epoch 119/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4748 - accuracy: 0.7885 - val_loss: 0.5187 - val_accuracy: 0.7474\n",
      "Epoch 120/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4728 - accuracy: 0.7937 - val_loss: 0.5386 - val_accuracy: 0.7526\n",
      "Epoch 121/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4762 - accuracy: 0.7875 - val_loss: 0.5364 - val_accuracy: 0.7474\n",
      "Epoch 122/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4753 - accuracy: 0.7902 - val_loss: 0.5112 - val_accuracy: 0.7683\n",
      "Epoch 123/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4743 - accuracy: 0.7935 - val_loss: 0.5287 - val_accuracy: 0.7526\n",
      "Epoch 124/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4739 - accuracy: 0.7924 - val_loss: 0.5153 - val_accuracy: 0.7561\n",
      "Epoch 125/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4733 - accuracy: 0.7887 - val_loss: 0.5419 - val_accuracy: 0.7509\n",
      "Epoch 126/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4746 - accuracy: 0.7933 - val_loss: 0.5456 - val_accuracy: 0.7456\n",
      "Epoch 127/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4728 - accuracy: 0.7926 - val_loss: 0.5436 - val_accuracy: 0.7491\n",
      "Epoch 128/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4714 - accuracy: 0.7883 - val_loss: 0.5119 - val_accuracy: 0.7596\n",
      "Epoch 129/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4747 - accuracy: 0.7904 - val_loss: 0.5272 - val_accuracy: 0.7561\n",
      "Epoch 130/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4701 - accuracy: 0.7964 - val_loss: 0.5108 - val_accuracy: 0.7596\n",
      "Epoch 131/200\n",
      "162/162 [==============================] - 9s 55ms/step - loss: 0.4735 - accuracy: 0.7912 - val_loss: 0.5352 - val_accuracy: 0.7526\n",
      "Epoch 132/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4727 - accuracy: 0.7910 - val_loss: 0.5193 - val_accuracy: 0.7439\n",
      "Epoch 133/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4702 - accuracy: 0.7922 - val_loss: 0.5210 - val_accuracy: 0.7526\n",
      "Epoch 134/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4705 - accuracy: 0.7929 - val_loss: 0.5095 - val_accuracy: 0.7648\n",
      "Epoch 135/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4700 - accuracy: 0.7908 - val_loss: 0.5301 - val_accuracy: 0.7613\n",
      "Epoch 136/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4706 - accuracy: 0.7912 - val_loss: 0.5216 - val_accuracy: 0.7491\n",
      "Epoch 137/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4715 - accuracy: 0.7896 - val_loss: 0.5144 - val_accuracy: 0.7526\n",
      "Epoch 138/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4683 - accuracy: 0.7895 - val_loss: 0.5075 - val_accuracy: 0.7683\n",
      "Epoch 139/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4716 - accuracy: 0.7908 - val_loss: 0.5198 - val_accuracy: 0.7578\n",
      "Epoch 140/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4718 - accuracy: 0.7910 - val_loss: 0.5251 - val_accuracy: 0.7526\n",
      "Epoch 141/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4657 - accuracy: 0.7960 - val_loss: 0.5247 - val_accuracy: 0.7631\n",
      "Epoch 142/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4710 - accuracy: 0.7935 - val_loss: 0.5132 - val_accuracy: 0.7613\n",
      "Epoch 143/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4677 - accuracy: 0.7929 - val_loss: 0.5425 - val_accuracy: 0.7509\n",
      "Epoch 144/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4673 - accuracy: 0.7951 - val_loss: 0.5228 - val_accuracy: 0.7578\n",
      "Epoch 145/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4675 - accuracy: 0.7939 - val_loss: 0.5272 - val_accuracy: 0.7613\n",
      "Epoch 146/200\n",
      "162/162 [==============================] - 8s 49ms/step - loss: 0.4694 - accuracy: 0.7916 - val_loss: 0.5207 - val_accuracy: 0.7631\n",
      "Epoch 147/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4660 - accuracy: 0.7974 - val_loss: 0.5143 - val_accuracy: 0.7578\n",
      "Epoch 148/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4664 - accuracy: 0.7959 - val_loss: 0.5189 - val_accuracy: 0.7613\n",
      "Epoch 149/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4653 - accuracy: 0.7964 - val_loss: 0.5089 - val_accuracy: 0.7613\n",
      "Epoch 150/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4679 - accuracy: 0.7960 - val_loss: 0.5201 - val_accuracy: 0.7596\n",
      "Epoch 151/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4664 - accuracy: 0.7959 - val_loss: 0.5221 - val_accuracy: 0.7474\n",
      "18/18 [==============================] - 1s 19ms/step\n",
      "Sn = 0.728435, Sp = 0.770115, Acc = 0.747387, MCC = 0.496502, AUC = 0.844834\n",
      "****************************** the 2 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 13s 61ms/step - loss: 0.4681 - accuracy: 0.7926 - val_loss: 0.4783 - val_accuracy: 0.7944\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 9s 55ms/step - loss: 0.4701 - accuracy: 0.7910 - val_loss: 0.4793 - val_accuracy: 0.7997\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 9s 52ms/step - loss: 0.4739 - accuracy: 0.7881 - val_loss: 0.4862 - val_accuracy: 0.7875\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4705 - accuracy: 0.7883 - val_loss: 0.4914 - val_accuracy: 0.7927\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4693 - accuracy: 0.7920 - val_loss: 0.4892 - val_accuracy: 0.7840\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4692 - accuracy: 0.7949 - val_loss: 0.5075 - val_accuracy: 0.7735\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4697 - accuracy: 0.7959 - val_loss: 0.4941 - val_accuracy: 0.7822\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4685 - accuracy: 0.7914 - val_loss: 0.4917 - val_accuracy: 0.7892\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4667 - accuracy: 0.7908 - val_loss: 0.4978 - val_accuracy: 0.7840\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 55ms/step - loss: 0.4679 - accuracy: 0.7904 - val_loss: 0.4965 - val_accuracy: 0.7962\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4673 - accuracy: 0.7937 - val_loss: 0.5100 - val_accuracy: 0.7875\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4651 - accuracy: 0.7931 - val_loss: 0.4950 - val_accuracy: 0.7892\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4664 - accuracy: 0.7916 - val_loss: 0.5105 - val_accuracy: 0.7700\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4650 - accuracy: 0.7966 - val_loss: 0.5110 - val_accuracy: 0.7787\n",
      "18/18 [==============================] - 1s 14ms/step\n",
      "Sn = 0.761404, Sp = 0.795848, Acc = 0.778746, MCC = 0.557647, AUC = 0.848686\n",
      "****************************** the 3 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 13s 61ms/step - loss: 0.4665 - accuracy: 0.7957 - val_loss: 0.4500 - val_accuracy: 0.7766\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4667 - accuracy: 0.7936 - val_loss: 0.4537 - val_accuracy: 0.7749\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4676 - accuracy: 0.7988 - val_loss: 0.4613 - val_accuracy: 0.7661\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4696 - accuracy: 0.7918 - val_loss: 0.4582 - val_accuracy: 0.7696\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4659 - accuracy: 0.7965 - val_loss: 0.4735 - val_accuracy: 0.7853\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4678 - accuracy: 0.7949 - val_loss: 0.4725 - val_accuracy: 0.7801\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4656 - accuracy: 0.7955 - val_loss: 0.4695 - val_accuracy: 0.7749\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4665 - accuracy: 0.7949 - val_loss: 0.4714 - val_accuracy: 0.7749\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4680 - accuracy: 0.7920 - val_loss: 0.4669 - val_accuracy: 0.7574\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4648 - accuracy: 0.7916 - val_loss: 0.4685 - val_accuracy: 0.7853\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4637 - accuracy: 0.8003 - val_loss: 0.4661 - val_accuracy: 0.7766\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4620 - accuracy: 0.7974 - val_loss: 0.4809 - val_accuracy: 0.7749\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4643 - accuracy: 0.7963 - val_loss: 0.4690 - val_accuracy: 0.7801\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4617 - accuracy: 0.7963 - val_loss: 0.4705 - val_accuracy: 0.7679\n",
      "18/18 [==============================] - 1s 17ms/step\n",
      "Sn = 0.825939, Sp = 0.707143, Acc = 0.767888, MCC = 0.537569, AUC = 0.872635\n",
      "****************************** the 4 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 13s 62ms/step - loss: 0.4602 - accuracy: 0.7924 - val_loss: 0.4278 - val_accuracy: 0.8220\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4670 - accuracy: 0.7914 - val_loss: 0.4310 - val_accuracy: 0.8185\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4652 - accuracy: 0.7903 - val_loss: 0.4386 - val_accuracy: 0.8237\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4671 - accuracy: 0.7926 - val_loss: 0.4423 - val_accuracy: 0.8220\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4613 - accuracy: 0.7965 - val_loss: 0.4482 - val_accuracy: 0.8115\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4650 - accuracy: 0.7959 - val_loss: 0.4479 - val_accuracy: 0.8080\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4602 - accuracy: 0.7949 - val_loss: 0.4446 - val_accuracy: 0.8150\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4640 - accuracy: 0.7984 - val_loss: 0.4461 - val_accuracy: 0.8098\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4597 - accuracy: 0.7978 - val_loss: 0.4446 - val_accuracy: 0.8150\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 55ms/step - loss: 0.4571 - accuracy: 0.7941 - val_loss: 0.4453 - val_accuracy: 0.8098\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4618 - accuracy: 0.8019 - val_loss: 0.4548 - val_accuracy: 0.8098\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4607 - accuracy: 0.7984 - val_loss: 0.4501 - val_accuracy: 0.8098\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4629 - accuracy: 0.8000 - val_loss: 0.4447 - val_accuracy: 0.8133\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4592 - accuracy: 0.8029 - val_loss: 0.4510 - val_accuracy: 0.8098\n",
      "18/18 [==============================] - 1s 16ms/step\n",
      "Sn = 0.814685, Sp = 0.804878, Acc = 0.809773, MCC = 0.619586, AUC = 0.885030\n",
      "****************************** the 5 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 13s 61ms/step - loss: 0.4505 - accuracy: 0.8050 - val_loss: 0.4412 - val_accuracy: 0.8115\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4559 - accuracy: 0.8011 - val_loss: 0.4459 - val_accuracy: 0.8010\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4595 - accuracy: 0.8003 - val_loss: 0.4547 - val_accuracy: 0.7976\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4569 - accuracy: 0.7996 - val_loss: 0.4588 - val_accuracy: 0.7871\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4586 - accuracy: 0.7996 - val_loss: 0.4552 - val_accuracy: 0.8098\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4566 - accuracy: 0.8066 - val_loss: 0.4580 - val_accuracy: 0.7941\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4560 - accuracy: 0.8023 - val_loss: 0.4612 - val_accuracy: 0.8028\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4538 - accuracy: 0.8021 - val_loss: 0.4595 - val_accuracy: 0.7941\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 55ms/step - loss: 0.4571 - accuracy: 0.8027 - val_loss: 0.4608 - val_accuracy: 0.7923\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4536 - accuracy: 0.8050 - val_loss: 0.4607 - val_accuracy: 0.7888\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 55ms/step - loss: 0.4555 - accuracy: 0.8025 - val_loss: 0.4687 - val_accuracy: 0.7871\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4519 - accuracy: 0.8035 - val_loss: 0.4642 - val_accuracy: 0.7993\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4530 - accuracy: 0.8025 - val_loss: 0.4687 - val_accuracy: 0.7871\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4536 - accuracy: 0.8011 - val_loss: 0.4687 - val_accuracy: 0.7958\n",
      "18/18 [==============================] - 1s 15ms/step\n",
      "Sn = 0.848592, Sp = 0.743945, Acc = 0.795812, MCC = 0.595467, AUC = 0.873995\n",
      "****************************** the 6 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 13s 61ms/step - loss: 0.4485 - accuracy: 0.8089 - val_loss: 0.4348 - val_accuracy: 0.8150\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4516 - accuracy: 0.8081 - val_loss: 0.4391 - val_accuracy: 0.8150\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4548 - accuracy: 0.8066 - val_loss: 0.4471 - val_accuracy: 0.8010\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4552 - accuracy: 0.8056 - val_loss: 0.4511 - val_accuracy: 0.8028\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4513 - accuracy: 0.8083 - val_loss: 0.4524 - val_accuracy: 0.7871\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4515 - accuracy: 0.8066 - val_loss: 0.4474 - val_accuracy: 0.7923\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4508 - accuracy: 0.8104 - val_loss: 0.4530 - val_accuracy: 0.7958\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4523 - accuracy: 0.8052 - val_loss: 0.4519 - val_accuracy: 0.7941\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4489 - accuracy: 0.8066 - val_loss: 0.4562 - val_accuracy: 0.7871\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4485 - accuracy: 0.8046 - val_loss: 0.4575 - val_accuracy: 0.7871\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4508 - accuracy: 0.8054 - val_loss: 0.4565 - val_accuracy: 0.7923\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4452 - accuracy: 0.8083 - val_loss: 0.4550 - val_accuracy: 0.7906\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4492 - accuracy: 0.8102 - val_loss: 0.4600 - val_accuracy: 0.7923\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4473 - accuracy: 0.8095 - val_loss: 0.4572 - val_accuracy: 0.7888\n",
      "18/18 [==============================] - 1s 15ms/step\n",
      "Sn = 0.846690, Sp = 0.730769, Acc = 0.788831, MCC = 0.581447, AUC = 0.879901\n",
      "****************************** the 7 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 13s 60ms/step - loss: 0.4425 - accuracy: 0.8093 - val_loss: 0.4286 - val_accuracy: 0.8220\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4480 - accuracy: 0.8075 - val_loss: 0.4363 - val_accuracy: 0.8150\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4485 - accuracy: 0.8075 - val_loss: 0.4389 - val_accuracy: 0.8168\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4494 - accuracy: 0.8089 - val_loss: 0.4539 - val_accuracy: 0.7976\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4455 - accuracy: 0.8118 - val_loss: 0.4492 - val_accuracy: 0.8028\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4471 - accuracy: 0.8100 - val_loss: 0.4473 - val_accuracy: 0.8045\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4446 - accuracy: 0.8098 - val_loss: 0.4476 - val_accuracy: 0.8045\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4447 - accuracy: 0.8085 - val_loss: 0.4473 - val_accuracy: 0.8098\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4465 - accuracy: 0.8071 - val_loss: 0.4509 - val_accuracy: 0.8028\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4427 - accuracy: 0.8100 - val_loss: 0.4565 - val_accuracy: 0.8080\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4455 - accuracy: 0.8106 - val_loss: 0.4562 - val_accuracy: 0.7923\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4426 - accuracy: 0.8112 - val_loss: 0.4528 - val_accuracy: 0.8045\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4447 - accuracy: 0.8137 - val_loss: 0.4587 - val_accuracy: 0.7923\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4419 - accuracy: 0.8162 - val_loss: 0.4562 - val_accuracy: 0.7976\n",
      "18/18 [==============================] - 1s 14ms/step\n",
      "Sn = 0.835125, Sp = 0.761905, Acc = 0.797557, MCC = 0.597818, AUC = 0.876807\n",
      "****************************** the 8 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 13s 62ms/step - loss: 0.4366 - accuracy: 0.8147 - val_loss: 0.4317 - val_accuracy: 0.8220\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4379 - accuracy: 0.8151 - val_loss: 0.4370 - val_accuracy: 0.8168\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4417 - accuracy: 0.8108 - val_loss: 0.4452 - val_accuracy: 0.8185\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4444 - accuracy: 0.8089 - val_loss: 0.4438 - val_accuracy: 0.8168\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4426 - accuracy: 0.8153 - val_loss: 0.4519 - val_accuracy: 0.8098\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4446 - accuracy: 0.8087 - val_loss: 0.4620 - val_accuracy: 0.8168\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4400 - accuracy: 0.8118 - val_loss: 0.4467 - val_accuracy: 0.8133\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4395 - accuracy: 0.8104 - val_loss: 0.4566 - val_accuracy: 0.8202\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4413 - accuracy: 0.8102 - val_loss: 0.4546 - val_accuracy: 0.8168\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4388 - accuracy: 0.8129 - val_loss: 0.4614 - val_accuracy: 0.8115\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4401 - accuracy: 0.8133 - val_loss: 0.4590 - val_accuracy: 0.8080\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 9s 55ms/step - loss: 0.4409 - accuracy: 0.8160 - val_loss: 0.4736 - val_accuracy: 0.7941\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4398 - accuracy: 0.8108 - val_loss: 0.4577 - val_accuracy: 0.8133\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4376 - accuracy: 0.8131 - val_loss: 0.4618 - val_accuracy: 0.8168\n",
      "18/18 [==============================] - 1s 14ms/step\n",
      "Sn = 0.877966, Sp = 0.751799, Acc = 0.816754, MCC = 0.636197, AUC = 0.877649\n",
      "****************************** the 9 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 13s 64ms/step - loss: 0.4345 - accuracy: 0.8182 - val_loss: 0.4198 - val_accuracy: 0.8412\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4383 - accuracy: 0.8151 - val_loss: 0.4251 - val_accuracy: 0.8342\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4390 - accuracy: 0.8116 - val_loss: 0.4296 - val_accuracy: 0.8412\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4383 - accuracy: 0.8137 - val_loss: 0.4342 - val_accuracy: 0.8377\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4370 - accuracy: 0.8151 - val_loss: 0.4479 - val_accuracy: 0.8080\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4383 - accuracy: 0.8145 - val_loss: 0.4326 - val_accuracy: 0.8237\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 9s 52ms/step - loss: 0.4369 - accuracy: 0.8160 - val_loss: 0.4411 - val_accuracy: 0.8202\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4376 - accuracy: 0.8162 - val_loss: 0.4386 - val_accuracy: 0.8325\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4382 - accuracy: 0.8126 - val_loss: 0.4411 - val_accuracy: 0.8307\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4357 - accuracy: 0.8145 - val_loss: 0.4424 - val_accuracy: 0.8290\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 8s 51ms/step - loss: 0.4361 - accuracy: 0.8131 - val_loss: 0.4420 - val_accuracy: 0.8255\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4333 - accuracy: 0.8184 - val_loss: 0.4495 - val_accuracy: 0.8220\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4396 - accuracy: 0.8176 - val_loss: 0.4423 - val_accuracy: 0.8272\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4331 - accuracy: 0.8168 - val_loss: 0.4596 - val_accuracy: 0.8255\n",
      "18/18 [==============================] - 1s 14ms/step\n",
      "Sn = 0.898551, Sp = 0.757576, Acc = 0.825480, MCC = 0.660215, AUC = 0.883424\n",
      "****************************** the 10 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 12s 61ms/step - loss: 0.4282 - accuracy: 0.8255 - val_loss: 0.4319 - val_accuracy: 0.8080\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4297 - accuracy: 0.8224 - val_loss: 0.4417 - val_accuracy: 0.8063\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4359 - accuracy: 0.8172 - val_loss: 0.4412 - val_accuracy: 0.7993\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4329 - accuracy: 0.8172 - val_loss: 0.4466 - val_accuracy: 0.7976\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4323 - accuracy: 0.8217 - val_loss: 0.4467 - val_accuracy: 0.7976\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4311 - accuracy: 0.8170 - val_loss: 0.4593 - val_accuracy: 0.7993\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4276 - accuracy: 0.8215 - val_loss: 0.4534 - val_accuracy: 0.7941\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4313 - accuracy: 0.8217 - val_loss: 0.4613 - val_accuracy: 0.7941\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4307 - accuracy: 0.8215 - val_loss: 0.4623 - val_accuracy: 0.7923\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4291 - accuracy: 0.8205 - val_loss: 0.4600 - val_accuracy: 0.7888\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4305 - accuracy: 0.8213 - val_loss: 0.4573 - val_accuracy: 0.7993\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4293 - accuracy: 0.8172 - val_loss: 0.4541 - val_accuracy: 0.7853\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4299 - accuracy: 0.8190 - val_loss: 0.4528 - val_accuracy: 0.7836\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4293 - accuracy: 0.8186 - val_loss: 0.4754 - val_accuracy: 0.7818\n",
      "18/18 [==============================] - 1s 15ms/step\n",
      "Sn = 0.835821, Sp = 0.734426, Acc = 0.781850, MCC = 0.570247, AUC = 0.871507\n",
      "10 fold result: [[0.7284345  0.77011494 0.74738676 0.49650246 0.84483371]\n",
      " [0.76140351 0.79584775 0.77874564 0.55764747 0.84868573]\n",
      " [0.82593856 0.70714285 0.76788831 0.53756898 0.8726353 ]\n",
      " [0.81468531 0.80487805 0.80977312 0.61958601 0.8850296 ]\n",
      " [0.84859155 0.74394463 0.79581152 0.59546719 0.87399483]\n",
      " [0.84668989 0.73076923 0.78883072 0.58144677 0.87990059]\n",
      " [0.83512545 0.76190476 0.79755672 0.59781785 0.87680735]\n",
      " [0.8779661  0.75179856 0.81675393 0.63619717 0.87764907]\n",
      " [0.89855072 0.75757576 0.82547993 0.66021454 0.88342361]\n",
      " [0.83582089 0.73442623 0.78184991 0.57024713 0.87150722]]\n",
      "Sn = 0.8273 ± 0.0478\n",
      "Sp = 0.7558 ± 0.0280\n",
      "Acc = 0.7910 ± 0.0222\n",
      "Mcc = 0.5853 ± 0.0456\n",
      "Auc = 0.8714 ± 0.0130\n",
      "Epoch 1/200\n",
      "180/180 [==============================] - 12s 54ms/step - loss: 0.4282 - accuracy: 0.8186 - val_loss: 0.4810 - val_accuracy: 0.7893\n",
      "Epoch 2/200\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.4307 - accuracy: 0.8210"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 16:42:50.614596: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 8s 47ms/step - loss: 0.4307 - accuracy: 0.8210 - val_loss: 0.4800 - val_accuracy: 0.7940\n",
      "Epoch 3/200\n",
      "180/180 [==============================] - 9s 48ms/step - loss: 0.4317 - accuracy: 0.8214 - val_loss: 0.4747 - val_accuracy: 0.7925\n",
      "Epoch 4/200\n",
      "180/180 [==============================] - 9s 48ms/step - loss: 0.4311 - accuracy: 0.8200 - val_loss: 0.4811 - val_accuracy: 0.7972\n",
      "Epoch 5/200\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.4269 - accuracy: 0.8212 - val_loss: 0.4776 - val_accuracy: 0.7909\n",
      "Epoch 6/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.4295 - accuracy: 0.8173 - val_loss: 0.4774 - val_accuracy: 0.7956\n",
      "Epoch 7/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.4272 - accuracy: 0.8221 - val_loss: 0.4762 - val_accuracy: 0.8019\n",
      "Epoch 8/200\n",
      "180/180 [==============================] - 9s 47ms/step - loss: 0.4302 - accuracy: 0.8201 - val_loss: 0.4852 - val_accuracy: 0.7925\n",
      "Epoch 9/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.4263 - accuracy: 0.8227 - val_loss: 0.4926 - val_accuracy: 0.7877\n",
      "Epoch 10/200\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.4289 - accuracy: 0.8161 - val_loss: 0.4877 - val_accuracy: 0.7925\n",
      "Epoch 11/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.4254 - accuracy: 0.8210 - val_loss: 0.4821 - val_accuracy: 0.7987\n",
      "Epoch 12/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.4272 - accuracy: 0.8205 - val_loss: 0.4818 - val_accuracy: 0.7972\n",
      "Epoch 13/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.4233 - accuracy: 0.8215 - val_loss: 0.4787 - val_accuracy: 0.8035\n",
      "Epoch 14/200\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.4243 - accuracy: 0.8224 - val_loss: 0.4862 - val_accuracy: 0.7925\n",
      "Epoch 15/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.4265 - accuracy: 0.8198 - val_loss: 0.4881 - val_accuracy: 0.7925\n",
      "Epoch 16/200\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.4260 - accuracy: 0.8229 - val_loss: 0.4832 - val_accuracy: 0.7909\n",
      "Epoch 17/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.4259 - accuracy: 0.8240 - val_loss: 0.4824 - val_accuracy: 0.7909\n",
      "Epoch 18/200\n",
      "180/180 [==============================] - 9s 48ms/step - loss: 0.4199 - accuracy: 0.8299 - val_loss: 0.4831 - val_accuracy: 0.7956\n",
      "Epoch 19/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.4206 - accuracy: 0.8257 - val_loss: 0.4828 - val_accuracy: 0.7940\n",
      "Epoch 20/200\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.4237 - accuracy: 0.8222 - val_loss: 0.4958 - val_accuracy: 0.7846\n",
      "Epoch 21/200\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.4218 - accuracy: 0.8275 - val_loss: 0.4922 - val_accuracy: 0.7956\n",
      "Epoch 22/200\n",
      "180/180 [==============================] - 8s 43ms/step - loss: 0.4219 - accuracy: 0.8224 - val_loss: 0.4892 - val_accuracy: 0.7909\n",
      "Epoch 23/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.4188 - accuracy: 0.8254 - val_loss: 0.4951 - val_accuracy: 0.7956\n",
      "20/20 [==============================] - 1s 17ms/step\n",
      "-----------------------------------------------test---------------------------------------\n",
      "Sn = 0.823899, Sp = 0.767296, Acc = 0.795597, MCC = 0.592144, AUC = 0.861932\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "tf.random.set_seed(1)  # for reproducibility\n",
    "# reading model\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 200\n",
    "\n",
    "# # Cross-validation\n",
    "n = 10\n",
    "k_fold = KFold(n_splits=n, shuffle=True, random_state=42)\n",
    "\n",
    "all_performance = []\n",
    "tprs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "for fold_count, (train_index, val_index) in enumerate(k_fold.split(train)):\n",
    "    print('*' * 30 + ' the ' + str(fold_count + 1) + ' fold ' + '*' * 30)\n",
    "    trains, val = train[train_index], train[val_index]\n",
    "    trains_label, val_label = train_label[train_index], train_label[val_index]\n",
    "    zaoting = EarlyStopping(monitor='val_loss', patience=13, mode='auto')\n",
    "    xuexilv = WarmupExponentialDecay(lr_base=0.0002,decay=0.00002,warmup_epochs=2)\n",
    "    callback_lists=[xuexilv,zaoting]\n",
    "    model.fit(x=trains, y=trains_label, validation_data=(val, val_label), epochs=EPOCHS,\n",
    "                batch_size=BATCH_SIZE, shuffle=True,\n",
    "                callbacks=callback_lists,\n",
    "                verbose=1)\n",
    "     # 保存模型\n",
    "\n",
    "    model.save('./warmup_embedding/model_fold' + str(fold_count+1) + '.h5')\n",
    "\n",
    "    del model\n",
    "\n",
    "    model = load_model('./warmup_embedding/model_fold' + str(fold_count+1) + '.h5')\n",
    "\n",
    "    val_pred = model.predict(val, verbose=1)\n",
    "\n",
    "    # Sn, Sp, Acc, MCC, AUC\n",
    "    Sn, Sp, Acc, MCC = show_performance(val_label[:, 1], val_pred[:, 1])\n",
    "    AUC = roc_auc_score(val_label[:, 1], val_pred[:, 1])\n",
    "    print('Sn = %f, Sp = %f, Acc = %f, MCC = %f, AUC = %f' % (Sn, Sp, Acc, MCC, AUC))\n",
    "\n",
    "    performance = [Sn, Sp, Acc, MCC, AUC]\n",
    "    all_performance.append(performance)\n",
    "    \n",
    "all_performance = np.array(all_performance)\n",
    "print('10 fold result:', all_performance)\n",
    "performance_mean = performance_mean(all_performance)\n",
    "\n",
    "model.fit(x=train, y=train_label, validation_data=(test, test_label), epochs=EPOCHS,\n",
    "                      batch_size=BATCH_SIZE, shuffle=True,\n",
    "                      callbacks=[EarlyStopping(monitor='val_loss', patience=20, mode='auto')],\n",
    "                      verbose=1)\n",
    "model.save('./warmup_embedding/model_test.h5')\n",
    "\n",
    "del model\n",
    "\n",
    "model = load_model('./warmup_embedding/model_test.h5')\n",
    "\n",
    "test_score = model.predict(test)\n",
    "\n",
    "\n",
    "# Sn, Sp, Acc, MCC, AUC\n",
    "Sn, Sp, Acc, MCC = show_performance(test_label[:,1], test_score[:,1])\n",
    "AUC = roc_auc_score(test_label[:,1], test_score[:,1])\n",
    "\n",
    "print('-----------------------------------------------test---------------------------------------')\n",
    "print('Sn = %f, Sp = %f, Acc = %f, MCC = %f, AUC = %f' % (Sn, Sp, Acc, MCC, AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4331ebd3-0402-4741-ac62-43ae871e37df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************Warmup+embedding_64******************************\n",
      "(None, 15, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 15:12:05.962735: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4226 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:65:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 15, 48)\n",
      "****************************** the 1 fold ******************************\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 15:12:14.089159: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8800\n",
      "Could not load symbol cublasGetSmCountTarget from libcublas.so.11. Error: /usr/local/cuda/targets/x86_64-linux/lib/libcublas.so.11: undefined symbol: cublasGetSmCountTarget\n",
      "2024-06-05 15:12:14.349178: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-06-05 15:12:14.388630: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f2612ddaa10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-05 15:12:14.388649: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-06-05 15:12:14.391984: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-06-05 15:12:14.443062: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-05 15:12:14.445673: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:231] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.6\n",
      "2024-06-05 15:12:14.445694: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:234] Used ptxas at ptxas\n",
      "2024-06-05 15:12:14.463807: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-06-05 15:12:14.514145: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/162 [..............................] - ETA: 21:51 - loss: 3.2299 - accuracy: 0.4062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 15:12:14.980715: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-05 15:12:15.007390: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-05 15:12:15.007485: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-05 15:12:15.052756: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-05 15:12:15.075657: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4/162 [..............................] - ETA: 13s - loss: 3.2301 - accuracy: 0.4531 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 15:12:15.231119: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 19/162 [==>...........................] - ETA: 8s - loss: 3.2284 - accuracy: 0.4934"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 15:12:16.163962: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-05 15:12:16.357348: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 18s 61ms/step - loss: 3.1445 - accuracy: 0.5403 - val_loss: 2.9772 - val_accuracy: 0.6115\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 2.6962 - accuracy: 0.5900 - val_loss: 2.3648 - val_accuracy: 0.6638\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 2.0554 - accuracy: 0.6522 - val_loss: 1.8135 - val_accuracy: 0.6463\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 1.6269 - accuracy: 0.6623 - val_loss: 1.4783 - val_accuracy: 0.6603\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 1.3582 - accuracy: 0.6671 - val_loss: 1.2671 - val_accuracy: 0.6742\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 1.1866 - accuracy: 0.6714 - val_loss: 1.1328 - val_accuracy: 0.6672\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - ETA: 0s - loss: 1.0740 - accuracy: 0.6702"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 15:13:16.371743: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 9s 55ms/step - loss: 1.0740 - accuracy: 0.6702 - val_loss: 1.0351 - val_accuracy: 0.6864\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 8s 51ms/step - loss: 0.9992 - accuracy: 0.6685 - val_loss: 0.9822 - val_accuracy: 0.6690\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.9472 - accuracy: 0.6722 - val_loss: 0.9357 - val_accuracy: 0.6707\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.9086 - accuracy: 0.6714 - val_loss: 0.9085 - val_accuracy: 0.6707\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.8779 - accuracy: 0.6696 - val_loss: 0.8776 - val_accuracy: 0.6777\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.8525 - accuracy: 0.6727 - val_loss: 0.8600 - val_accuracy: 0.6812\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.8306 - accuracy: 0.6758 - val_loss: 0.8310 - val_accuracy: 0.7038\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.8084 - accuracy: 0.6799 - val_loss: 0.8066 - val_accuracy: 0.6969\n",
      "Epoch 15/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.7860 - accuracy: 0.6797 - val_loss: 0.7884 - val_accuracy: 0.6916\n",
      "Epoch 16/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.7660 - accuracy: 0.6884 - val_loss: 0.7641 - val_accuracy: 0.7038\n",
      "Epoch 17/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.7483 - accuracy: 0.6919 - val_loss: 0.7575 - val_accuracy: 0.6899\n",
      "Epoch 18/200\n",
      "162/162 [==============================] - ETA: 0s - loss: 0.7304 - accuracy: 0.6966"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 15:14:51.308058: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 9s 54ms/step - loss: 0.7304 - accuracy: 0.6966 - val_loss: 0.7347 - val_accuracy: 0.7108\n",
      "Epoch 19/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.7145 - accuracy: 0.7020 - val_loss: 0.7192 - val_accuracy: 0.6986\n",
      "Epoch 20/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.6989 - accuracy: 0.7067 - val_loss: 0.7024 - val_accuracy: 0.7021\n",
      "Epoch 21/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.6837 - accuracy: 0.7096 - val_loss: 0.6911 - val_accuracy: 0.7091\n",
      "Epoch 22/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.6705 - accuracy: 0.7109 - val_loss: 0.6790 - val_accuracy: 0.7160\n",
      "Epoch 23/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.6586 - accuracy: 0.7121 - val_loss: 0.6766 - val_accuracy: 0.6986\n",
      "Epoch 24/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.6463 - accuracy: 0.7181 - val_loss: 0.6618 - val_accuracy: 0.7178\n",
      "Epoch 25/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.6342 - accuracy: 0.7166 - val_loss: 0.6473 - val_accuracy: 0.7160\n",
      "Epoch 26/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.6214 - accuracy: 0.7286 - val_loss: 0.6468 - val_accuracy: 0.7160\n",
      "Epoch 27/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.6128 - accuracy: 0.7307 - val_loss: 0.6436 - val_accuracy: 0.7178\n",
      "Epoch 28/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.6041 - accuracy: 0.7334 - val_loss: 0.6275 - val_accuracy: 0.7073\n",
      "Epoch 29/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5930 - accuracy: 0.7352 - val_loss: 0.6165 - val_accuracy: 0.7265\n",
      "Epoch 30/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5858 - accuracy: 0.7423 - val_loss: 0.6059 - val_accuracy: 0.7317\n",
      "Epoch 31/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5784 - accuracy: 0.7447 - val_loss: 0.6120 - val_accuracy: 0.7073\n",
      "Epoch 32/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5714 - accuracy: 0.7406 - val_loss: 0.6071 - val_accuracy: 0.7125\n",
      "Epoch 33/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5660 - accuracy: 0.7449 - val_loss: 0.5979 - val_accuracy: 0.7143\n",
      "Epoch 34/200\n",
      "162/162 [==============================] - ETA: 0s - loss: 0.5622 - accuracy: 0.7423"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 15:17:10.093696: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 9s 55ms/step - loss: 0.5622 - accuracy: 0.7423 - val_loss: 0.5856 - val_accuracy: 0.7195\n",
      "Epoch 35/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5552 - accuracy: 0.7445 - val_loss: 0.5734 - val_accuracy: 0.7474\n",
      "Epoch 36/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5519 - accuracy: 0.7476 - val_loss: 0.5748 - val_accuracy: 0.7352\n",
      "Epoch 37/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5464 - accuracy: 0.7495 - val_loss: 0.5825 - val_accuracy: 0.7247\n",
      "Epoch 38/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5424 - accuracy: 0.7493 - val_loss: 0.5679 - val_accuracy: 0.7456\n",
      "Epoch 39/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5408 - accuracy: 0.7520 - val_loss: 0.5645 - val_accuracy: 0.7422\n",
      "Epoch 40/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5366 - accuracy: 0.7542 - val_loss: 0.5609 - val_accuracy: 0.7404\n",
      "Epoch 41/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5343 - accuracy: 0.7575 - val_loss: 0.5559 - val_accuracy: 0.7474\n",
      "Epoch 42/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5305 - accuracy: 0.7553 - val_loss: 0.5643 - val_accuracy: 0.7352\n",
      "Epoch 43/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5281 - accuracy: 0.7569 - val_loss: 0.5619 - val_accuracy: 0.7352\n",
      "Epoch 44/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5262 - accuracy: 0.7561 - val_loss: 0.5600 - val_accuracy: 0.7404\n",
      "Epoch 45/200\n",
      "162/162 [==============================] - 8s 51ms/step - loss: 0.5245 - accuracy: 0.7615 - val_loss: 0.5563 - val_accuracy: 0.7404\n",
      "Epoch 46/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5234 - accuracy: 0.7617 - val_loss: 0.5630 - val_accuracy: 0.7387\n",
      "Epoch 47/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.5216 - accuracy: 0.7573 - val_loss: 0.5537 - val_accuracy: 0.7456\n",
      "Epoch 48/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.5225 - accuracy: 0.7611 - val_loss: 0.5456 - val_accuracy: 0.7561\n",
      "Epoch 49/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.5167 - accuracy: 0.7641 - val_loss: 0.5551 - val_accuracy: 0.7491\n",
      "Epoch 50/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5162 - accuracy: 0.7642 - val_loss: 0.5486 - val_accuracy: 0.7456\n",
      "Epoch 51/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5159 - accuracy: 0.7621 - val_loss: 0.5515 - val_accuracy: 0.7404\n",
      "Epoch 52/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5148 - accuracy: 0.7660 - val_loss: 0.5433 - val_accuracy: 0.7544\n",
      "Epoch 53/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5136 - accuracy: 0.7668 - val_loss: 0.5431 - val_accuracy: 0.7509\n",
      "Epoch 54/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5118 - accuracy: 0.7679 - val_loss: 0.5606 - val_accuracy: 0.7387\n",
      "Epoch 55/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5120 - accuracy: 0.7691 - val_loss: 0.5625 - val_accuracy: 0.7387\n",
      "Epoch 56/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5119 - accuracy: 0.7677 - val_loss: 0.5516 - val_accuracy: 0.7422\n",
      "Epoch 57/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5113 - accuracy: 0.7675 - val_loss: 0.5423 - val_accuracy: 0.7422\n",
      "Epoch 58/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5080 - accuracy: 0.7679 - val_loss: 0.5572 - val_accuracy: 0.7369\n",
      "Epoch 59/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5077 - accuracy: 0.7710 - val_loss: 0.5453 - val_accuracy: 0.7456\n",
      "Epoch 60/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5079 - accuracy: 0.7716 - val_loss: 0.5483 - val_accuracy: 0.7300\n",
      "Epoch 61/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5061 - accuracy: 0.7722 - val_loss: 0.5557 - val_accuracy: 0.7300\n",
      "Epoch 62/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5088 - accuracy: 0.7631 - val_loss: 0.5411 - val_accuracy: 0.7491\n",
      "Epoch 63/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5056 - accuracy: 0.7683 - val_loss: 0.5461 - val_accuracy: 0.7404\n",
      "Epoch 64/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5033 - accuracy: 0.7705 - val_loss: 0.5454 - val_accuracy: 0.7352\n",
      "Epoch 65/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5025 - accuracy: 0.7753 - val_loss: 0.5379 - val_accuracy: 0.7439\n",
      "Epoch 66/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5038 - accuracy: 0.7712 - val_loss: 0.5478 - val_accuracy: 0.7456\n",
      "Epoch 67/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5025 - accuracy: 0.7668 - val_loss: 0.5526 - val_accuracy: 0.7300\n",
      "Epoch 68/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5045 - accuracy: 0.7720 - val_loss: 0.5438 - val_accuracy: 0.7439\n",
      "Epoch 69/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5049 - accuracy: 0.7712 - val_loss: 0.5443 - val_accuracy: 0.7404\n",
      "Epoch 70/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5010 - accuracy: 0.7745 - val_loss: 0.5463 - val_accuracy: 0.7456\n",
      "Epoch 71/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5017 - accuracy: 0.7763 - val_loss: 0.5410 - val_accuracy: 0.7404\n",
      "Epoch 72/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.5016 - accuracy: 0.7741 - val_loss: 0.5335 - val_accuracy: 0.7596\n",
      "Epoch 73/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4982 - accuracy: 0.7749 - val_loss: 0.5364 - val_accuracy: 0.7387\n",
      "Epoch 74/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.5000 - accuracy: 0.7736 - val_loss: 0.5492 - val_accuracy: 0.7317\n",
      "Epoch 75/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4976 - accuracy: 0.7767 - val_loss: 0.5503 - val_accuracy: 0.7352\n",
      "Epoch 76/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4960 - accuracy: 0.7747 - val_loss: 0.5401 - val_accuracy: 0.7439\n",
      "Epoch 77/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4967 - accuracy: 0.7743 - val_loss: 0.5482 - val_accuracy: 0.7369\n",
      "Epoch 78/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4982 - accuracy: 0.7695 - val_loss: 0.5331 - val_accuracy: 0.7474\n",
      "Epoch 79/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4973 - accuracy: 0.7761 - val_loss: 0.5413 - val_accuracy: 0.7404\n",
      "Epoch 80/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4912 - accuracy: 0.7803 - val_loss: 0.5391 - val_accuracy: 0.7422\n",
      "Epoch 81/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4943 - accuracy: 0.7801 - val_loss: 0.5339 - val_accuracy: 0.7474\n",
      "Epoch 82/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4944 - accuracy: 0.7803 - val_loss: 0.5444 - val_accuracy: 0.7352\n",
      "Epoch 83/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4935 - accuracy: 0.7774 - val_loss: 0.5342 - val_accuracy: 0.7509\n",
      "Epoch 84/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4905 - accuracy: 0.7801 - val_loss: 0.5522 - val_accuracy: 0.7334\n",
      "Epoch 85/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4918 - accuracy: 0.7801 - val_loss: 0.5370 - val_accuracy: 0.7474\n",
      "Epoch 86/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4917 - accuracy: 0.7800 - val_loss: 0.5322 - val_accuracy: 0.7596\n",
      "Epoch 87/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4933 - accuracy: 0.7763 - val_loss: 0.5312 - val_accuracy: 0.7526\n",
      "Epoch 88/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4881 - accuracy: 0.7765 - val_loss: 0.5410 - val_accuracy: 0.7474\n",
      "Epoch 89/200\n",
      "162/162 [==============================] - 8s 49ms/step - loss: 0.4894 - accuracy: 0.7786 - val_loss: 0.5461 - val_accuracy: 0.7439\n",
      "Epoch 90/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4885 - accuracy: 0.7788 - val_loss: 0.5332 - val_accuracy: 0.7439\n",
      "Epoch 91/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4880 - accuracy: 0.7819 - val_loss: 0.5601 - val_accuracy: 0.7160\n",
      "Epoch 92/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4873 - accuracy: 0.7817 - val_loss: 0.5368 - val_accuracy: 0.7352\n",
      "Epoch 93/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4887 - accuracy: 0.7829 - val_loss: 0.5402 - val_accuracy: 0.7334\n",
      "Epoch 94/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4834 - accuracy: 0.7831 - val_loss: 0.5296 - val_accuracy: 0.7509\n",
      "Epoch 95/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4878 - accuracy: 0.7782 - val_loss: 0.5304 - val_accuracy: 0.7474\n",
      "Epoch 96/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4849 - accuracy: 0.7842 - val_loss: 0.5258 - val_accuracy: 0.7544\n",
      "Epoch 97/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4845 - accuracy: 0.7834 - val_loss: 0.5472 - val_accuracy: 0.7439\n",
      "Epoch 98/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4833 - accuracy: 0.7788 - val_loss: 0.5235 - val_accuracy: 0.7596\n",
      "Epoch 99/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4823 - accuracy: 0.7834 - val_loss: 0.5497 - val_accuracy: 0.7282\n",
      "Epoch 100/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4820 - accuracy: 0.7864 - val_loss: 0.5396 - val_accuracy: 0.7474\n",
      "Epoch 101/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4823 - accuracy: 0.7838 - val_loss: 0.5255 - val_accuracy: 0.7544\n",
      "Epoch 102/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4823 - accuracy: 0.7836 - val_loss: 0.5350 - val_accuracy: 0.7456\n",
      "Epoch 103/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4850 - accuracy: 0.7846 - val_loss: 0.5386 - val_accuracy: 0.7456\n",
      "Epoch 104/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4811 - accuracy: 0.7832 - val_loss: 0.5409 - val_accuracy: 0.7422\n",
      "Epoch 105/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4822 - accuracy: 0.7805 - val_loss: 0.5345 - val_accuracy: 0.7509\n",
      "Epoch 106/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4813 - accuracy: 0.7881 - val_loss: 0.5312 - val_accuracy: 0.7456\n",
      "Epoch 107/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4816 - accuracy: 0.7829 - val_loss: 0.5275 - val_accuracy: 0.7474\n",
      "Epoch 108/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4807 - accuracy: 0.7829 - val_loss: 0.5326 - val_accuracy: 0.7474\n",
      "Epoch 109/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4802 - accuracy: 0.7860 - val_loss: 0.5226 - val_accuracy: 0.7700\n",
      "Epoch 110/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4787 - accuracy: 0.7836 - val_loss: 0.5398 - val_accuracy: 0.7491\n",
      "Epoch 111/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4766 - accuracy: 0.7891 - val_loss: 0.5262 - val_accuracy: 0.7596\n",
      "Epoch 112/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4801 - accuracy: 0.7844 - val_loss: 0.5227 - val_accuracy: 0.7613\n",
      "Epoch 113/200\n",
      "162/162 [==============================] - 9s 55ms/step - loss: 0.4758 - accuracy: 0.7864 - val_loss: 0.5458 - val_accuracy: 0.7439\n",
      "Epoch 114/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4763 - accuracy: 0.7902 - val_loss: 0.5186 - val_accuracy: 0.7631\n",
      "Epoch 115/200\n",
      "162/162 [==============================] - 9s 52ms/step - loss: 0.4776 - accuracy: 0.7875 - val_loss: 0.5484 - val_accuracy: 0.7334\n",
      "Epoch 116/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4754 - accuracy: 0.7873 - val_loss: 0.5280 - val_accuracy: 0.7491\n",
      "Epoch 117/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4748 - accuracy: 0.7873 - val_loss: 0.5195 - val_accuracy: 0.7613\n",
      "Epoch 118/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4761 - accuracy: 0.7864 - val_loss: 0.5447 - val_accuracy: 0.7352\n",
      "Epoch 119/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4781 - accuracy: 0.7838 - val_loss: 0.5252 - val_accuracy: 0.7526\n",
      "Epoch 120/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4744 - accuracy: 0.7914 - val_loss: 0.5406 - val_accuracy: 0.7439\n",
      "Epoch 121/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4752 - accuracy: 0.7840 - val_loss: 0.5369 - val_accuracy: 0.7456\n",
      "Epoch 122/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4768 - accuracy: 0.7854 - val_loss: 0.5212 - val_accuracy: 0.7648\n",
      "Epoch 123/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4750 - accuracy: 0.7867 - val_loss: 0.5362 - val_accuracy: 0.7456\n",
      "Epoch 124/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4738 - accuracy: 0.7879 - val_loss: 0.5225 - val_accuracy: 0.7596\n",
      "Epoch 125/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4727 - accuracy: 0.7858 - val_loss: 0.5488 - val_accuracy: 0.7404\n",
      "Epoch 126/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4746 - accuracy: 0.7873 - val_loss: 0.5427 - val_accuracy: 0.7369\n",
      "Epoch 127/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4723 - accuracy: 0.7891 - val_loss: 0.5489 - val_accuracy: 0.7352\n",
      "18/18 [==============================] - 1s 16ms/step\n",
      "Sn = 0.690096, Sp = 0.789272, Acc = 0.735192, MCC = 0.478140, AUC = 0.831760\n",
      "****************************** the 2 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 13s 60ms/step - loss: 0.4783 - accuracy: 0.7856 - val_loss: 0.4839 - val_accuracy: 0.7822\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 8s 51ms/step - loss: 0.4772 - accuracy: 0.7862 - val_loss: 0.4842 - val_accuracy: 0.7857\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4795 - accuracy: 0.7869 - val_loss: 0.4929 - val_accuracy: 0.7666\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4777 - accuracy: 0.7885 - val_loss: 0.4963 - val_accuracy: 0.7700\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4752 - accuracy: 0.7854 - val_loss: 0.4924 - val_accuracy: 0.7700\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 9s 55ms/step - loss: 0.4762 - accuracy: 0.7883 - val_loss: 0.5003 - val_accuracy: 0.7666\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4749 - accuracy: 0.7964 - val_loss: 0.4967 - val_accuracy: 0.7805\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4742 - accuracy: 0.7879 - val_loss: 0.4950 - val_accuracy: 0.7753\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4736 - accuracy: 0.7881 - val_loss: 0.4964 - val_accuracy: 0.7735\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4760 - accuracy: 0.7865 - val_loss: 0.4999 - val_accuracy: 0.7753\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4742 - accuracy: 0.7860 - val_loss: 0.5084 - val_accuracy: 0.7648\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4715 - accuracy: 0.7852 - val_loss: 0.4988 - val_accuracy: 0.7666\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4735 - accuracy: 0.7867 - val_loss: 0.5140 - val_accuracy: 0.7526\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4727 - accuracy: 0.7893 - val_loss: 0.5066 - val_accuracy: 0.7596\n",
      "18/18 [==============================] - 1s 15ms/step\n",
      "Sn = 0.740351, Sp = 0.778547, Acc = 0.759582, MCC = 0.519339, AUC = 0.849523\n",
      "****************************** the 3 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 13s 63ms/step - loss: 0.4702 - accuracy: 0.7926 - val_loss: 0.4671 - val_accuracy: 0.7801\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4722 - accuracy: 0.7883 - val_loss: 0.4701 - val_accuracy: 0.7731\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4717 - accuracy: 0.7938 - val_loss: 0.4749 - val_accuracy: 0.7696\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4757 - accuracy: 0.7877 - val_loss: 0.4728 - val_accuracy: 0.7714\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4718 - accuracy: 0.7893 - val_loss: 0.4861 - val_accuracy: 0.7853\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4732 - accuracy: 0.7940 - val_loss: 0.4858 - val_accuracy: 0.7696\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4721 - accuracy: 0.7899 - val_loss: 0.4807 - val_accuracy: 0.7609\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4722 - accuracy: 0.7914 - val_loss: 0.4882 - val_accuracy: 0.7853\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4743 - accuracy: 0.7914 - val_loss: 0.4809 - val_accuracy: 0.7644\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4706 - accuracy: 0.7910 - val_loss: 0.4812 - val_accuracy: 0.7836\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4701 - accuracy: 0.7891 - val_loss: 0.4832 - val_accuracy: 0.7627\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4679 - accuracy: 0.7932 - val_loss: 0.4955 - val_accuracy: 0.7609\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4709 - accuracy: 0.7885 - val_loss: 0.4846 - val_accuracy: 0.7714\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4692 - accuracy: 0.7876 - val_loss: 0.4903 - val_accuracy: 0.7557\n",
      "18/18 [==============================] - 1s 15ms/step\n",
      "Sn = 0.802048, Sp = 0.707143, Acc = 0.755672, MCC = 0.511969, AUC = 0.856009\n",
      "****************************** the 4 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 13s 62ms/step - loss: 0.4685 - accuracy: 0.7877 - val_loss: 0.4395 - val_accuracy: 0.8237\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4723 - accuracy: 0.7874 - val_loss: 0.4442 - val_accuracy: 0.8202\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4730 - accuracy: 0.7876 - val_loss: 0.4494 - val_accuracy: 0.8080\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4722 - accuracy: 0.7895 - val_loss: 0.4515 - val_accuracy: 0.8202\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4712 - accuracy: 0.7881 - val_loss: 0.4600 - val_accuracy: 0.7958\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4727 - accuracy: 0.7866 - val_loss: 0.4576 - val_accuracy: 0.8028\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4691 - accuracy: 0.7885 - val_loss: 0.4531 - val_accuracy: 0.8063\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4706 - accuracy: 0.7893 - val_loss: 0.4541 - val_accuracy: 0.8045\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4707 - accuracy: 0.7877 - val_loss: 0.4543 - val_accuracy: 0.7976\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4682 - accuracy: 0.7866 - val_loss: 0.4547 - val_accuracy: 0.8010\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4692 - accuracy: 0.7909 - val_loss: 0.4600 - val_accuracy: 0.8080\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 8s 51ms/step - loss: 0.4693 - accuracy: 0.7889 - val_loss: 0.4617 - val_accuracy: 0.8028\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4702 - accuracy: 0.7877 - val_loss: 0.4550 - val_accuracy: 0.8080\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4679 - accuracy: 0.7901 - val_loss: 0.4587 - val_accuracy: 0.7941\n",
      "18/18 [==============================] - 1s 19ms/step\n",
      "Sn = 0.790210, Sp = 0.797909, Acc = 0.794066, MCC = 0.588141, AUC = 0.878439\n",
      "****************************** the 5 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 12s 61ms/step - loss: 0.4626 - accuracy: 0.7926 - val_loss: 0.4484 - val_accuracy: 0.7976\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4655 - accuracy: 0.7909 - val_loss: 0.4535 - val_accuracy: 0.7976\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4685 - accuracy: 0.7905 - val_loss: 0.4613 - val_accuracy: 0.7923\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4657 - accuracy: 0.7922 - val_loss: 0.4661 - val_accuracy: 0.7906\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4665 - accuracy: 0.7965 - val_loss: 0.4609 - val_accuracy: 0.7871\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4671 - accuracy: 0.7940 - val_loss: 0.4651 - val_accuracy: 0.7993\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4666 - accuracy: 0.7947 - val_loss: 0.4726 - val_accuracy: 0.7871\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 55ms/step - loss: 0.4659 - accuracy: 0.7907 - val_loss: 0.4648 - val_accuracy: 0.7923\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4649 - accuracy: 0.7959 - val_loss: 0.4643 - val_accuracy: 0.7871\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 55ms/step - loss: 0.4650 - accuracy: 0.7971 - val_loss: 0.4685 - val_accuracy: 0.7976\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 55ms/step - loss: 0.4637 - accuracy: 0.7941 - val_loss: 0.4710 - val_accuracy: 0.7853\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4625 - accuracy: 0.7963 - val_loss: 0.4662 - val_accuracy: 0.7836\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4626 - accuracy: 0.7986 - val_loss: 0.4714 - val_accuracy: 0.7888\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4629 - accuracy: 0.7945 - val_loss: 0.4764 - val_accuracy: 0.7818\n",
      "18/18 [==============================] - 1s 14ms/step\n",
      "Sn = 0.859155, Sp = 0.705882, Acc = 0.781850, MCC = 0.571337, AUC = 0.870644\n",
      "****************************** the 6 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 13s 60ms/step - loss: 0.4583 - accuracy: 0.8002 - val_loss: 0.4425 - val_accuracy: 0.8080\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4613 - accuracy: 0.7963 - val_loss: 0.4414 - val_accuracy: 0.8133\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4652 - accuracy: 0.7972 - val_loss: 0.4488 - val_accuracy: 0.8080\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4663 - accuracy: 0.7953 - val_loss: 0.4539 - val_accuracy: 0.7976\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4611 - accuracy: 0.7953 - val_loss: 0.4513 - val_accuracy: 0.8115\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4623 - accuracy: 0.7936 - val_loss: 0.4483 - val_accuracy: 0.8045\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4605 - accuracy: 0.8002 - val_loss: 0.4540 - val_accuracy: 0.8010\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4627 - accuracy: 0.7994 - val_loss: 0.4574 - val_accuracy: 0.8063\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4622 - accuracy: 0.7971 - val_loss: 0.4594 - val_accuracy: 0.8028\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4591 - accuracy: 0.7953 - val_loss: 0.4550 - val_accuracy: 0.8010\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4626 - accuracy: 0.7934 - val_loss: 0.4560 - val_accuracy: 0.7993\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4583 - accuracy: 0.7978 - val_loss: 0.4570 - val_accuracy: 0.7958\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4622 - accuracy: 0.7982 - val_loss: 0.4635 - val_accuracy: 0.7976\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4613 - accuracy: 0.7963 - val_loss: 0.4645 - val_accuracy: 0.7958\n",
      "Epoch 15/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4606 - accuracy: 0.7974 - val_loss: 0.4613 - val_accuracy: 0.7993\n",
      "18/18 [==============================] - 1s 16ms/step\n",
      "Sn = 0.853659, Sp = 0.744755, Acc = 0.799302, MCC = 0.602063, AUC = 0.876453\n",
      "****************************** the 7 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 13s 61ms/step - loss: 0.4572 - accuracy: 0.7971 - val_loss: 0.4354 - val_accuracy: 0.8098\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4592 - accuracy: 0.8015 - val_loss: 0.4444 - val_accuracy: 0.7993\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4593 - accuracy: 0.8023 - val_loss: 0.4431 - val_accuracy: 0.7976\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4605 - accuracy: 0.8011 - val_loss: 0.4610 - val_accuracy: 0.7801\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4580 - accuracy: 0.8027 - val_loss: 0.4500 - val_accuracy: 0.8063\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4590 - accuracy: 0.7972 - val_loss: 0.4545 - val_accuracy: 0.7923\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4557 - accuracy: 0.8021 - val_loss: 0.4537 - val_accuracy: 0.7958\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4570 - accuracy: 0.7990 - val_loss: 0.4525 - val_accuracy: 0.7906\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4599 - accuracy: 0.7976 - val_loss: 0.4544 - val_accuracy: 0.7906\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4548 - accuracy: 0.8046 - val_loss: 0.4601 - val_accuracy: 0.7941\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4592 - accuracy: 0.8009 - val_loss: 0.4597 - val_accuracy: 0.7836\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4580 - accuracy: 0.8025 - val_loss: 0.4565 - val_accuracy: 0.7853\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4565 - accuracy: 0.8000 - val_loss: 0.4650 - val_accuracy: 0.7818\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4547 - accuracy: 0.8017 - val_loss: 0.4638 - val_accuracy: 0.7853\n",
      "18/18 [==============================] - 1s 15ms/step\n",
      "Sn = 0.853047, Sp = 0.721088, Acc = 0.785340, MCC = 0.577902, AUC = 0.873601\n",
      "****************************** the 8 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 13s 63ms/step - loss: 0.4512 - accuracy: 0.8025 - val_loss: 0.4466 - val_accuracy: 0.8098\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4501 - accuracy: 0.8017 - val_loss: 0.4518 - val_accuracy: 0.8185\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 8s 51ms/step - loss: 0.4552 - accuracy: 0.7955 - val_loss: 0.4596 - val_accuracy: 0.8150\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4525 - accuracy: 0.7986 - val_loss: 0.4574 - val_accuracy: 0.8080\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4552 - accuracy: 0.7992 - val_loss: 0.4675 - val_accuracy: 0.7976\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4563 - accuracy: 0.8017 - val_loss: 0.4789 - val_accuracy: 0.7906\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4522 - accuracy: 0.8035 - val_loss: 0.4604 - val_accuracy: 0.8133\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4538 - accuracy: 0.8002 - val_loss: 0.4679 - val_accuracy: 0.8010\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4521 - accuracy: 0.8044 - val_loss: 0.4674 - val_accuracy: 0.8098\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 8s 53ms/step - loss: 0.4509 - accuracy: 0.8040 - val_loss: 0.4745 - val_accuracy: 0.7958\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4518 - accuracy: 0.8042 - val_loss: 0.4672 - val_accuracy: 0.7976\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4513 - accuracy: 0.8058 - val_loss: 0.4880 - val_accuracy: 0.7888\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4485 - accuracy: 0.8054 - val_loss: 0.4756 - val_accuracy: 0.7958\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4495 - accuracy: 0.8056 - val_loss: 0.4832 - val_accuracy: 0.7993\n",
      "18/18 [==============================] - 1s 16ms/step\n",
      "Sn = 0.884746, Sp = 0.708633, Acc = 0.799302, MCC = 0.604570, AUC = 0.867394\n",
      "****************************** the 9 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 13s 62ms/step - loss: 0.4473 - accuracy: 0.8062 - val_loss: 0.4448 - val_accuracy: 0.8272\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4473 - accuracy: 0.8035 - val_loss: 0.4483 - val_accuracy: 0.8133\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4491 - accuracy: 0.8025 - val_loss: 0.4554 - val_accuracy: 0.8133\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4486 - accuracy: 0.8044 - val_loss: 0.4592 - val_accuracy: 0.8168\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4503 - accuracy: 0.8007 - val_loss: 0.4682 - val_accuracy: 0.8028\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4514 - accuracy: 0.7996 - val_loss: 0.4604 - val_accuracy: 0.8098\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4484 - accuracy: 0.8046 - val_loss: 0.4723 - val_accuracy: 0.8045\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4469 - accuracy: 0.8027 - val_loss: 0.4686 - val_accuracy: 0.8098\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4481 - accuracy: 0.8050 - val_loss: 0.4653 - val_accuracy: 0.8168\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4472 - accuracy: 0.8056 - val_loss: 0.4693 - val_accuracy: 0.8168\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4470 - accuracy: 0.8017 - val_loss: 0.4679 - val_accuracy: 0.7976\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 9s 55ms/step - loss: 0.4441 - accuracy: 0.8091 - val_loss: 0.4697 - val_accuracy: 0.8133\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4484 - accuracy: 0.8042 - val_loss: 0.4714 - val_accuracy: 0.7993\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4450 - accuracy: 0.8085 - val_loss: 0.4904 - val_accuracy: 0.8028\n",
      "18/18 [==============================] - 1s 15ms/step\n",
      "Sn = 0.905797, Sp = 0.707071, Acc = 0.802792, MCC = 0.622198, AUC = 0.870761\n",
      "****************************** the 10 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 12s 60ms/step - loss: 0.4439 - accuracy: 0.8118 - val_loss: 0.4318 - val_accuracy: 0.8080\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4461 - accuracy: 0.8083 - val_loss: 0.4410 - val_accuracy: 0.8028\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 8s 51ms/step - loss: 0.4491 - accuracy: 0.8075 - val_loss: 0.4453 - val_accuracy: 0.7976\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4466 - accuracy: 0.8100 - val_loss: 0.4449 - val_accuracy: 0.7993\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 8s 52ms/step - loss: 0.4476 - accuracy: 0.8102 - val_loss: 0.4460 - val_accuracy: 0.7923\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4466 - accuracy: 0.8131 - val_loss: 0.4566 - val_accuracy: 0.7818\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4440 - accuracy: 0.8129 - val_loss: 0.4530 - val_accuracy: 0.7958\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4452 - accuracy: 0.8116 - val_loss: 0.4622 - val_accuracy: 0.7853\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4448 - accuracy: 0.8116 - val_loss: 0.4603 - val_accuracy: 0.7836\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4438 - accuracy: 0.8085 - val_loss: 0.4602 - val_accuracy: 0.7958\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4430 - accuracy: 0.8141 - val_loss: 0.4508 - val_accuracy: 0.7941\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 9s 53ms/step - loss: 0.4440 - accuracy: 0.8089 - val_loss: 0.4525 - val_accuracy: 0.7993\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4428 - accuracy: 0.8097 - val_loss: 0.4556 - val_accuracy: 0.7958\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 9s 54ms/step - loss: 0.4400 - accuracy: 0.8108 - val_loss: 0.4767 - val_accuracy: 0.7836\n",
      "18/18 [==============================] - 1s 16ms/step\n",
      "Sn = 0.865672, Sp = 0.711475, Acc = 0.783595, MCC = 0.579921, AUC = 0.875777\n",
      "10 fold result: [[0.69009584 0.78927203 0.73519164 0.47814035 0.83176037]\n",
      " [0.74035087 0.77854671 0.75958188 0.51933915 0.84952346]\n",
      " [0.80204778 0.70714285 0.7556719  0.51196895 0.85600926]\n",
      " [0.79020979 0.7979094  0.79406632 0.58814069 0.87843863]\n",
      " [0.85915493 0.70588235 0.78184991 0.57133698 0.87064428]\n",
      " [0.85365853 0.74475524 0.79930192 0.60206295 0.87645282]\n",
      " [0.85304659 0.72108843 0.78534031 0.57790249 0.87360105]\n",
      " [0.88474576 0.70863309 0.79930192 0.60456977 0.86739422]\n",
      " [0.9057971  0.7070707  0.80279232 0.62219802 0.87076075]\n",
      " [0.86567164 0.71147541 0.78359511 0.57992062 0.87577685]]\n",
      "Sn = 0.8245 ± 0.0645\n",
      "Sp = 0.7372 ± 0.0356\n",
      "Acc = 0.7797 ± 0.0213\n",
      "Mcc = 0.5656 ± 0.0443\n",
      "Auc = 0.8650 ± 0.0141\n",
      "Epoch 1/200\n",
      "180/180 [==============================] - 13s 54ms/step - loss: 0.4457 - accuracy: 0.8102 - val_loss: 0.4768 - val_accuracy: 0.8050\n",
      "Epoch 2/200\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.4410 - accuracy: 0.8109"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 15:50:11.179104: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 8s 46ms/step - loss: 0.4410 - accuracy: 0.8109 - val_loss: 0.4768 - val_accuracy: 0.8082\n",
      "Epoch 3/200\n",
      "180/180 [==============================] - 9s 48ms/step - loss: 0.4449 - accuracy: 0.8102 - val_loss: 0.4770 - val_accuracy: 0.8003\n",
      "Epoch 4/200\n",
      "180/180 [==============================] - 9s 48ms/step - loss: 0.4428 - accuracy: 0.8095 - val_loss: 0.4826 - val_accuracy: 0.8019\n",
      "Epoch 5/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.4418 - accuracy: 0.8137 - val_loss: 0.4743 - val_accuracy: 0.8050\n",
      "Epoch 6/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.4421 - accuracy: 0.8118 - val_loss: 0.4764 - val_accuracy: 0.8082\n",
      "Epoch 7/200\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.4412 - accuracy: 0.8109 - val_loss: 0.4738 - val_accuracy: 0.8019\n",
      "Epoch 8/200\n",
      "180/180 [==============================] - 9s 47ms/step - loss: 0.4424 - accuracy: 0.8114 - val_loss: 0.4852 - val_accuracy: 0.7940\n",
      "Epoch 9/200\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.4432 - accuracy: 0.8128 - val_loss: 0.4825 - val_accuracy: 0.7909\n",
      "Epoch 10/200\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.4395 - accuracy: 0.8139 - val_loss: 0.4813 - val_accuracy: 0.8066\n",
      "Epoch 11/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.4402 - accuracy: 0.8116 - val_loss: 0.4760 - val_accuracy: 0.8082\n",
      "Epoch 12/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.4396 - accuracy: 0.8130 - val_loss: 0.4742 - val_accuracy: 0.8129\n",
      "Epoch 13/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.4365 - accuracy: 0.8156 - val_loss: 0.4738 - val_accuracy: 0.8097\n",
      "Epoch 14/200\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.4402 - accuracy: 0.8152 - val_loss: 0.4774 - val_accuracy: 0.8113\n",
      "Epoch 15/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.4387 - accuracy: 0.8142 - val_loss: 0.4800 - val_accuracy: 0.8035\n",
      "Epoch 16/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.4368 - accuracy: 0.8189 - val_loss: 0.4801 - val_accuracy: 0.7909\n",
      "Epoch 17/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.4380 - accuracy: 0.8137 - val_loss: 0.4819 - val_accuracy: 0.7987\n",
      "Epoch 18/200\n",
      "180/180 [==============================] - 8s 45ms/step - loss: 0.4366 - accuracy: 0.8175 - val_loss: 0.4812 - val_accuracy: 0.7972\n",
      "Epoch 19/200\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.4342 - accuracy: 0.8144 - val_loss: 0.4840 - val_accuracy: 0.7987\n",
      "Epoch 20/200\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.4385 - accuracy: 0.8159 - val_loss: 0.4860 - val_accuracy: 0.8082\n",
      "Epoch 21/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.4361 - accuracy: 0.8215 - val_loss: 0.4814 - val_accuracy: 0.8145\n",
      "Epoch 22/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.4350 - accuracy: 0.8140 - val_loss: 0.4780 - val_accuracy: 0.8097\n",
      "Epoch 23/200\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.4359 - accuracy: 0.8194 - val_loss: 0.4818 - val_accuracy: 0.8035\n",
      "Epoch 24/200\n",
      "180/180 [==============================] - 8s 46ms/step - loss: 0.4344 - accuracy: 0.8200 - val_loss: 0.4777 - val_accuracy: 0.8097\n",
      "Epoch 25/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.4342 - accuracy: 0.8173 - val_loss: 0.4890 - val_accuracy: 0.7830\n",
      "Epoch 26/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.4342 - accuracy: 0.8198 - val_loss: 0.4747 - val_accuracy: 0.8035\n",
      "Epoch 27/200\n",
      "180/180 [==============================] - 8s 47ms/step - loss: 0.4335 - accuracy: 0.8222 - val_loss: 0.4965 - val_accuracy: 0.7877\n",
      "20/20 [==============================] - 1s 15ms/step\n",
      "-----------------------------------------------test---------------------------------------\n",
      "Sn = 0.786164, Sp = 0.789308, Acc = 0.787736, MCC = 0.575475, AUC = 0.863910\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "tf.random.set_seed(1)  # for reproducibility\n",
    "# reading model\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 200\n",
    "\n",
    "# # Cross-validation\n",
    "n = 10\n",
    "k_fold = KFold(n_splits=n, shuffle=True, random_state=42)\n",
    "\n",
    "all_performance = []\n",
    "tprs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "for fold_count, (train_index, val_index) in enumerate(k_fold.split(train)):\n",
    "    print('*' * 30 + ' the ' + str(fold_count + 1) + ' fold ' + '*' * 30)\n",
    "    trains, val = train[train_index], train[val_index]\n",
    "    trains_label, val_label = train_label[train_index], train_label[val_index]\n",
    "    zaoting = EarlyStopping(monitor='val_loss', patience=13, mode='auto')\n",
    "    xuexilv = WarmupExponentialDecay(lr_base=0.0002,decay=0.00002,warmup_epochs=2)\n",
    "    callback_lists=[xuexilv,zaoting]\n",
    "    model.fit(x=trains, y=trains_label, validation_data=(val, val_label), epochs=EPOCHS,\n",
    "                batch_size=BATCH_SIZE, shuffle=True,\n",
    "                callbacks=callback_lists,\n",
    "                verbose=1)\n",
    "     # 保存模型\n",
    "\n",
    "    model.save('./warmup_embedding/model_fold' + str(fold_count+1) + '.h5')\n",
    "\n",
    "    del model\n",
    "\n",
    "    model = load_model('./warmup_embedding/model_fold' + str(fold_count+1) + '.h5')\n",
    "\n",
    "    val_pred = model.predict(val, verbose=1)\n",
    "\n",
    "    # Sn, Sp, Acc, MCC, AUC\n",
    "    Sn, Sp, Acc, MCC = show_performance(val_label[:, 1], val_pred[:, 1])\n",
    "    AUC = roc_auc_score(val_label[:, 1], val_pred[:, 1])\n",
    "    print('Sn = %f, Sp = %f, Acc = %f, MCC = %f, AUC = %f' % (Sn, Sp, Acc, MCC, AUC))\n",
    "\n",
    "    performance = [Sn, Sp, Acc, MCC, AUC]\n",
    "    all_performance.append(performance)\n",
    "    \n",
    "all_performance = np.array(all_performance)\n",
    "print('10 fold result:', all_performance)\n",
    "performance_mean = performance_mean(all_performance)\n",
    "\n",
    "model.fit(x=train, y=train_label, validation_data=(test, test_label), epochs=EPOCHS,\n",
    "                      batch_size=BATCH_SIZE, shuffle=True,\n",
    "                      callbacks=[EarlyStopping(monitor='val_loss', patience=20, mode='auto')],\n",
    "                      verbose=1)\n",
    "model.save('./warmup_embedding/model_test.h5')\n",
    "\n",
    "del model\n",
    "\n",
    "model = load_model('./warmup_embedding/model_test.h5')\n",
    "\n",
    "test_score = model.predict(test)\n",
    "\n",
    "\n",
    "# Sn, Sp, Acc, MCC, AUC\n",
    "Sn, Sp, Acc, MCC = show_performance(test_label[:,1], test_score[:,1])\n",
    "AUC = roc_auc_score(test_label[:,1], test_score[:,1])\n",
    "\n",
    "print('-----------------------------------------------test---------------------------------------')\n",
    "print('Sn = %f, Sp = %f, Acc = %f, MCC = %f, AUC = %f' % (Sn, Sp, Acc, MCC, AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a58ee25-f191-49da-b73c-152224503940",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************Warmup+embedding_32******************************\n",
      "(None, 15, 32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 12:09:52.806821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8976 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:65:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 15, 48)\n",
      "****************************** the 1 fold ******************************\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 12:09:59.849609: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8800\n",
      "Could not load symbol cublasGetSmCountTarget from libcublas.so.11. Error: /usr/local/cuda/targets/x86_64-linux/lib/libcublas.so.11: undefined symbol: cublasGetSmCountTarget\n",
      "2024-06-05 12:10:00.092845: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-06-05 12:10:00.119126: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f659baa64d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-05 12:10:00.119147: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-06-05 12:10:00.122437: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-06-05 12:10:00.171834: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-05 12:10:00.174599: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:231] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.6\n",
      "2024-06-05 12:10:00.174610: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:234] Used ptxas at ptxas\n",
      "2024-06-05 12:10:00.187550: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-06-05 12:10:00.237833: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/162 [..............................] - ETA: 18:48 - loss: 3.2193 - accuracy: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 12:10:00.619935: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-05 12:10:00.626212: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-05 12:10:00.637207: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-05 12:10:00.692763: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-05 12:10:00.708470: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6/162 [>.............................] - ETA: 8s - loss: 3.2179 - accuracy: 0.5521 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 12:10:00.837775: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 19/162 [==>...........................] - ETA: 6s - loss: 3.2172 - accuracy: 0.5197"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 12:10:01.520064: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-05 12:10:01.695638: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 14s 44ms/step - loss: 3.1345 - accuracy: 0.5198 - val_loss: 2.9689 - val_accuracy: 0.5348\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 6s 34ms/step - loss: 2.6930 - accuracy: 0.5556 - val_loss: 2.3758 - val_accuracy: 0.6463\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 2.0624 - accuracy: 0.6516 - val_loss: 1.8188 - val_accuracy: 0.6411\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 1.6276 - accuracy: 0.6588 - val_loss: 1.4802 - val_accuracy: 0.6655\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 1.3606 - accuracy: 0.6632 - val_loss: 1.2677 - val_accuracy: 0.6725\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 1.1882 - accuracy: 0.6650 - val_loss: 1.1355 - val_accuracy: 0.6655\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - ETA: 0s - loss: 1.0759 - accuracy: 0.6693"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 12:10:41.980152: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 6s 36ms/step - loss: 1.0759 - accuracy: 0.6693 - val_loss: 1.0368 - val_accuracy: 0.6847\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 1.0012 - accuracy: 0.6650 - val_loss: 0.9855 - val_accuracy: 0.6655\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.9485 - accuracy: 0.6710 - val_loss: 0.9378 - val_accuracy: 0.6707\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.9100 - accuracy: 0.6696 - val_loss: 0.9119 - val_accuracy: 0.6585\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.8801 - accuracy: 0.6689 - val_loss: 0.8792 - val_accuracy: 0.6707\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.8551 - accuracy: 0.6714 - val_loss: 0.8638 - val_accuracy: 0.6638\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.8351 - accuracy: 0.6693 - val_loss: 0.8367 - val_accuracy: 0.6829\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.8160 - accuracy: 0.6685 - val_loss: 0.8153 - val_accuracy: 0.6777\n",
      "Epoch 15/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.7977 - accuracy: 0.6696 - val_loss: 0.8011 - val_accuracy: 0.6777\n",
      "Epoch 16/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.7814 - accuracy: 0.6702 - val_loss: 0.7807 - val_accuracy: 0.6760\n",
      "Epoch 17/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.7657 - accuracy: 0.6724 - val_loss: 0.7715 - val_accuracy: 0.6777\n",
      "Epoch 18/200\n",
      "162/162 [==============================] - ETA: 0s - loss: 0.7508 - accuracy: 0.6733"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 12:11:46.189561: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 6s 37ms/step - loss: 0.7508 - accuracy: 0.6733 - val_loss: 0.7510 - val_accuracy: 0.6899\n",
      "Epoch 19/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.7363 - accuracy: 0.6762 - val_loss: 0.7381 - val_accuracy: 0.6742\n",
      "Epoch 20/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.7226 - accuracy: 0.6807 - val_loss: 0.7265 - val_accuracy: 0.6899\n",
      "Epoch 21/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.7081 - accuracy: 0.6782 - val_loss: 0.7140 - val_accuracy: 0.6934\n",
      "Epoch 22/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.6960 - accuracy: 0.6842 - val_loss: 0.6985 - val_accuracy: 0.6899\n",
      "Epoch 23/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.6852 - accuracy: 0.6853 - val_loss: 0.6937 - val_accuracy: 0.6916\n",
      "Epoch 24/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.6740 - accuracy: 0.6914 - val_loss: 0.6796 - val_accuracy: 0.6916\n",
      "Epoch 25/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.6636 - accuracy: 0.6894 - val_loss: 0.6733 - val_accuracy: 0.6847\n",
      "Epoch 26/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.6538 - accuracy: 0.6912 - val_loss: 0.6684 - val_accuracy: 0.6760\n",
      "Epoch 27/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.6460 - accuracy: 0.6923 - val_loss: 0.6653 - val_accuracy: 0.6760\n",
      "Epoch 28/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.6382 - accuracy: 0.6981 - val_loss: 0.6499 - val_accuracy: 0.6934\n",
      "Epoch 29/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.6287 - accuracy: 0.6948 - val_loss: 0.6413 - val_accuracy: 0.6847\n",
      "Epoch 30/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.6229 - accuracy: 0.7005 - val_loss: 0.6313 - val_accuracy: 0.6829\n",
      "Epoch 31/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.6150 - accuracy: 0.7045 - val_loss: 0.6363 - val_accuracy: 0.6829\n",
      "Epoch 32/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.6079 - accuracy: 0.7026 - val_loss: 0.6271 - val_accuracy: 0.6934\n",
      "Epoch 33/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.6011 - accuracy: 0.7073 - val_loss: 0.6255 - val_accuracy: 0.6864\n",
      "Epoch 34/200\n",
      "162/162 [==============================] - ETA: 0s - loss: 0.5946 - accuracy: 0.7117"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 12:13:19.109746: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5946 - accuracy: 0.7117 - val_loss: 0.6059 - val_accuracy: 0.7021\n",
      "Epoch 35/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5868 - accuracy: 0.7168 - val_loss: 0.5993 - val_accuracy: 0.7073\n",
      "Epoch 36/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5814 - accuracy: 0.7168 - val_loss: 0.6014 - val_accuracy: 0.7160\n",
      "Epoch 37/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5758 - accuracy: 0.7255 - val_loss: 0.6164 - val_accuracy: 0.6899\n",
      "Epoch 38/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5702 - accuracy: 0.7299 - val_loss: 0.5957 - val_accuracy: 0.7143\n",
      "Epoch 39/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5650 - accuracy: 0.7309 - val_loss: 0.5916 - val_accuracy: 0.7265\n",
      "Epoch 40/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5582 - accuracy: 0.7385 - val_loss: 0.5871 - val_accuracy: 0.7247\n",
      "Epoch 41/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5559 - accuracy: 0.7305 - val_loss: 0.5817 - val_accuracy: 0.7317\n",
      "Epoch 42/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5504 - accuracy: 0.7408 - val_loss: 0.5851 - val_accuracy: 0.7265\n",
      "Epoch 43/200\n",
      "162/162 [==============================] - 5s 34ms/step - loss: 0.5465 - accuracy: 0.7408 - val_loss: 0.5845 - val_accuracy: 0.7125\n",
      "Epoch 44/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5460 - accuracy: 0.7406 - val_loss: 0.5853 - val_accuracy: 0.7195\n",
      "Epoch 45/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5424 - accuracy: 0.7439 - val_loss: 0.5729 - val_accuracy: 0.7369\n",
      "Epoch 46/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5392 - accuracy: 0.7485 - val_loss: 0.5831 - val_accuracy: 0.7160\n",
      "Epoch 47/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5373 - accuracy: 0.7468 - val_loss: 0.5718 - val_accuracy: 0.7247\n",
      "Epoch 48/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5373 - accuracy: 0.7449 - val_loss: 0.5597 - val_accuracy: 0.7509\n",
      "Epoch 49/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5300 - accuracy: 0.7579 - val_loss: 0.5674 - val_accuracy: 0.7247\n",
      "Epoch 50/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5314 - accuracy: 0.7526 - val_loss: 0.5598 - val_accuracy: 0.7282\n",
      "Epoch 51/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5298 - accuracy: 0.7536 - val_loss: 0.5679 - val_accuracy: 0.7230\n",
      "Epoch 52/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5279 - accuracy: 0.7580 - val_loss: 0.5533 - val_accuracy: 0.7439\n",
      "Epoch 53/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5266 - accuracy: 0.7520 - val_loss: 0.5524 - val_accuracy: 0.7334\n",
      "Epoch 54/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5246 - accuracy: 0.7553 - val_loss: 0.5751 - val_accuracy: 0.7265\n",
      "Epoch 55/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5250 - accuracy: 0.7528 - val_loss: 0.5738 - val_accuracy: 0.7247\n",
      "Epoch 56/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5251 - accuracy: 0.7540 - val_loss: 0.5630 - val_accuracy: 0.7300\n",
      "Epoch 57/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5238 - accuracy: 0.7557 - val_loss: 0.5505 - val_accuracy: 0.7404\n",
      "Epoch 58/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5224 - accuracy: 0.7573 - val_loss: 0.5673 - val_accuracy: 0.7265\n",
      "Epoch 59/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5215 - accuracy: 0.7563 - val_loss: 0.5508 - val_accuracy: 0.7509\n",
      "Epoch 60/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5202 - accuracy: 0.7596 - val_loss: 0.5619 - val_accuracy: 0.7456\n",
      "Epoch 61/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5184 - accuracy: 0.7631 - val_loss: 0.5686 - val_accuracy: 0.7160\n",
      "Epoch 62/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5184 - accuracy: 0.7553 - val_loss: 0.5469 - val_accuracy: 0.7404\n",
      "Epoch 63/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5175 - accuracy: 0.7590 - val_loss: 0.5537 - val_accuracy: 0.7387\n",
      "Epoch 64/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5162 - accuracy: 0.7592 - val_loss: 0.5529 - val_accuracy: 0.7404\n",
      "Epoch 65/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5145 - accuracy: 0.7652 - val_loss: 0.5441 - val_accuracy: 0.7491\n",
      "Epoch 66/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5147 - accuracy: 0.7621 - val_loss: 0.5589 - val_accuracy: 0.7282\n",
      "Epoch 67/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5134 - accuracy: 0.7637 - val_loss: 0.5559 - val_accuracy: 0.7334\n",
      "Epoch 68/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5137 - accuracy: 0.7619 - val_loss: 0.5498 - val_accuracy: 0.7387\n",
      "Epoch 69/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5136 - accuracy: 0.7621 - val_loss: 0.5519 - val_accuracy: 0.7369\n",
      "Epoch 70/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5124 - accuracy: 0.7633 - val_loss: 0.5489 - val_accuracy: 0.7422\n",
      "Epoch 71/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5117 - accuracy: 0.7648 - val_loss: 0.5439 - val_accuracy: 0.7387\n",
      "Epoch 72/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5113 - accuracy: 0.7641 - val_loss: 0.5383 - val_accuracy: 0.7544\n",
      "Epoch 73/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5090 - accuracy: 0.7639 - val_loss: 0.5407 - val_accuracy: 0.7509\n",
      "Epoch 74/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5096 - accuracy: 0.7652 - val_loss: 0.5505 - val_accuracy: 0.7247\n",
      "Epoch 75/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5104 - accuracy: 0.7656 - val_loss: 0.5575 - val_accuracy: 0.7265\n",
      "Epoch 76/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5076 - accuracy: 0.7631 - val_loss: 0.5426 - val_accuracy: 0.7439\n",
      "Epoch 77/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5077 - accuracy: 0.7670 - val_loss: 0.5513 - val_accuracy: 0.7317\n",
      "Epoch 78/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5093 - accuracy: 0.7654 - val_loss: 0.5351 - val_accuracy: 0.7526\n",
      "Epoch 79/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5097 - accuracy: 0.7685 - val_loss: 0.5466 - val_accuracy: 0.7352\n",
      "Epoch 80/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5047 - accuracy: 0.7668 - val_loss: 0.5403 - val_accuracy: 0.7491\n",
      "Epoch 81/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5038 - accuracy: 0.7701 - val_loss: 0.5359 - val_accuracy: 0.7578\n",
      "Epoch 82/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5064 - accuracy: 0.7679 - val_loss: 0.5527 - val_accuracy: 0.7300\n",
      "Epoch 83/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5049 - accuracy: 0.7664 - val_loss: 0.5324 - val_accuracy: 0.7526\n",
      "Epoch 84/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5048 - accuracy: 0.7679 - val_loss: 0.5601 - val_accuracy: 0.7282\n",
      "Epoch 85/200\n",
      "162/162 [==============================] - 4s 26ms/step - loss: 0.5023 - accuracy: 0.7716 - val_loss: 0.5378 - val_accuracy: 0.7526\n",
      "Epoch 86/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5045 - accuracy: 0.7679 - val_loss: 0.5380 - val_accuracy: 0.7561\n",
      "Epoch 87/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5024 - accuracy: 0.7666 - val_loss: 0.5364 - val_accuracy: 0.7509\n",
      "Epoch 88/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5015 - accuracy: 0.7703 - val_loss: 0.5414 - val_accuracy: 0.7456\n",
      "Epoch 89/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.5020 - accuracy: 0.7679 - val_loss: 0.5486 - val_accuracy: 0.7352\n",
      "Epoch 90/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.5001 - accuracy: 0.7703 - val_loss: 0.5313 - val_accuracy: 0.7578\n",
      "Epoch 91/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4999 - accuracy: 0.7736 - val_loss: 0.5646 - val_accuracy: 0.7247\n",
      "Epoch 92/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4992 - accuracy: 0.7734 - val_loss: 0.5436 - val_accuracy: 0.7422\n",
      "Epoch 93/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4985 - accuracy: 0.7734 - val_loss: 0.5437 - val_accuracy: 0.7387\n",
      "Epoch 94/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4968 - accuracy: 0.7759 - val_loss: 0.5302 - val_accuracy: 0.7352\n",
      "Epoch 95/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4969 - accuracy: 0.7765 - val_loss: 0.5329 - val_accuracy: 0.7491\n",
      "Epoch 96/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4991 - accuracy: 0.7695 - val_loss: 0.5256 - val_accuracy: 0.7509\n",
      "Epoch 97/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4968 - accuracy: 0.7739 - val_loss: 0.5485 - val_accuracy: 0.7387\n",
      "Epoch 98/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4940 - accuracy: 0.7724 - val_loss: 0.5263 - val_accuracy: 0.7456\n",
      "Epoch 99/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4956 - accuracy: 0.7815 - val_loss: 0.5596 - val_accuracy: 0.7282\n",
      "Epoch 100/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4961 - accuracy: 0.7772 - val_loss: 0.5415 - val_accuracy: 0.7439\n",
      "Epoch 101/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4945 - accuracy: 0.7743 - val_loss: 0.5287 - val_accuracy: 0.7526\n",
      "Epoch 102/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4928 - accuracy: 0.7790 - val_loss: 0.5362 - val_accuracy: 0.7422\n",
      "Epoch 103/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4948 - accuracy: 0.7792 - val_loss: 0.5405 - val_accuracy: 0.7509\n",
      "Epoch 104/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4961 - accuracy: 0.7757 - val_loss: 0.5397 - val_accuracy: 0.7456\n",
      "Epoch 105/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4922 - accuracy: 0.7736 - val_loss: 0.5379 - val_accuracy: 0.7456\n",
      "Epoch 106/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4927 - accuracy: 0.7745 - val_loss: 0.5400 - val_accuracy: 0.7474\n",
      "Epoch 107/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4913 - accuracy: 0.7823 - val_loss: 0.5314 - val_accuracy: 0.7474\n",
      "Epoch 108/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4921 - accuracy: 0.7780 - val_loss: 0.5285 - val_accuracy: 0.7526\n",
      "Epoch 109/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4925 - accuracy: 0.7778 - val_loss: 0.5221 - val_accuracy: 0.7596\n",
      "Epoch 110/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4929 - accuracy: 0.7784 - val_loss: 0.5388 - val_accuracy: 0.7491\n",
      "Epoch 111/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4893 - accuracy: 0.7827 - val_loss: 0.5275 - val_accuracy: 0.7491\n",
      "Epoch 112/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4925 - accuracy: 0.7765 - val_loss: 0.5212 - val_accuracy: 0.7596\n",
      "Epoch 113/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4905 - accuracy: 0.7800 - val_loss: 0.5507 - val_accuracy: 0.7404\n",
      "Epoch 114/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4906 - accuracy: 0.7757 - val_loss: 0.5202 - val_accuracy: 0.7596\n",
      "Epoch 115/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4909 - accuracy: 0.7790 - val_loss: 0.5514 - val_accuracy: 0.7456\n",
      "Epoch 116/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4900 - accuracy: 0.7796 - val_loss: 0.5316 - val_accuracy: 0.7456\n",
      "Epoch 117/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4894 - accuracy: 0.7796 - val_loss: 0.5188 - val_accuracy: 0.7613\n",
      "Epoch 118/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4893 - accuracy: 0.7803 - val_loss: 0.5577 - val_accuracy: 0.7404\n",
      "Epoch 119/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4913 - accuracy: 0.7782 - val_loss: 0.5278 - val_accuracy: 0.7526\n",
      "Epoch 120/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4854 - accuracy: 0.7879 - val_loss: 0.5427 - val_accuracy: 0.7387\n",
      "Epoch 121/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4883 - accuracy: 0.7770 - val_loss: 0.5442 - val_accuracy: 0.7404\n",
      "Epoch 122/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4891 - accuracy: 0.7790 - val_loss: 0.5198 - val_accuracy: 0.7491\n",
      "Epoch 123/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4880 - accuracy: 0.7832 - val_loss: 0.5337 - val_accuracy: 0.7491\n",
      "Epoch 124/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4882 - accuracy: 0.7792 - val_loss: 0.5241 - val_accuracy: 0.7544\n",
      "Epoch 125/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4883 - accuracy: 0.7823 - val_loss: 0.5527 - val_accuracy: 0.7387\n",
      "Epoch 126/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4887 - accuracy: 0.7809 - val_loss: 0.5487 - val_accuracy: 0.7439\n",
      "Epoch 127/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4845 - accuracy: 0.7840 - val_loss: 0.5492 - val_accuracy: 0.7439\n",
      "Epoch 128/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4845 - accuracy: 0.7825 - val_loss: 0.5179 - val_accuracy: 0.7544\n",
      "Epoch 129/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4873 - accuracy: 0.7767 - val_loss: 0.5311 - val_accuracy: 0.7456\n",
      "Epoch 130/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4863 - accuracy: 0.7800 - val_loss: 0.5175 - val_accuracy: 0.7509\n",
      "Epoch 131/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4885 - accuracy: 0.7827 - val_loss: 0.5428 - val_accuracy: 0.7387\n",
      "Epoch 132/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4845 - accuracy: 0.7854 - val_loss: 0.5254 - val_accuracy: 0.7474\n",
      "Epoch 133/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4854 - accuracy: 0.7807 - val_loss: 0.5256 - val_accuracy: 0.7474\n",
      "Epoch 134/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4863 - accuracy: 0.7832 - val_loss: 0.5156 - val_accuracy: 0.7509\n",
      "Epoch 135/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4852 - accuracy: 0.7852 - val_loss: 0.5397 - val_accuracy: 0.7439\n",
      "Epoch 136/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4857 - accuracy: 0.7801 - val_loss: 0.5273 - val_accuracy: 0.7526\n",
      "Epoch 137/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4845 - accuracy: 0.7831 - val_loss: 0.5232 - val_accuracy: 0.7526\n",
      "Epoch 138/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4832 - accuracy: 0.7850 - val_loss: 0.5129 - val_accuracy: 0.7648\n",
      "Epoch 139/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4860 - accuracy: 0.7778 - val_loss: 0.5244 - val_accuracy: 0.7526\n",
      "Epoch 140/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4871 - accuracy: 0.7807 - val_loss: 0.5300 - val_accuracy: 0.7596\n",
      "Epoch 141/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4829 - accuracy: 0.7825 - val_loss: 0.5300 - val_accuracy: 0.7509\n",
      "Epoch 142/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4853 - accuracy: 0.7801 - val_loss: 0.5178 - val_accuracy: 0.7509\n",
      "Epoch 143/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4822 - accuracy: 0.7819 - val_loss: 0.5452 - val_accuracy: 0.7509\n",
      "Epoch 144/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4842 - accuracy: 0.7836 - val_loss: 0.5289 - val_accuracy: 0.7509\n",
      "Epoch 145/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4826 - accuracy: 0.7854 - val_loss: 0.5301 - val_accuracy: 0.7491\n",
      "Epoch 146/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4834 - accuracy: 0.7846 - val_loss: 0.5266 - val_accuracy: 0.7544\n",
      "Epoch 147/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4828 - accuracy: 0.7850 - val_loss: 0.5212 - val_accuracy: 0.7456\n",
      "Epoch 148/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4818 - accuracy: 0.7807 - val_loss: 0.5298 - val_accuracy: 0.7491\n",
      "Epoch 149/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4808 - accuracy: 0.7844 - val_loss: 0.5132 - val_accuracy: 0.7544\n",
      "Epoch 150/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4840 - accuracy: 0.7842 - val_loss: 0.5259 - val_accuracy: 0.7526\n",
      "Epoch 151/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4807 - accuracy: 0.7891 - val_loss: 0.5252 - val_accuracy: 0.7578\n",
      "18/18 [==============================] - 1s 7ms/step\n",
      "Sn = 0.744409, Sp = 0.773946, Acc = 0.757840, MCC = 0.516302, AUC = 0.838322\n",
      "****************************** the 2 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 8s 31ms/step - loss: 0.4827 - accuracy: 0.7832 - val_loss: 0.4918 - val_accuracy: 0.7770\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4854 - accuracy: 0.7778 - val_loss: 0.4937 - val_accuracy: 0.7840\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4875 - accuracy: 0.7780 - val_loss: 0.5005 - val_accuracy: 0.7718\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4866 - accuracy: 0.7807 - val_loss: 0.5049 - val_accuracy: 0.7666\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4843 - accuracy: 0.7815 - val_loss: 0.5014 - val_accuracy: 0.7666\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4836 - accuracy: 0.7801 - val_loss: 0.5108 - val_accuracy: 0.7648\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4828 - accuracy: 0.7813 - val_loss: 0.5035 - val_accuracy: 0.7735\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4840 - accuracy: 0.7850 - val_loss: 0.5018 - val_accuracy: 0.7805\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4836 - accuracy: 0.7838 - val_loss: 0.5109 - val_accuracy: 0.7683\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4831 - accuracy: 0.7807 - val_loss: 0.5101 - val_accuracy: 0.7718\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4828 - accuracy: 0.7796 - val_loss: 0.5234 - val_accuracy: 0.7648\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4822 - accuracy: 0.7811 - val_loss: 0.5036 - val_accuracy: 0.7753\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4823 - accuracy: 0.7834 - val_loss: 0.5190 - val_accuracy: 0.7613\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4833 - accuracy: 0.7832 - val_loss: 0.5208 - val_accuracy: 0.7666\n",
      "18/18 [==============================] - 1s 8ms/step\n",
      "Sn = 0.761404, Sp = 0.771626, Acc = 0.766551, MCC = 0.533069, AUC = 0.837564\n",
      "****************************** the 3 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 8s 32ms/step - loss: 0.4819 - accuracy: 0.7868 - val_loss: 0.4736 - val_accuracy: 0.7801\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4824 - accuracy: 0.7854 - val_loss: 0.4758 - val_accuracy: 0.7801\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4829 - accuracy: 0.7868 - val_loss: 0.4795 - val_accuracy: 0.7679\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4863 - accuracy: 0.7833 - val_loss: 0.4810 - val_accuracy: 0.7696\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4807 - accuracy: 0.7846 - val_loss: 0.4927 - val_accuracy: 0.7749\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4860 - accuracy: 0.7823 - val_loss: 0.4904 - val_accuracy: 0.7714\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4813 - accuracy: 0.7858 - val_loss: 0.4882 - val_accuracy: 0.7574\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4834 - accuracy: 0.7804 - val_loss: 0.4899 - val_accuracy: 0.7784\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4842 - accuracy: 0.7814 - val_loss: 0.4860 - val_accuracy: 0.7609\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4810 - accuracy: 0.7839 - val_loss: 0.4890 - val_accuracy: 0.7853\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4805 - accuracy: 0.7881 - val_loss: 0.4866 - val_accuracy: 0.7714\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4787 - accuracy: 0.7837 - val_loss: 0.5009 - val_accuracy: 0.7696\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4807 - accuracy: 0.7835 - val_loss: 0.4859 - val_accuracy: 0.7714\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4799 - accuracy: 0.7864 - val_loss: 0.4899 - val_accuracy: 0.7644\n",
      "18/18 [==============================] - 1s 7ms/step\n",
      "Sn = 0.805461, Sp = 0.721429, Acc = 0.764398, MCC = 0.529197, AUC = 0.856229\n",
      "****************************** the 4 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 7s 31ms/step - loss: 0.4804 - accuracy: 0.7837 - val_loss: 0.4516 - val_accuracy: 0.8202\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4835 - accuracy: 0.7769 - val_loss: 0.4538 - val_accuracy: 0.8202\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4843 - accuracy: 0.7767 - val_loss: 0.4611 - val_accuracy: 0.8133\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4834 - accuracy: 0.7817 - val_loss: 0.4674 - val_accuracy: 0.8098\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4794 - accuracy: 0.7825 - val_loss: 0.4662 - val_accuracy: 0.7941\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4825 - accuracy: 0.7767 - val_loss: 0.4661 - val_accuracy: 0.8133\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4798 - accuracy: 0.7790 - val_loss: 0.4635 - val_accuracy: 0.7993\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4809 - accuracy: 0.7798 - val_loss: 0.4644 - val_accuracy: 0.8080\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4800 - accuracy: 0.7819 - val_loss: 0.4624 - val_accuracy: 0.8028\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4782 - accuracy: 0.7786 - val_loss: 0.4622 - val_accuracy: 0.8063\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4805 - accuracy: 0.7850 - val_loss: 0.4666 - val_accuracy: 0.8028\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4814 - accuracy: 0.7831 - val_loss: 0.4714 - val_accuracy: 0.8010\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4817 - accuracy: 0.7798 - val_loss: 0.4627 - val_accuracy: 0.8063\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4808 - accuracy: 0.7808 - val_loss: 0.4665 - val_accuracy: 0.8028\n",
      "18/18 [==============================] - 1s 8ms/step\n",
      "Sn = 0.807692, Sp = 0.797909, Acc = 0.802792, MCC = 0.605624, AUC = 0.874199\n",
      "****************************** the 5 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 7s 31ms/step - loss: 0.4734 - accuracy: 0.7891 - val_loss: 0.4626 - val_accuracy: 0.7801\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4760 - accuracy: 0.7833 - val_loss: 0.4693 - val_accuracy: 0.7941\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4780 - accuracy: 0.7852 - val_loss: 0.4726 - val_accuracy: 0.7818\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4764 - accuracy: 0.7874 - val_loss: 0.4774 - val_accuracy: 0.7696\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4766 - accuracy: 0.7850 - val_loss: 0.4760 - val_accuracy: 0.7888\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4786 - accuracy: 0.7874 - val_loss: 0.4762 - val_accuracy: 0.7679\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4761 - accuracy: 0.7868 - val_loss: 0.4810 - val_accuracy: 0.7749\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4757 - accuracy: 0.7883 - val_loss: 0.4775 - val_accuracy: 0.7627\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4774 - accuracy: 0.7862 - val_loss: 0.4762 - val_accuracy: 0.7749\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4762 - accuracy: 0.7893 - val_loss: 0.4780 - val_accuracy: 0.7661\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4763 - accuracy: 0.7876 - val_loss: 0.4871 - val_accuracy: 0.7941\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4753 - accuracy: 0.7862 - val_loss: 0.4806 - val_accuracy: 0.7801\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4732 - accuracy: 0.7860 - val_loss: 0.4829 - val_accuracy: 0.7696\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4748 - accuracy: 0.7829 - val_loss: 0.4822 - val_accuracy: 0.7749\n",
      "18/18 [==============================] - 1s 8ms/step\n",
      "Sn = 0.838028, Sp = 0.712803, Acc = 0.774869, MCC = 0.554847, AUC = 0.862091\n",
      "****************************** the 6 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 8s 31ms/step - loss: 0.4726 - accuracy: 0.7897 - val_loss: 0.4543 - val_accuracy: 0.7923\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4741 - accuracy: 0.7837 - val_loss: 0.4553 - val_accuracy: 0.8028\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4781 - accuracy: 0.7891 - val_loss: 0.4615 - val_accuracy: 0.7958\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4776 - accuracy: 0.7858 - val_loss: 0.4673 - val_accuracy: 0.7836\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4751 - accuracy: 0.7877 - val_loss: 0.4670 - val_accuracy: 0.8028\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4752 - accuracy: 0.7870 - val_loss: 0.4606 - val_accuracy: 0.7941\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4715 - accuracy: 0.7918 - val_loss: 0.4650 - val_accuracy: 0.7906\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4760 - accuracy: 0.7870 - val_loss: 0.4671 - val_accuracy: 0.7853\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4747 - accuracy: 0.7856 - val_loss: 0.4673 - val_accuracy: 0.7853\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4719 - accuracy: 0.7852 - val_loss: 0.4683 - val_accuracy: 0.7853\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4742 - accuracy: 0.7887 - val_loss: 0.4668 - val_accuracy: 0.7906\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4716 - accuracy: 0.7901 - val_loss: 0.4661 - val_accuracy: 0.7958\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4745 - accuracy: 0.7885 - val_loss: 0.4733 - val_accuracy: 0.7784\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4742 - accuracy: 0.7858 - val_loss: 0.4721 - val_accuracy: 0.7784\n",
      "18/18 [==============================] - 1s 8ms/step\n",
      "Sn = 0.867596, Sp = 0.688811, Acc = 0.778360, MCC = 0.565619, AUC = 0.868899\n",
      "****************************** the 7 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 8s 31ms/step - loss: 0.4686 - accuracy: 0.7895 - val_loss: 0.4570 - val_accuracy: 0.7784\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4708 - accuracy: 0.7883 - val_loss: 0.4657 - val_accuracy: 0.7818\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4696 - accuracy: 0.7924 - val_loss: 0.4645 - val_accuracy: 0.7731\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4714 - accuracy: 0.7909 - val_loss: 0.4789 - val_accuracy: 0.7627\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4696 - accuracy: 0.7914 - val_loss: 0.4706 - val_accuracy: 0.7801\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4713 - accuracy: 0.7870 - val_loss: 0.4751 - val_accuracy: 0.7766\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4693 - accuracy: 0.7905 - val_loss: 0.4704 - val_accuracy: 0.7609\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4711 - accuracy: 0.7922 - val_loss: 0.4717 - val_accuracy: 0.7818\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4717 - accuracy: 0.7916 - val_loss: 0.4728 - val_accuracy: 0.7661\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4693 - accuracy: 0.7899 - val_loss: 0.4837 - val_accuracy: 0.7784\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4703 - accuracy: 0.7848 - val_loss: 0.4765 - val_accuracy: 0.7644\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4716 - accuracy: 0.7850 - val_loss: 0.4751 - val_accuracy: 0.7714\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4706 - accuracy: 0.7932 - val_loss: 0.4853 - val_accuracy: 0.7644\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4674 - accuracy: 0.7909 - val_loss: 0.4803 - val_accuracy: 0.7679\n",
      "18/18 [==============================] - 1s 6ms/step\n",
      "Sn = 0.831541, Sp = 0.707483, Acc = 0.767888, MCC = 0.542126, AUC = 0.856972\n",
      "****************************** the 8 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 8s 31ms/step - loss: 0.4649 - accuracy: 0.7897 - val_loss: 0.4611 - val_accuracy: 0.8080\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4627 - accuracy: 0.7903 - val_loss: 0.4625 - val_accuracy: 0.8115\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4695 - accuracy: 0.7852 - val_loss: 0.4677 - val_accuracy: 0.8202\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4681 - accuracy: 0.7879 - val_loss: 0.4659 - val_accuracy: 0.8010\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4681 - accuracy: 0.7889 - val_loss: 0.4739 - val_accuracy: 0.7976\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4708 - accuracy: 0.7852 - val_loss: 0.4935 - val_accuracy: 0.7923\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4677 - accuracy: 0.7922 - val_loss: 0.4677 - val_accuracy: 0.8063\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4690 - accuracy: 0.7889 - val_loss: 0.4762 - val_accuracy: 0.8045\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4690 - accuracy: 0.7858 - val_loss: 0.4728 - val_accuracy: 0.8098\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4648 - accuracy: 0.7899 - val_loss: 0.4835 - val_accuracy: 0.7923\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4658 - accuracy: 0.7910 - val_loss: 0.4760 - val_accuracy: 0.8010\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4679 - accuracy: 0.7897 - val_loss: 0.4916 - val_accuracy: 0.7784\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4684 - accuracy: 0.7901 - val_loss: 0.4757 - val_accuracy: 0.7976\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4649 - accuracy: 0.7889 - val_loss: 0.4845 - val_accuracy: 0.8080\n",
      "18/18 [==============================] - 1s 9ms/step\n",
      "Sn = 0.894915, Sp = 0.715827, Acc = 0.808028, MCC = 0.622703, AUC = 0.862236\n",
      "****************************** the 9 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 8s 33ms/step - loss: 0.4631 - accuracy: 0.7943 - val_loss: 0.4586 - val_accuracy: 0.8185\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4641 - accuracy: 0.7893 - val_loss: 0.4611 - val_accuracy: 0.8150\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4660 - accuracy: 0.7903 - val_loss: 0.4669 - val_accuracy: 0.8220\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4640 - accuracy: 0.7928 - val_loss: 0.4721 - val_accuracy: 0.8063\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4646 - accuracy: 0.7903 - val_loss: 0.4846 - val_accuracy: 0.7923\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4665 - accuracy: 0.7891 - val_loss: 0.4691 - val_accuracy: 0.8010\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4647 - accuracy: 0.7909 - val_loss: 0.4768 - val_accuracy: 0.7993\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4642 - accuracy: 0.7951 - val_loss: 0.4753 - val_accuracy: 0.8063\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4644 - accuracy: 0.7936 - val_loss: 0.4810 - val_accuracy: 0.8045\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4637 - accuracy: 0.7940 - val_loss: 0.4789 - val_accuracy: 0.8010\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4631 - accuracy: 0.7907 - val_loss: 0.4762 - val_accuracy: 0.7976\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4626 - accuracy: 0.7963 - val_loss: 0.4814 - val_accuracy: 0.7958\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4661 - accuracy: 0.7959 - val_loss: 0.4786 - val_accuracy: 0.7906\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4615 - accuracy: 0.7951 - val_loss: 0.4877 - val_accuracy: 0.7941\n",
      "18/18 [==============================] - 1s 8ms/step\n",
      "Sn = 0.869565, Sp = 0.723906, Acc = 0.794066, MCC = 0.597678, AUC = 0.861648\n",
      "****************************** the 10 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 7s 30ms/step - loss: 0.4608 - accuracy: 0.7955 - val_loss: 0.4576 - val_accuracy: 0.7818\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4602 - accuracy: 0.7982 - val_loss: 0.4617 - val_accuracy: 0.7853\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4662 - accuracy: 0.7926 - val_loss: 0.4625 - val_accuracy: 0.7749\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4626 - accuracy: 0.7930 - val_loss: 0.4657 - val_accuracy: 0.7801\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4627 - accuracy: 0.7940 - val_loss: 0.4659 - val_accuracy: 0.7714\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4630 - accuracy: 0.8005 - val_loss: 0.4733 - val_accuracy: 0.7679\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4610 - accuracy: 0.7953 - val_loss: 0.4722 - val_accuracy: 0.7731\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4631 - accuracy: 0.7945 - val_loss: 0.4759 - val_accuracy: 0.7714\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4623 - accuracy: 0.7984 - val_loss: 0.4745 - val_accuracy: 0.7749\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4629 - accuracy: 0.7957 - val_loss: 0.4764 - val_accuracy: 0.7661\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4618 - accuracy: 0.7955 - val_loss: 0.4696 - val_accuracy: 0.7766\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4613 - accuracy: 0.7941 - val_loss: 0.4708 - val_accuracy: 0.7714\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4612 - accuracy: 0.7982 - val_loss: 0.4706 - val_accuracy: 0.7731\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4598 - accuracy: 0.7938 - val_loss: 0.4830 - val_accuracy: 0.7609\n",
      "18/18 [==============================] - 1s 8ms/step\n",
      "Sn = 0.824627, Sp = 0.704918, Acc = 0.760908, MCC = 0.530383, AUC = 0.862454\n",
      "10 fold result: [[0.74440894 0.77394636 0.75783972 0.51630222 0.83832152]\n",
      " [0.76140351 0.77162629 0.76655052 0.53306864 0.8375645 ]\n",
      " [0.80546075 0.72142857 0.76439791 0.52919718 0.85622867]\n",
      " [0.8076923  0.7979094  0.80279232 0.60562385 0.87419897]\n",
      " [0.83802817 0.71280277 0.77486911 0.55484749 0.86209123]\n",
      " [0.86759582 0.68881119 0.77835951 0.56561937 0.86889939]\n",
      " [0.83154122 0.70748299 0.76788831 0.54212619 0.85697218]\n",
      " [0.89491525 0.71582734 0.80802792 0.62270254 0.86223631]\n",
      " [0.86956521 0.72390572 0.79406632 0.59767822 0.86164788]\n",
      " [0.82462686 0.70491803 0.7609075  0.5303826  0.86245412]]\n",
      "Sn = 0.8245 ± 0.0449\n",
      "Sp = 0.7319 ± 0.0342\n",
      "Acc = 0.7776 ± 0.0170\n",
      "Mcc = 0.5598 ± 0.0350\n",
      "Auc = 0.8581 ± 0.0112\n",
      "Epoch 1/200\n",
      "180/180 [==============================] - 8s 29ms/step - loss: 0.4622 - accuracy: 0.7912 - val_loss: 0.4863 - val_accuracy: 0.7814\n",
      "Epoch 2/200\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.4604 - accuracy: 0.7973"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 12:31:37.125971: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 4s 22ms/step - loss: 0.4604 - accuracy: 0.7973 - val_loss: 0.4846 - val_accuracy: 0.7830\n",
      "Epoch 3/200\n",
      "180/180 [==============================] - 4s 23ms/step - loss: 0.4630 - accuracy: 0.7922 - val_loss: 0.4929 - val_accuracy: 0.7736\n",
      "Epoch 4/200\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.4605 - accuracy: 0.7961 - val_loss: 0.4953 - val_accuracy: 0.7736\n",
      "Epoch 5/200\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.4590 - accuracy: 0.7959 - val_loss: 0.4843 - val_accuracy: 0.7925\n",
      "Epoch 6/200\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.4573 - accuracy: 0.7962 - val_loss: 0.4881 - val_accuracy: 0.7814\n",
      "Epoch 7/200\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.4589 - accuracy: 0.7971 - val_loss: 0.4827 - val_accuracy: 0.7862\n",
      "Epoch 8/200\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.4599 - accuracy: 0.7936 - val_loss: 0.4957 - val_accuracy: 0.7720\n",
      "Epoch 9/200\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.4593 - accuracy: 0.7985 - val_loss: 0.4962 - val_accuracy: 0.7799\n",
      "Epoch 10/200\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.4594 - accuracy: 0.7952 - val_loss: 0.4927 - val_accuracy: 0.7846\n",
      "Epoch 11/200\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.4585 - accuracy: 0.7954 - val_loss: 0.4885 - val_accuracy: 0.7767\n",
      "Epoch 12/200\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.4580 - accuracy: 0.7971 - val_loss: 0.4877 - val_accuracy: 0.7862\n",
      "Epoch 13/200\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.4547 - accuracy: 0.8009 - val_loss: 0.4849 - val_accuracy: 0.7877\n",
      "Epoch 14/200\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.4591 - accuracy: 0.7980 - val_loss: 0.4866 - val_accuracy: 0.7940\n",
      "Epoch 15/200\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.4577 - accuracy: 0.7947 - val_loss: 0.4891 - val_accuracy: 0.7846\n",
      "Epoch 16/200\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.4565 - accuracy: 0.7976 - val_loss: 0.4920 - val_accuracy: 0.7767\n",
      "Epoch 17/200\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.4577 - accuracy: 0.7985 - val_loss: 0.4883 - val_accuracy: 0.7799\n",
      "Epoch 18/200\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.4556 - accuracy: 0.7999 - val_loss: 0.4996 - val_accuracy: 0.7720\n",
      "Epoch 19/200\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.4538 - accuracy: 0.7988 - val_loss: 0.4898 - val_accuracy: 0.7830\n",
      "Epoch 20/200\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.4572 - accuracy: 0.7987 - val_loss: 0.4927 - val_accuracy: 0.7862\n",
      "Epoch 21/200\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.4567 - accuracy: 0.8013 - val_loss: 0.4891 - val_accuracy: 0.7799\n",
      "Epoch 22/200\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.4566 - accuracy: 0.7990 - val_loss: 0.4833 - val_accuracy: 0.7846\n",
      "Epoch 23/200\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.4550 - accuracy: 0.8011 - val_loss: 0.4908 - val_accuracy: 0.7862\n",
      "Epoch 24/200\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.4558 - accuracy: 0.8006 - val_loss: 0.4909 - val_accuracy: 0.7862\n",
      "Epoch 25/200\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.4541 - accuracy: 0.8001 - val_loss: 0.5029 - val_accuracy: 0.7767\n",
      "Epoch 26/200\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.4529 - accuracy: 0.8046 - val_loss: 0.4859 - val_accuracy: 0.7862\n",
      "Epoch 27/200\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.4552 - accuracy: 0.7999 - val_loss: 0.5034 - val_accuracy: 0.7814\n",
      "20/20 [==============================] - 1s 6ms/step\n",
      "-----------------------------------------------test---------------------------------------\n",
      "Sn = 0.751572, Sp = 0.811321, Acc = 0.781447, MCC = 0.563901, AUC = 0.855840\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "tf.random.set_seed(1)  # for reproducibility\n",
    "# reading model\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 200\n",
    "\n",
    "# # Cross-validation\n",
    "n = 10\n",
    "k_fold = KFold(n_splits=n, shuffle=True, random_state=42)\n",
    "\n",
    "all_performance = []\n",
    "tprs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "for fold_count, (train_index, val_index) in enumerate(k_fold.split(train)):\n",
    "    print('*' * 30 + ' the ' + str(fold_count + 1) + ' fold ' + '*' * 30)\n",
    "    trains, val = train[train_index], train[val_index]\n",
    "    trains_label, val_label = train_label[train_index], train_label[val_index]\n",
    "    zaoting = EarlyStopping(monitor='val_loss', patience=13, mode='auto')\n",
    "    xuexilv = WarmupExponentialDecay(lr_base=0.0002,decay=0.00002,warmup_epochs=2)\n",
    "    callback_lists=[xuexilv,zaoting]\n",
    "    model.fit(x=trains, y=trains_label, validation_data=(val, val_label), epochs=EPOCHS,\n",
    "                batch_size=BATCH_SIZE, shuffle=True,\n",
    "                callbacks=callback_lists,\n",
    "                verbose=1)\n",
    "     # 保存模型\n",
    "\n",
    "    model.save('./warmup_embedding/model_fold' + str(fold_count+1) + '.h5')\n",
    "\n",
    "    del model\n",
    "\n",
    "    model = load_model('./warmup_embedding/model_fold' + str(fold_count+1) + '.h5')\n",
    "\n",
    "    val_pred = model.predict(val, verbose=1)\n",
    "\n",
    "    # Sn, Sp, Acc, MCC, AUC\n",
    "    Sn, Sp, Acc, MCC = show_performance(val_label[:, 1], val_pred[:, 1])\n",
    "    AUC = roc_auc_score(val_label[:, 1], val_pred[:, 1])\n",
    "    print('Sn = %f, Sp = %f, Acc = %f, MCC = %f, AUC = %f' % (Sn, Sp, Acc, MCC, AUC))\n",
    "\n",
    "    performance = [Sn, Sp, Acc, MCC, AUC]\n",
    "    all_performance.append(performance)\n",
    "    \n",
    "all_performance = np.array(all_performance)\n",
    "print('10 fold result:', all_performance)\n",
    "performance_mean = performance_mean(all_performance)\n",
    "\n",
    "model.fit(x=train, y=train_label, validation_data=(test, test_label), epochs=EPOCHS,\n",
    "                      batch_size=BATCH_SIZE, shuffle=True,\n",
    "                      callbacks=[EarlyStopping(monitor='val_loss', patience=20, mode='auto')],\n",
    "                      verbose=1)\n",
    "model.save('./warmup_embedding/model_test.h5')\n",
    "\n",
    "del model\n",
    "\n",
    "model = load_model('./warmup_embedding/model_test.h5')\n",
    "\n",
    "test_score = model.predict(test)\n",
    "\n",
    "\n",
    "# Sn, Sp, Acc, MCC, AUC\n",
    "Sn, Sp, Acc, MCC = show_performance(test_label[:,1], test_score[:,1])\n",
    "AUC = roc_auc_score(test_label[:,1], test_score[:,1])\n",
    "\n",
    "print('-----------------------------------------------test---------------------------------------')\n",
    "print('Sn = %f, Sp = %f, Acc = %f, MCC = %f, AUC = %f' % (Sn, Sp, Acc, MCC, AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c77cffde-7a83-4e9e-a029-f5d74a70e1c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************Warmup+embedding_16******************************\n",
      "(None, 15, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 10:24:29.135102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8164 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:65:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 15, 48)\n",
      "****************************** the 1 fold ******************************\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 10:24:36.116406: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8800\n",
      "Could not load symbol cublasGetSmCountTarget from libcublas.so.11. Error: /usr/local/cuda/targets/x86_64-linux/lib/libcublas.so.11: undefined symbol: cublasGetSmCountTarget\n",
      "2024-06-05 10:24:36.345926: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-06-05 10:24:36.372656: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f4c7c8c4fb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-05 10:24:36.372690: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-06-05 10:24:36.379068: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-06-05 10:24:36.439577: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-05 10:24:36.442503: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:231] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.6\n",
      "2024-06-05 10:24:36.442514: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:234] Used ptxas at ptxas\n",
      "2024-06-05 10:24:36.455346: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-06-05 10:24:36.505084: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/162 [..............................] - ETA: 18:41 - loss: 3.2083 - accuracy: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 10:24:36.880024: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-05 10:24:36.903699: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-05 10:24:36.903823: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-05 10:24:36.946256: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-05 10:24:36.971067: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6/162 [>.............................] - ETA: 8s - loss: 3.2090 - accuracy: 0.4792 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 10:24:37.113685: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 19/162 [==>...........................] - ETA: 6s - loss: 3.2078 - accuracy: 0.4967"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 10:24:37.767157: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 25/162 [===>..........................] - ETA: 6s - loss: 3.2070 - accuracy: 0.4812"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 10:24:37.975846: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 14s 43ms/step - loss: 3.1252 - accuracy: 0.5091 - val_loss: 2.9603 - val_accuracy: 0.4930\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 2.6854 - accuracy: 0.5481 - val_loss: 2.3704 - val_accuracy: 0.6237\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 2.0635 - accuracy: 0.6402 - val_loss: 1.8244 - val_accuracy: 0.6272\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 1.6265 - accuracy: 0.6572 - val_loss: 1.4809 - val_accuracy: 0.6463\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 1.3589 - accuracy: 0.6630 - val_loss: 1.2680 - val_accuracy: 0.6672\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 1.1863 - accuracy: 0.6638 - val_loss: 1.1352 - val_accuracy: 0.6585\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - ETA: 0s - loss: 1.0739 - accuracy: 0.6660"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 10:25:18.498305: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 6s 37ms/step - loss: 1.0739 - accuracy: 0.6660 - val_loss: 1.0371 - val_accuracy: 0.6707\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.9987 - accuracy: 0.6634 - val_loss: 0.9861 - val_accuracy: 0.6498\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.9471 - accuracy: 0.6693 - val_loss: 0.9381 - val_accuracy: 0.6742\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.9083 - accuracy: 0.6689 - val_loss: 0.9111 - val_accuracy: 0.6533\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.8783 - accuracy: 0.6656 - val_loss: 0.8782 - val_accuracy: 0.6725\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.8532 - accuracy: 0.6694 - val_loss: 0.8624 - val_accuracy: 0.6603\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.8318 - accuracy: 0.6737 - val_loss: 0.8349 - val_accuracy: 0.6829\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.8126 - accuracy: 0.6786 - val_loss: 0.8142 - val_accuracy: 0.6864\n",
      "Epoch 15/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.7931 - accuracy: 0.6776 - val_loss: 0.7980 - val_accuracy: 0.6969\n",
      "Epoch 16/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.7754 - accuracy: 0.6780 - val_loss: 0.7779 - val_accuracy: 0.6794\n",
      "Epoch 17/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.7600 - accuracy: 0.6842 - val_loss: 0.7682 - val_accuracy: 0.6847\n",
      "Epoch 18/200\n",
      "162/162 [==============================] - ETA: 0s - loss: 0.7435 - accuracy: 0.6846"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 10:26:22.324309: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 6s 37ms/step - loss: 0.7435 - accuracy: 0.6846 - val_loss: 0.7477 - val_accuracy: 0.6777\n",
      "Epoch 19/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.7293 - accuracy: 0.6846 - val_loss: 0.7343 - val_accuracy: 0.6847\n",
      "Epoch 20/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.7158 - accuracy: 0.6902 - val_loss: 0.7237 - val_accuracy: 0.6864\n",
      "Epoch 21/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.7033 - accuracy: 0.6896 - val_loss: 0.7112 - val_accuracy: 0.6760\n",
      "Epoch 22/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.6923 - accuracy: 0.6884 - val_loss: 0.6962 - val_accuracy: 0.6829\n",
      "Epoch 23/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.6820 - accuracy: 0.6921 - val_loss: 0.6903 - val_accuracy: 0.6864\n",
      "Epoch 24/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.6706 - accuracy: 0.6908 - val_loss: 0.6784 - val_accuracy: 0.6916\n",
      "Epoch 25/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.6614 - accuracy: 0.6906 - val_loss: 0.6709 - val_accuracy: 0.6829\n",
      "Epoch 26/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.6521 - accuracy: 0.6941 - val_loss: 0.6668 - val_accuracy: 0.6655\n",
      "Epoch 27/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.6447 - accuracy: 0.6964 - val_loss: 0.6579 - val_accuracy: 0.6794\n",
      "Epoch 28/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.6373 - accuracy: 0.6970 - val_loss: 0.6453 - val_accuracy: 0.7003\n",
      "Epoch 29/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.6298 - accuracy: 0.6941 - val_loss: 0.6355 - val_accuracy: 0.7056\n",
      "Epoch 30/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.6249 - accuracy: 0.6993 - val_loss: 0.6306 - val_accuracy: 0.7038\n",
      "Epoch 31/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.6171 - accuracy: 0.7036 - val_loss: 0.6299 - val_accuracy: 0.6951\n",
      "Epoch 32/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.6125 - accuracy: 0.7005 - val_loss: 0.6229 - val_accuracy: 0.7125\n",
      "Epoch 33/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.6071 - accuracy: 0.7043 - val_loss: 0.6216 - val_accuracy: 0.6882\n",
      "Epoch 34/200\n",
      "162/162 [==============================] - ETA: 0s - loss: 0.6030 - accuracy: 0.7041"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 10:27:55.525742: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 6s 37ms/step - loss: 0.6030 - accuracy: 0.7041 - val_loss: 0.6100 - val_accuracy: 0.7143\n",
      "Epoch 35/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5969 - accuracy: 0.7086 - val_loss: 0.6063 - val_accuracy: 0.7195\n",
      "Epoch 36/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5941 - accuracy: 0.7051 - val_loss: 0.6034 - val_accuracy: 0.7125\n",
      "Epoch 37/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5897 - accuracy: 0.7117 - val_loss: 0.6059 - val_accuracy: 0.7125\n",
      "Epoch 38/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5861 - accuracy: 0.7094 - val_loss: 0.5966 - val_accuracy: 0.7178\n",
      "Epoch 39/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5829 - accuracy: 0.7140 - val_loss: 0.5962 - val_accuracy: 0.7195\n",
      "Epoch 40/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5788 - accuracy: 0.7105 - val_loss: 0.5895 - val_accuracy: 0.7247\n",
      "Epoch 41/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5761 - accuracy: 0.7169 - val_loss: 0.5882 - val_accuracy: 0.7160\n",
      "Epoch 42/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5732 - accuracy: 0.7125 - val_loss: 0.5922 - val_accuracy: 0.7091\n",
      "Epoch 43/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5700 - accuracy: 0.7210 - val_loss: 0.5891 - val_accuracy: 0.7143\n",
      "Epoch 44/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5688 - accuracy: 0.7185 - val_loss: 0.5863 - val_accuracy: 0.7282\n",
      "Epoch 45/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5659 - accuracy: 0.7276 - val_loss: 0.5903 - val_accuracy: 0.7125\n",
      "Epoch 46/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5635 - accuracy: 0.7257 - val_loss: 0.5912 - val_accuracy: 0.7108\n",
      "Epoch 47/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5611 - accuracy: 0.7276 - val_loss: 0.5796 - val_accuracy: 0.7387\n",
      "Epoch 48/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5591 - accuracy: 0.7251 - val_loss: 0.5816 - val_accuracy: 0.7300\n",
      "Epoch 49/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5557 - accuracy: 0.7309 - val_loss: 0.5799 - val_accuracy: 0.7282\n",
      "Epoch 50/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5542 - accuracy: 0.7295 - val_loss: 0.5848 - val_accuracy: 0.7091\n",
      "Epoch 51/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5501 - accuracy: 0.7315 - val_loss: 0.5764 - val_accuracy: 0.7334\n",
      "Epoch 52/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5490 - accuracy: 0.7377 - val_loss: 0.5717 - val_accuracy: 0.7456\n",
      "Epoch 53/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5450 - accuracy: 0.7379 - val_loss: 0.5712 - val_accuracy: 0.7282\n",
      "Epoch 54/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5441 - accuracy: 0.7406 - val_loss: 0.5764 - val_accuracy: 0.7282\n",
      "Epoch 55/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5400 - accuracy: 0.7439 - val_loss: 0.5747 - val_accuracy: 0.7317\n",
      "Epoch 56/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5393 - accuracy: 0.7449 - val_loss: 0.5666 - val_accuracy: 0.7422\n",
      "Epoch 57/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5359 - accuracy: 0.7458 - val_loss: 0.5626 - val_accuracy: 0.7526\n",
      "Epoch 58/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5324 - accuracy: 0.7513 - val_loss: 0.5696 - val_accuracy: 0.7317\n",
      "Epoch 59/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5361 - accuracy: 0.7507 - val_loss: 0.5657 - val_accuracy: 0.7422\n",
      "Epoch 60/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5309 - accuracy: 0.7524 - val_loss: 0.5573 - val_accuracy: 0.7474\n",
      "Epoch 61/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5279 - accuracy: 0.7553 - val_loss: 0.5632 - val_accuracy: 0.7474\n",
      "Epoch 62/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5297 - accuracy: 0.7505 - val_loss: 0.5601 - val_accuracy: 0.7491\n",
      "Epoch 63/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5264 - accuracy: 0.7536 - val_loss: 0.5584 - val_accuracy: 0.7509\n",
      "Epoch 64/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5266 - accuracy: 0.7573 - val_loss: 0.5632 - val_accuracy: 0.7439\n",
      "Epoch 65/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5252 - accuracy: 0.7584 - val_loss: 0.5562 - val_accuracy: 0.7422\n",
      "Epoch 66/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5223 - accuracy: 0.7561 - val_loss: 0.5619 - val_accuracy: 0.7526\n",
      "Epoch 67/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5233 - accuracy: 0.7547 - val_loss: 0.5607 - val_accuracy: 0.7491\n",
      "Epoch 68/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5216 - accuracy: 0.7577 - val_loss: 0.5563 - val_accuracy: 0.7509\n",
      "Epoch 69/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5205 - accuracy: 0.7606 - val_loss: 0.5574 - val_accuracy: 0.7544\n",
      "Epoch 70/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5208 - accuracy: 0.7579 - val_loss: 0.5571 - val_accuracy: 0.7491\n",
      "Epoch 71/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5184 - accuracy: 0.7610 - val_loss: 0.5580 - val_accuracy: 0.7491\n",
      "Epoch 72/200\n",
      "162/162 [==============================] - 6s 37ms/step - loss: 0.5192 - accuracy: 0.7559 - val_loss: 0.5503 - val_accuracy: 0.7352\n",
      "Epoch 73/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5153 - accuracy: 0.7664 - val_loss: 0.5515 - val_accuracy: 0.7456\n",
      "Epoch 74/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5163 - accuracy: 0.7650 - val_loss: 0.5584 - val_accuracy: 0.7474\n",
      "Epoch 75/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5157 - accuracy: 0.7664 - val_loss: 0.5540 - val_accuracy: 0.7509\n",
      "Epoch 76/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5121 - accuracy: 0.7654 - val_loss: 0.5586 - val_accuracy: 0.7474\n",
      "Epoch 77/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5131 - accuracy: 0.7621 - val_loss: 0.5595 - val_accuracy: 0.7439\n",
      "Epoch 78/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5127 - accuracy: 0.7635 - val_loss: 0.5489 - val_accuracy: 0.7456\n",
      "Epoch 79/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5117 - accuracy: 0.7687 - val_loss: 0.5528 - val_accuracy: 0.7561\n",
      "Epoch 80/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5093 - accuracy: 0.7662 - val_loss: 0.5546 - val_accuracy: 0.7422\n",
      "Epoch 81/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5135 - accuracy: 0.7664 - val_loss: 0.5509 - val_accuracy: 0.7578\n",
      "Epoch 82/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5102 - accuracy: 0.7625 - val_loss: 0.5606 - val_accuracy: 0.7526\n",
      "Epoch 83/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5091 - accuracy: 0.7685 - val_loss: 0.5501 - val_accuracy: 0.7474\n",
      "Epoch 84/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5084 - accuracy: 0.7664 - val_loss: 0.5513 - val_accuracy: 0.7474\n",
      "Epoch 85/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5043 - accuracy: 0.7701 - val_loss: 0.5516 - val_accuracy: 0.7439\n",
      "Epoch 86/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5089 - accuracy: 0.7674 - val_loss: 0.5495 - val_accuracy: 0.7596\n",
      "Epoch 87/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5086 - accuracy: 0.7662 - val_loss: 0.5467 - val_accuracy: 0.7439\n",
      "Epoch 88/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5070 - accuracy: 0.7650 - val_loss: 0.5557 - val_accuracy: 0.7561\n",
      "Epoch 89/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5048 - accuracy: 0.7716 - val_loss: 0.5537 - val_accuracy: 0.7474\n",
      "Epoch 90/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5062 - accuracy: 0.7751 - val_loss: 0.5565 - val_accuracy: 0.7439\n",
      "Epoch 91/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5040 - accuracy: 0.7710 - val_loss: 0.5584 - val_accuracy: 0.7474\n",
      "Epoch 92/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5042 - accuracy: 0.7708 - val_loss: 0.5502 - val_accuracy: 0.7439\n",
      "Epoch 93/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5033 - accuracy: 0.7737 - val_loss: 0.5525 - val_accuracy: 0.7509\n",
      "Epoch 94/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5019 - accuracy: 0.7701 - val_loss: 0.5482 - val_accuracy: 0.7456\n",
      "Epoch 95/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5025 - accuracy: 0.7724 - val_loss: 0.5588 - val_accuracy: 0.7456\n",
      "Epoch 96/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5038 - accuracy: 0.7712 - val_loss: 0.5496 - val_accuracy: 0.7422\n",
      "Epoch 97/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5029 - accuracy: 0.7695 - val_loss: 0.5525 - val_accuracy: 0.7526\n",
      "Epoch 98/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5026 - accuracy: 0.7743 - val_loss: 0.5411 - val_accuracy: 0.7561\n",
      "Epoch 99/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4991 - accuracy: 0.7749 - val_loss: 0.5575 - val_accuracy: 0.7578\n",
      "Epoch 100/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.4999 - accuracy: 0.7728 - val_loss: 0.5501 - val_accuracy: 0.7509\n",
      "Epoch 101/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4994 - accuracy: 0.7705 - val_loss: 0.5409 - val_accuracy: 0.7596\n",
      "Epoch 102/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4984 - accuracy: 0.7743 - val_loss: 0.5505 - val_accuracy: 0.7491\n",
      "Epoch 103/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4998 - accuracy: 0.7753 - val_loss: 0.5477 - val_accuracy: 0.7456\n",
      "Epoch 104/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5003 - accuracy: 0.7724 - val_loss: 0.5519 - val_accuracy: 0.7578\n",
      "Epoch 105/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4965 - accuracy: 0.7780 - val_loss: 0.5448 - val_accuracy: 0.7491\n",
      "Epoch 106/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4987 - accuracy: 0.7734 - val_loss: 0.5446 - val_accuracy: 0.7526\n",
      "Epoch 107/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4956 - accuracy: 0.7769 - val_loss: 0.5514 - val_accuracy: 0.7561\n",
      "Epoch 108/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4974 - accuracy: 0.7743 - val_loss: 0.5524 - val_accuracy: 0.7613\n",
      "Epoch 109/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4969 - accuracy: 0.7776 - val_loss: 0.5428 - val_accuracy: 0.7456\n",
      "Epoch 110/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4963 - accuracy: 0.7801 - val_loss: 0.5525 - val_accuracy: 0.7509\n",
      "Epoch 111/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.4944 - accuracy: 0.7803 - val_loss: 0.5383 - val_accuracy: 0.7456\n",
      "Epoch 112/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.4954 - accuracy: 0.7788 - val_loss: 0.5424 - val_accuracy: 0.7491\n",
      "Epoch 113/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4924 - accuracy: 0.7792 - val_loss: 0.5483 - val_accuracy: 0.7509\n",
      "Epoch 114/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4946 - accuracy: 0.7801 - val_loss: 0.5363 - val_accuracy: 0.7526\n",
      "Epoch 115/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4935 - accuracy: 0.7759 - val_loss: 0.5548 - val_accuracy: 0.7422\n",
      "Epoch 116/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4930 - accuracy: 0.7780 - val_loss: 0.5395 - val_accuracy: 0.7578\n",
      "Epoch 117/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4926 - accuracy: 0.7807 - val_loss: 0.5404 - val_accuracy: 0.7544\n",
      "Epoch 118/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.4918 - accuracy: 0.7776 - val_loss: 0.5452 - val_accuracy: 0.7544\n",
      "Epoch 119/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4930 - accuracy: 0.7831 - val_loss: 0.5451 - val_accuracy: 0.7526\n",
      "Epoch 120/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.4911 - accuracy: 0.7862 - val_loss: 0.5490 - val_accuracy: 0.7474\n",
      "Epoch 121/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.4912 - accuracy: 0.7796 - val_loss: 0.5445 - val_accuracy: 0.7561\n",
      "Epoch 122/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4913 - accuracy: 0.7792 - val_loss: 0.5411 - val_accuracy: 0.7491\n",
      "Epoch 123/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4905 - accuracy: 0.7792 - val_loss: 0.5416 - val_accuracy: 0.7526\n",
      "Epoch 124/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.4917 - accuracy: 0.7829 - val_loss: 0.5421 - val_accuracy: 0.7474\n",
      "Epoch 125/200\n",
      "162/162 [==============================] - 6s 34ms/step - loss: 0.4903 - accuracy: 0.7815 - val_loss: 0.5495 - val_accuracy: 0.7491\n",
      "Epoch 126/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4884 - accuracy: 0.7821 - val_loss: 0.5522 - val_accuracy: 0.7456\n",
      "Epoch 127/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4902 - accuracy: 0.7817 - val_loss: 0.5473 - val_accuracy: 0.7474\n",
      "18/18 [==============================] - 1s 10ms/step\n",
      "Sn = 0.734824, Sp = 0.762452, Acc = 0.747387, MCC = 0.495307, AUC = 0.823179\n",
      "****************************** the 2 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 10s 43ms/step - loss: 0.4909 - accuracy: 0.7796 - val_loss: 0.5060 - val_accuracy: 0.7822\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4923 - accuracy: 0.7786 - val_loss: 0.5059 - val_accuracy: 0.7857\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4930 - accuracy: 0.7765 - val_loss: 0.5093 - val_accuracy: 0.7753\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4922 - accuracy: 0.7815 - val_loss: 0.5094 - val_accuracy: 0.7718\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4911 - accuracy: 0.7811 - val_loss: 0.5079 - val_accuracy: 0.7683\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 6s 37ms/step - loss: 0.4902 - accuracy: 0.7838 - val_loss: 0.5128 - val_accuracy: 0.7770\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4885 - accuracy: 0.7800 - val_loss: 0.5081 - val_accuracy: 0.7770\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4884 - accuracy: 0.7846 - val_loss: 0.5130 - val_accuracy: 0.7857\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 5s 33ms/step - loss: 0.4902 - accuracy: 0.7745 - val_loss: 0.5136 - val_accuracy: 0.7822\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.4884 - accuracy: 0.7811 - val_loss: 0.5158 - val_accuracy: 0.7770\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 3s 18ms/step - loss: 0.4902 - accuracy: 0.7831 - val_loss: 0.5195 - val_accuracy: 0.7805\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 3s 18ms/step - loss: 0.4861 - accuracy: 0.7807 - val_loss: 0.5111 - val_accuracy: 0.7735\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.4862 - accuracy: 0.7811 - val_loss: 0.5169 - val_accuracy: 0.7840\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 3s 18ms/step - loss: 0.4871 - accuracy: 0.7801 - val_loss: 0.5240 - val_accuracy: 0.7753\n",
      "Epoch 15/200\n",
      "162/162 [==============================] - 3s 17ms/step - loss: 0.4891 - accuracy: 0.7829 - val_loss: 0.5122 - val_accuracy: 0.7787\n",
      "18/18 [==============================] - 1s 6ms/step\n",
      "Sn = 0.775439, Sp = 0.782007, Acc = 0.778746, MCC = 0.557462, AUC = 0.845456\n",
      "****************************** the 3 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 6s 25ms/step - loss: 0.4875 - accuracy: 0.7823 - val_loss: 0.4771 - val_accuracy: 0.7941\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 3s 17ms/step - loss: 0.4882 - accuracy: 0.7860 - val_loss: 0.4809 - val_accuracy: 0.7976\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 3s 17ms/step - loss: 0.4899 - accuracy: 0.7781 - val_loss: 0.4802 - val_accuracy: 0.7818\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 3s 17ms/step - loss: 0.4905 - accuracy: 0.7786 - val_loss: 0.4823 - val_accuracy: 0.7871\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.4881 - accuracy: 0.7817 - val_loss: 0.4833 - val_accuracy: 0.7871\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 3s 18ms/step - loss: 0.4869 - accuracy: 0.7827 - val_loss: 0.4935 - val_accuracy: 0.7818\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 3s 18ms/step - loss: 0.4875 - accuracy: 0.7825 - val_loss: 0.4873 - val_accuracy: 0.7836\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 3s 17ms/step - loss: 0.4866 - accuracy: 0.7798 - val_loss: 0.4863 - val_accuracy: 0.7853\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 3s 17ms/step - loss: 0.4879 - accuracy: 0.7848 - val_loss: 0.4816 - val_accuracy: 0.7627\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 3s 16ms/step - loss: 0.4852 - accuracy: 0.7837 - val_loss: 0.4844 - val_accuracy: 0.7853\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 3s 18ms/step - loss: 0.4836 - accuracy: 0.7827 - val_loss: 0.4885 - val_accuracy: 0.7679\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 3s 17ms/step - loss: 0.4846 - accuracy: 0.7825 - val_loss: 0.4913 - val_accuracy: 0.7923\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 3s 17ms/step - loss: 0.4852 - accuracy: 0.7866 - val_loss: 0.4851 - val_accuracy: 0.7818\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 3s 17ms/step - loss: 0.4862 - accuracy: 0.7815 - val_loss: 0.4847 - val_accuracy: 0.7679\n",
      "18/18 [==============================] - 1s 5ms/step\n",
      "Sn = 0.815700, Sp = 0.717857, Acc = 0.767888, MCC = 0.536673, AUC = 0.863615\n",
      "****************************** the 4 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 6s 25ms/step - loss: 0.4839 - accuracy: 0.7876 - val_loss: 0.4525 - val_accuracy: 0.8028\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 3s 17ms/step - loss: 0.4870 - accuracy: 0.7821 - val_loss: 0.4564 - val_accuracy: 0.8080\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 3s 18ms/step - loss: 0.4885 - accuracy: 0.7806 - val_loss: 0.4535 - val_accuracy: 0.8063\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 3s 18ms/step - loss: 0.4856 - accuracy: 0.7825 - val_loss: 0.4636 - val_accuracy: 0.7993\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 3s 18ms/step - loss: 0.4854 - accuracy: 0.7846 - val_loss: 0.4686 - val_accuracy: 0.7958\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.4868 - accuracy: 0.7837 - val_loss: 0.4678 - val_accuracy: 0.7993\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 3s 18ms/step - loss: 0.4867 - accuracy: 0.7845 - val_loss: 0.4658 - val_accuracy: 0.7906\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 3s 18ms/step - loss: 0.4844 - accuracy: 0.7870 - val_loss: 0.4681 - val_accuracy: 0.7871\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.4857 - accuracy: 0.7786 - val_loss: 0.4611 - val_accuracy: 0.7958\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 3s 18ms/step - loss: 0.4846 - accuracy: 0.7825 - val_loss: 0.4669 - val_accuracy: 0.7784\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 3s 18ms/step - loss: 0.4842 - accuracy: 0.7808 - val_loss: 0.4657 - val_accuracy: 0.7801\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 3s 17ms/step - loss: 0.4815 - accuracy: 0.7848 - val_loss: 0.4718 - val_accuracy: 0.7853\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.4839 - accuracy: 0.7835 - val_loss: 0.4609 - val_accuracy: 0.8045\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.4842 - accuracy: 0.7858 - val_loss: 0.4635 - val_accuracy: 0.7853\n",
      "18/18 [==============================] - 1s 5ms/step\n",
      "Sn = 0.790210, Sp = 0.780488, Acc = 0.785340, MCC = 0.570718, AUC = 0.875795\n",
      "****************************** the 5 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 6s 24ms/step - loss: 0.4767 - accuracy: 0.7897 - val_loss: 0.4711 - val_accuracy: 0.7958\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.4804 - accuracy: 0.7885 - val_loss: 0.4720 - val_accuracy: 0.7993\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.4829 - accuracy: 0.7870 - val_loss: 0.4788 - val_accuracy: 0.7871\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.4783 - accuracy: 0.7862 - val_loss: 0.4797 - val_accuracy: 0.7906\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 3s 18ms/step - loss: 0.4832 - accuracy: 0.7800 - val_loss: 0.4779 - val_accuracy: 0.7906\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.4800 - accuracy: 0.7854 - val_loss: 0.4781 - val_accuracy: 0.7906\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 3s 18ms/step - loss: 0.4799 - accuracy: 0.7829 - val_loss: 0.4830 - val_accuracy: 0.7766\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 3s 18ms/step - loss: 0.4793 - accuracy: 0.7852 - val_loss: 0.4853 - val_accuracy: 0.7958\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 3s 18ms/step - loss: 0.4788 - accuracy: 0.7858 - val_loss: 0.4838 - val_accuracy: 0.7888\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 3s 18ms/step - loss: 0.4789 - accuracy: 0.7899 - val_loss: 0.4822 - val_accuracy: 0.7836\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.4784 - accuracy: 0.7864 - val_loss: 0.4855 - val_accuracy: 0.7976\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 3s 18ms/step - loss: 0.4741 - accuracy: 0.7924 - val_loss: 0.4815 - val_accuracy: 0.7958\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 3s 17ms/step - loss: 0.4767 - accuracy: 0.7883 - val_loss: 0.4816 - val_accuracy: 0.7836\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 3s 18ms/step - loss: 0.4788 - accuracy: 0.7868 - val_loss: 0.4863 - val_accuracy: 0.7836\n",
      "18/18 [==============================] - 1s 5ms/step\n",
      "Sn = 0.855634, Sp = 0.712803, Acc = 0.783595, MCC = 0.573896, AUC = 0.862968\n",
      "****************************** the 6 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 8s 27ms/step - loss: 0.4733 - accuracy: 0.7924 - val_loss: 0.4588 - val_accuracy: 0.7976\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.4759 - accuracy: 0.7872 - val_loss: 0.4585 - val_accuracy: 0.8028\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.4798 - accuracy: 0.7833 - val_loss: 0.4709 - val_accuracy: 0.7818\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.4772 - accuracy: 0.7895 - val_loss: 0.4716 - val_accuracy: 0.8028\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.4749 - accuracy: 0.7885 - val_loss: 0.4683 - val_accuracy: 0.7941\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 3s 18ms/step - loss: 0.4748 - accuracy: 0.7924 - val_loss: 0.4665 - val_accuracy: 0.7941\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.4773 - accuracy: 0.7852 - val_loss: 0.4712 - val_accuracy: 0.7958\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.4740 - accuracy: 0.7885 - val_loss: 0.4690 - val_accuracy: 0.7993\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.4758 - accuracy: 0.7909 - val_loss: 0.4719 - val_accuracy: 0.7941\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.4739 - accuracy: 0.7899 - val_loss: 0.4712 - val_accuracy: 0.7941\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.4743 - accuracy: 0.7907 - val_loss: 0.4718 - val_accuracy: 0.7871\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.4723 - accuracy: 0.7876 - val_loss: 0.4703 - val_accuracy: 0.8045\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.4730 - accuracy: 0.7905 - val_loss: 0.4739 - val_accuracy: 0.7941\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.4759 - accuracy: 0.7895 - val_loss: 0.4740 - val_accuracy: 0.7976\n",
      "Epoch 15/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.4741 - accuracy: 0.7914 - val_loss: 0.4772 - val_accuracy: 0.7923\n",
      "18/18 [==============================] - 1s 4ms/step\n",
      "Sn = 0.860627, Sp = 0.723776, Acc = 0.792321, MCC = 0.590037, AUC = 0.864660\n",
      "****************************** the 7 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 7s 29ms/step - loss: 0.4713 - accuracy: 0.7932 - val_loss: 0.4568 - val_accuracy: 0.7888\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.4723 - accuracy: 0.7959 - val_loss: 0.4612 - val_accuracy: 0.7801\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.4729 - accuracy: 0.7907 - val_loss: 0.4633 - val_accuracy: 0.7784\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 0.4730 - accuracy: 0.7941 - val_loss: 0.4701 - val_accuracy: 0.7731\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 3s 18ms/step - loss: 0.4732 - accuracy: 0.7916 - val_loss: 0.4699 - val_accuracy: 0.7714\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.4716 - accuracy: 0.7914 - val_loss: 0.4732 - val_accuracy: 0.7766\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.4737 - accuracy: 0.7889 - val_loss: 0.4693 - val_accuracy: 0.7644\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.4724 - accuracy: 0.7920 - val_loss: 0.4712 - val_accuracy: 0.7766\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4737 - accuracy: 0.7910 - val_loss: 0.4740 - val_accuracy: 0.7661\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.4680 - accuracy: 0.7955 - val_loss: 0.4775 - val_accuracy: 0.7749\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.4719 - accuracy: 0.7936 - val_loss: 0.4773 - val_accuracy: 0.7696\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.4693 - accuracy: 0.7953 - val_loss: 0.4753 - val_accuracy: 0.7644\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 3s 22ms/step - loss: 0.4699 - accuracy: 0.7924 - val_loss: 0.4751 - val_accuracy: 0.7679\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.4694 - accuracy: 0.7909 - val_loss: 0.4783 - val_accuracy: 0.7714\n",
      "18/18 [==============================] - 1s 8ms/step\n",
      "Sn = 0.799283, Sp = 0.744898, Acc = 0.771379, MCC = 0.544433, AUC = 0.862641\n",
      "****************************** the 8 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 8s 29ms/step - loss: 0.4664 - accuracy: 0.7883 - val_loss: 0.4623 - val_accuracy: 0.8045\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.4688 - accuracy: 0.7959 - val_loss: 0.4671 - val_accuracy: 0.8063\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.4700 - accuracy: 0.7914 - val_loss: 0.4695 - val_accuracy: 0.8063\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.4674 - accuracy: 0.7883 - val_loss: 0.4698 - val_accuracy: 0.8028\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.4698 - accuracy: 0.7930 - val_loss: 0.4728 - val_accuracy: 0.7993\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.4692 - accuracy: 0.7907 - val_loss: 0.4767 - val_accuracy: 0.7923\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 0.4686 - accuracy: 0.7934 - val_loss: 0.4696 - val_accuracy: 0.8010\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 0.4702 - accuracy: 0.7907 - val_loss: 0.4700 - val_accuracy: 0.7941\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 4s 25ms/step - loss: 0.4669 - accuracy: 0.7889 - val_loss: 0.4718 - val_accuracy: 0.7958\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4675 - accuracy: 0.7912 - val_loss: 0.4826 - val_accuracy: 0.7976\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4680 - accuracy: 0.7893 - val_loss: 0.4779 - val_accuracy: 0.8063\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4638 - accuracy: 0.7945 - val_loss: 0.4842 - val_accuracy: 0.7958\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 5s 30ms/step - loss: 0.4691 - accuracy: 0.7932 - val_loss: 0.4756 - val_accuracy: 0.8010\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 4s 24ms/step - loss: 0.4630 - accuracy: 0.7945 - val_loss: 0.4799 - val_accuracy: 0.7923\n",
      "18/18 [==============================] - 1s 7ms/step\n",
      "Sn = 0.833898, Sp = 0.748201, Acc = 0.792321, MCC = 0.584953, AUC = 0.866626\n",
      "****************************** the 9 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 9s 40ms/step - loss: 0.4629 - accuracy: 0.7984 - val_loss: 0.4643 - val_accuracy: 0.7976\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 4s 27ms/step - loss: 0.4666 - accuracy: 0.7920 - val_loss: 0.4626 - val_accuracy: 0.7906\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 5s 32ms/step - loss: 0.4652 - accuracy: 0.7885 - val_loss: 0.4706 - val_accuracy: 0.7906\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4675 - accuracy: 0.7940 - val_loss: 0.4729 - val_accuracy: 0.7906\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 5s 28ms/step - loss: 0.4665 - accuracy: 0.7963 - val_loss: 0.4739 - val_accuracy: 0.7888\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.4660 - accuracy: 0.7961 - val_loss: 0.4698 - val_accuracy: 0.7958\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.4640 - accuracy: 0.7951 - val_loss: 0.4836 - val_accuracy: 0.7888\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 3s 16ms/step - loss: 0.4654 - accuracy: 0.7967 - val_loss: 0.4803 - val_accuracy: 0.7941\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 3s 17ms/step - loss: 0.4630 - accuracy: 0.7949 - val_loss: 0.4779 - val_accuracy: 0.7923\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 3s 17ms/step - loss: 0.4658 - accuracy: 0.7943 - val_loss: 0.4758 - val_accuracy: 0.7906\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 3s 17ms/step - loss: 0.4630 - accuracy: 0.7928 - val_loss: 0.4748 - val_accuracy: 0.7818\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 3s 18ms/step - loss: 0.4588 - accuracy: 0.7992 - val_loss: 0.4787 - val_accuracy: 0.7976\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 3s 17ms/step - loss: 0.4659 - accuracy: 0.7980 - val_loss: 0.4771 - val_accuracy: 0.7923\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 3s 18ms/step - loss: 0.4617 - accuracy: 0.7982 - val_loss: 0.5000 - val_accuracy: 0.7941\n",
      "Epoch 15/200\n",
      "162/162 [==============================] - 3s 18ms/step - loss: 0.4622 - accuracy: 0.7941 - val_loss: 0.4922 - val_accuracy: 0.7836\n",
      "18/18 [==============================] - 1s 9ms/step\n",
      "Sn = 0.858696, Sp = 0.713805, Acc = 0.783595, MCC = 0.576559, AUC = 0.862441\n",
      "****************************** the 10 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 10s 43ms/step - loss: 0.4608 - accuracy: 0.8036 - val_loss: 0.4544 - val_accuracy: 0.7853\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4633 - accuracy: 0.7990 - val_loss: 0.4585 - val_accuracy: 0.7853\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4634 - accuracy: 0.7978 - val_loss: 0.4623 - val_accuracy: 0.7784\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4634 - accuracy: 0.8000 - val_loss: 0.4613 - val_accuracy: 0.7853\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4642 - accuracy: 0.7998 - val_loss: 0.4668 - val_accuracy: 0.7731\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4601 - accuracy: 0.7969 - val_loss: 0.4720 - val_accuracy: 0.7818\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4632 - accuracy: 0.7955 - val_loss: 0.4809 - val_accuracy: 0.7766\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 6s 37ms/step - loss: 0.4629 - accuracy: 0.8025 - val_loss: 0.4675 - val_accuracy: 0.7731\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 6s 37ms/step - loss: 0.4599 - accuracy: 0.8005 - val_loss: 0.4711 - val_accuracy: 0.7749\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4590 - accuracy: 0.8042 - val_loss: 0.4696 - val_accuracy: 0.7679\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4624 - accuracy: 0.7971 - val_loss: 0.4704 - val_accuracy: 0.7888\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4607 - accuracy: 0.8011 - val_loss: 0.4686 - val_accuracy: 0.7766\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4623 - accuracy: 0.7978 - val_loss: 0.4702 - val_accuracy: 0.7714\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 6s 37ms/step - loss: 0.4582 - accuracy: 0.8017 - val_loss: 0.4840 - val_accuracy: 0.7749\n",
      "18/18 [==============================] - 1s 10ms/step\n",
      "Sn = 0.839552, Sp = 0.718033, Acc = 0.774869, MCC = 0.558467, AUC = 0.865574\n",
      "10 fold result: [[0.73482428 0.7624521  0.74738676 0.49530679 0.82317946]\n",
      " [0.77543859 0.78200692 0.77874564 0.55746244 0.8454562 ]\n",
      " [0.81569966 0.71785714 0.76788831 0.53667311 0.86361531]\n",
      " [0.79020979 0.7804878  0.78534031 0.57071845 0.87579494]\n",
      " [0.8556338  0.71280277 0.78359511 0.57389551 0.86296847]\n",
      " [0.86062717 0.72377622 0.79232112 0.59003724 0.86465973]\n",
      " [0.79928315 0.74489796 0.77137871 0.54443339 0.86264111]\n",
      " [0.8338983  0.74820144 0.79232112 0.58495265 0.86662602]\n",
      " [0.85869565 0.71380471 0.78359511 0.57655898 0.86244083]\n",
      " [0.83955224 0.71803278 0.77486911 0.55846708 0.86557377]]\n",
      "Sn = 0.8164 ± 0.0393\n",
      "Sp = 0.7404 ± 0.0258\n",
      "Acc = 0.7777 ± 0.0127\n",
      "Mcc = 0.5589 ± 0.0266\n",
      "Auc = 0.8593 ± 0.0139\n",
      "Epoch 1/200\n",
      "180/180 [==============================] - 9s 39ms/step - loss: 0.4628 - accuracy: 0.7975 - val_loss: 0.4793 - val_accuracy: 0.7862\n",
      "Epoch 2/200\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.4612 - accuracy: 0.7934"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 10:46:00.173481: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 6s 33ms/step - loss: 0.4612 - accuracy: 0.7934 - val_loss: 0.4798 - val_accuracy: 0.7940\n",
      "Epoch 3/200\n",
      "180/180 [==============================] - 6s 33ms/step - loss: 0.4611 - accuracy: 0.7966 - val_loss: 0.4855 - val_accuracy: 0.7909\n",
      "Epoch 4/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4595 - accuracy: 0.8018 - val_loss: 0.4770 - val_accuracy: 0.7877\n",
      "Epoch 5/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4613 - accuracy: 0.7976 - val_loss: 0.4774 - val_accuracy: 0.7940\n",
      "Epoch 6/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4592 - accuracy: 0.8018 - val_loss: 0.4819 - val_accuracy: 0.7877\n",
      "Epoch 7/200\n",
      "180/180 [==============================] - 6s 31ms/step - loss: 0.4597 - accuracy: 0.7985 - val_loss: 0.4765 - val_accuracy: 0.7940\n",
      "Epoch 8/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4602 - accuracy: 0.7936 - val_loss: 0.4813 - val_accuracy: 0.7893\n",
      "Epoch 9/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4609 - accuracy: 0.7966 - val_loss: 0.4781 - val_accuracy: 0.7877\n",
      "Epoch 10/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4591 - accuracy: 0.7980 - val_loss: 0.4791 - val_accuracy: 0.7846\n",
      "Epoch 11/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4580 - accuracy: 0.8001 - val_loss: 0.4753 - val_accuracy: 0.7956\n",
      "Epoch 12/200\n",
      "180/180 [==============================] - 6s 31ms/step - loss: 0.4601 - accuracy: 0.8008 - val_loss: 0.4773 - val_accuracy: 0.7862\n",
      "Epoch 13/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4609 - accuracy: 0.7983 - val_loss: 0.4744 - val_accuracy: 0.7909\n",
      "Epoch 14/200\n",
      "180/180 [==============================] - 6s 31ms/step - loss: 0.4574 - accuracy: 0.7975 - val_loss: 0.4768 - val_accuracy: 0.7940\n",
      "Epoch 15/200\n",
      "180/180 [==============================] - 6s 31ms/step - loss: 0.4573 - accuracy: 0.8013 - val_loss: 0.4776 - val_accuracy: 0.7956\n",
      "Epoch 16/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4570 - accuracy: 0.7999 - val_loss: 0.4794 - val_accuracy: 0.7814\n",
      "Epoch 17/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4589 - accuracy: 0.7992 - val_loss: 0.4750 - val_accuracy: 0.7830\n",
      "Epoch 18/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4568 - accuracy: 0.7982 - val_loss: 0.4806 - val_accuracy: 0.7830\n",
      "Epoch 19/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4571 - accuracy: 0.8002 - val_loss: 0.4754 - val_accuracy: 0.7925\n",
      "Epoch 20/200\n",
      "180/180 [==============================] - 6s 31ms/step - loss: 0.4591 - accuracy: 0.7987 - val_loss: 0.4762 - val_accuracy: 0.7925\n",
      "Epoch 21/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4573 - accuracy: 0.8050 - val_loss: 0.4798 - val_accuracy: 0.7862\n",
      "Epoch 22/200\n",
      "180/180 [==============================] - 6s 31ms/step - loss: 0.4563 - accuracy: 0.7982 - val_loss: 0.4824 - val_accuracy: 0.7925\n",
      "Epoch 23/200\n",
      "180/180 [==============================] - 6s 31ms/step - loss: 0.4563 - accuracy: 0.8029 - val_loss: 0.4776 - val_accuracy: 0.7925\n",
      "Epoch 24/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4551 - accuracy: 0.8043 - val_loss: 0.4779 - val_accuracy: 0.7877\n",
      "Epoch 25/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4577 - accuracy: 0.7980 - val_loss: 0.4814 - val_accuracy: 0.7862\n",
      "Epoch 26/200\n",
      "180/180 [==============================] - 6s 31ms/step - loss: 0.4566 - accuracy: 0.8004 - val_loss: 0.4753 - val_accuracy: 0.7925\n",
      "Epoch 27/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4569 - accuracy: 0.8009 - val_loss: 0.4821 - val_accuracy: 0.7893\n",
      "Epoch 28/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4533 - accuracy: 0.8011 - val_loss: 0.4765 - val_accuracy: 0.7956\n",
      "Epoch 29/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4566 - accuracy: 0.8009 - val_loss: 0.4795 - val_accuracy: 0.7830\n",
      "Epoch 30/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4584 - accuracy: 0.7997 - val_loss: 0.4720 - val_accuracy: 0.7987\n",
      "Epoch 31/200\n",
      "180/180 [==============================] - 6s 31ms/step - loss: 0.4535 - accuracy: 0.8013 - val_loss: 0.4774 - val_accuracy: 0.7846\n",
      "Epoch 32/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4561 - accuracy: 0.8013 - val_loss: 0.4781 - val_accuracy: 0.8003\n",
      "Epoch 33/200\n",
      "180/180 [==============================] - 6s 31ms/step - loss: 0.4517 - accuracy: 0.7987 - val_loss: 0.4761 - val_accuracy: 0.7925\n",
      "Epoch 34/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4546 - accuracy: 0.8013 - val_loss: 0.4890 - val_accuracy: 0.7783\n",
      "Epoch 35/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4550 - accuracy: 0.8015 - val_loss: 0.4736 - val_accuracy: 0.7956\n",
      "Epoch 36/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4521 - accuracy: 0.8013 - val_loss: 0.4760 - val_accuracy: 0.7925\n",
      "Epoch 37/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4547 - accuracy: 0.8004 - val_loss: 0.4783 - val_accuracy: 0.7987\n",
      "Epoch 38/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4519 - accuracy: 0.8016 - val_loss: 0.4811 - val_accuracy: 0.7830\n",
      "Epoch 39/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4500 - accuracy: 0.8053 - val_loss: 0.4743 - val_accuracy: 0.8003\n",
      "Epoch 40/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4518 - accuracy: 0.8060 - val_loss: 0.4756 - val_accuracy: 0.7956\n",
      "Epoch 41/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4540 - accuracy: 0.8034 - val_loss: 0.4835 - val_accuracy: 0.7909\n",
      "Epoch 42/200\n",
      "180/180 [==============================] - 6s 31ms/step - loss: 0.4533 - accuracy: 0.8006 - val_loss: 0.4754 - val_accuracy: 0.7956\n",
      "Epoch 43/200\n",
      "180/180 [==============================] - 6s 31ms/step - loss: 0.4507 - accuracy: 0.8053 - val_loss: 0.4792 - val_accuracy: 0.7877\n",
      "Epoch 44/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4499 - accuracy: 0.8020 - val_loss: 0.4822 - val_accuracy: 0.7830\n",
      "Epoch 45/200\n",
      "180/180 [==============================] - 5s 29ms/step - loss: 0.4507 - accuracy: 0.8029 - val_loss: 0.4760 - val_accuracy: 0.7846\n",
      "Epoch 46/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4542 - accuracy: 0.8013 - val_loss: 0.4795 - val_accuracy: 0.7956\n",
      "Epoch 47/200\n",
      "180/180 [==============================] - 6s 31ms/step - loss: 0.4499 - accuracy: 0.8041 - val_loss: 0.4752 - val_accuracy: 0.7909\n",
      "Epoch 48/200\n",
      "180/180 [==============================] - 6s 31ms/step - loss: 0.4509 - accuracy: 0.8051 - val_loss: 0.4808 - val_accuracy: 0.7862\n",
      "Epoch 49/200\n",
      "180/180 [==============================] - 6s 31ms/step - loss: 0.4519 - accuracy: 0.8011 - val_loss: 0.4747 - val_accuracy: 0.7987\n",
      "Epoch 50/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4491 - accuracy: 0.8023 - val_loss: 0.4765 - val_accuracy: 0.7940\n",
      "20/20 [==============================] - 1s 11ms/step\n",
      "-----------------------------------------------test---------------------------------------\n",
      "Sn = 0.798742, Sp = 0.789308, Acc = 0.794025, MCC = 0.588076, AUC = 0.867430\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "tf.random.set_seed(1)  # for reproducibility\n",
    "# reading model\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 200\n",
    "\n",
    "# # Cross-validation\n",
    "n = 10\n",
    "k_fold = KFold(n_splits=n, shuffle=True, random_state=42)\n",
    "\n",
    "all_performance = []\n",
    "tprs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "for fold_count, (train_index, val_index) in enumerate(k_fold.split(train)):\n",
    "    print('*' * 30 + ' the ' + str(fold_count + 1) + ' fold ' + '*' * 30)\n",
    "    trains, val = train[train_index], train[val_index]\n",
    "    trains_label, val_label = train_label[train_index], train_label[val_index]\n",
    "    zaoting = EarlyStopping(monitor='val_loss', patience=13, mode='auto')\n",
    "    xuexilv = WarmupExponentialDecay(lr_base=0.0002,decay=0.00002,warmup_epochs=2)\n",
    "    callback_lists=[xuexilv,zaoting]\n",
    "    model.fit(x=trains, y=trains_label, validation_data=(val, val_label), epochs=EPOCHS,\n",
    "                batch_size=BATCH_SIZE, shuffle=True,\n",
    "                callbacks=callback_lists,\n",
    "                verbose=1)\n",
    "     # 保存模型\n",
    "\n",
    "    model.save('./warmup_embedding/model_fold' + str(fold_count+1) + '.h5')\n",
    "\n",
    "    del model\n",
    "\n",
    "    model = load_model('./warmup_embedding/model_fold' + str(fold_count+1) + '.h5')\n",
    "\n",
    "    val_pred = model.predict(val, verbose=1)\n",
    "\n",
    "    # Sn, Sp, Acc, MCC, AUC\n",
    "    Sn, Sp, Acc, MCC = show_performance(val_label[:, 1], val_pred[:, 1])\n",
    "    AUC = roc_auc_score(val_label[:, 1], val_pred[:, 1])\n",
    "    print('Sn = %f, Sp = %f, Acc = %f, MCC = %f, AUC = %f' % (Sn, Sp, Acc, MCC, AUC))\n",
    "\n",
    "    performance = [Sn, Sp, Acc, MCC, AUC]\n",
    "    all_performance.append(performance)\n",
    "    \n",
    "all_performance = np.array(all_performance)\n",
    "print('10 fold result:', all_performance)\n",
    "performance_mean = performance_mean(all_performance)\n",
    "\n",
    "model.fit(x=train, y=train_label, validation_data=(test, test_label), epochs=EPOCHS,\n",
    "                      batch_size=BATCH_SIZE, shuffle=True,\n",
    "                      callbacks=[EarlyStopping(monitor='val_loss', patience=20, mode='auto')],\n",
    "                      verbose=1)\n",
    "model.save('./warmup_embedding/model_test.h5')\n",
    "\n",
    "del model\n",
    "\n",
    "model = load_model('./warmup_embedding/model_test.h5')\n",
    "\n",
    "test_score = model.predict(test)\n",
    "\n",
    "\n",
    "# Sn, Sp, Acc, MCC, AUC\n",
    "Sn, Sp, Acc, MCC = show_performance(test_label[:,1], test_score[:,1])\n",
    "AUC = roc_auc_score(test_label[:,1], test_score[:,1])\n",
    "\n",
    "print('-----------------------------------------------test---------------------------------------')\n",
    "print('Sn = %f, Sp = %f, Acc = %f, MCC = %f, AUC = %f' % (Sn, Sp, Acc, MCC, AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd8c09e1-ac81-40ac-9a2f-87db0ce121e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************Warmup+embedding_8******************************\n",
      "(None, 15, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 09:48:13.008298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8164 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:65:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 15, 48)\n",
      "****************************** the 1 fold ******************************\n",
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 09:48:20.231614: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8800\n",
      "Could not load symbol cublasGetSmCountTarget from libcublas.so.11. Error: /usr/local/cuda/targets/x86_64-linux/lib/libcublas.so.11: undefined symbol: cublasGetSmCountTarget\n",
      "2024-06-05 09:48:20.564157: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-06-05 09:48:20.593763: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55cacf9fd6b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-05 09:48:20.593795: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-06-05 09:48:20.610138: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-06-05 09:48:20.714984: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-05 09:48:20.719468: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:231] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.6\n",
      "2024-06-05 09:48:20.719490: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:234] Used ptxas at ptxas\n",
      "2024-06-05 09:48:20.738705: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-06-05 09:48:20.792748: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/162 [..............................] - ETA: 19:54 - loss: 3.1995 - accuracy: 0.4688"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 09:48:21.166185: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-05 09:48:21.186585: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-05 09:48:21.186790: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-05 09:48:21.246739: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-05 09:48:21.255382: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-05 09:48:21.292327: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6/162 [>.............................] - ETA: 9s - loss: 3.1995 - accuracy: 0.5417 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 09:48:21.459619: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 19/162 [==>...........................] - ETA: 7s - loss: 3.1984 - accuracy: 0.5543"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 09:48:22.127014: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 25/162 [===>..........................] - ETA: 7s - loss: 3.1976 - accuracy: 0.5387"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 09:48:22.387897: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 15s 44ms/step - loss: 3.1161 - accuracy: 0.5452 - val_loss: 2.9510 - val_accuracy: 0.6516\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 2.6764 - accuracy: 0.5752 - val_loss: 2.3607 - val_accuracy: 0.6132\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 2.0579 - accuracy: 0.6342 - val_loss: 1.8267 - val_accuracy: 0.6150\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 1.6235 - accuracy: 0.6541 - val_loss: 1.4796 - val_accuracy: 0.6394\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 1.3561 - accuracy: 0.6599 - val_loss: 1.2674 - val_accuracy: 0.6498\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 1.1848 - accuracy: 0.6619 - val_loss: 1.1359 - val_accuracy: 0.6429\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - ETA: 0s - loss: 1.0732 - accuracy: 0.6642"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 09:49:02.937487: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 6s 37ms/step - loss: 1.0732 - accuracy: 0.6642 - val_loss: 1.0377 - val_accuracy: 0.6742\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.9992 - accuracy: 0.6588 - val_loss: 0.9889 - val_accuracy: 0.6341\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.9479 - accuracy: 0.6663 - val_loss: 0.9403 - val_accuracy: 0.6551\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.9096 - accuracy: 0.6656 - val_loss: 0.9155 - val_accuracy: 0.6498\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 5s 33ms/step - loss: 0.8802 - accuracy: 0.6665 - val_loss: 0.8828 - val_accuracy: 0.6585\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.8552 - accuracy: 0.6667 - val_loss: 0.8685 - val_accuracy: 0.6446\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.8354 - accuracy: 0.6667 - val_loss: 0.8412 - val_accuracy: 0.6620\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.8164 - accuracy: 0.6679 - val_loss: 0.8207 - val_accuracy: 0.6777\n",
      "Epoch 15/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.7987 - accuracy: 0.6675 - val_loss: 0.8058 - val_accuracy: 0.6725\n",
      "Epoch 16/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.7824 - accuracy: 0.6667 - val_loss: 0.7877 - val_accuracy: 0.6760\n",
      "Epoch 17/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.7686 - accuracy: 0.6687 - val_loss: 0.7777 - val_accuracy: 0.6707\n",
      "Epoch 18/200\n",
      "162/162 [==============================] - ETA: 0s - loss: 0.7537 - accuracy: 0.6706"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 09:50:07.040596: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 6s 38ms/step - loss: 0.7537 - accuracy: 0.6706 - val_loss: 0.7600 - val_accuracy: 0.6760\n",
      "Epoch 19/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.7415 - accuracy: 0.6696 - val_loss: 0.7473 - val_accuracy: 0.6760\n",
      "Epoch 20/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.7291 - accuracy: 0.6714 - val_loss: 0.7390 - val_accuracy: 0.6760\n",
      "Epoch 21/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.7171 - accuracy: 0.6737 - val_loss: 0.7271 - val_accuracy: 0.6725\n",
      "Epoch 22/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.7079 - accuracy: 0.6720 - val_loss: 0.7129 - val_accuracy: 0.6829\n",
      "Epoch 23/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.6982 - accuracy: 0.6747 - val_loss: 0.7074 - val_accuracy: 0.6742\n",
      "Epoch 24/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.6878 - accuracy: 0.6809 - val_loss: 0.6966 - val_accuracy: 0.6794\n",
      "Epoch 25/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.6794 - accuracy: 0.6725 - val_loss: 0.6927 - val_accuracy: 0.6777\n",
      "Epoch 26/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.6703 - accuracy: 0.6776 - val_loss: 0.6835 - val_accuracy: 0.6725\n",
      "Epoch 27/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.6635 - accuracy: 0.6735 - val_loss: 0.6826 - val_accuracy: 0.6655\n",
      "Epoch 28/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.6562 - accuracy: 0.6747 - val_loss: 0.6742 - val_accuracy: 0.6725\n",
      "Epoch 29/200\n",
      "162/162 [==============================] - 6s 34ms/step - loss: 0.6482 - accuracy: 0.6813 - val_loss: 0.6571 - val_accuracy: 0.6916\n",
      "Epoch 30/200\n",
      "162/162 [==============================] - 5s 34ms/step - loss: 0.6439 - accuracy: 0.6822 - val_loss: 0.6537 - val_accuracy: 0.6794\n",
      "Epoch 31/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.6371 - accuracy: 0.6813 - val_loss: 0.6577 - val_accuracy: 0.6707\n",
      "Epoch 32/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.6319 - accuracy: 0.6828 - val_loss: 0.6478 - val_accuracy: 0.6794\n",
      "Epoch 33/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.6274 - accuracy: 0.6838 - val_loss: 0.6437 - val_accuracy: 0.6864\n",
      "Epoch 34/200\n",
      "162/162 [==============================] - ETA: 0s - loss: 0.6218 - accuracy: 0.6892"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 09:51:39.778706: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 6s 37ms/step - loss: 0.6218 - accuracy: 0.6892 - val_loss: 0.6336 - val_accuracy: 0.6829\n",
      "Epoch 35/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.6184 - accuracy: 0.6900 - val_loss: 0.6269 - val_accuracy: 0.6864\n",
      "Epoch 36/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.6142 - accuracy: 0.6863 - val_loss: 0.6259 - val_accuracy: 0.6882\n",
      "Epoch 37/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.6105 - accuracy: 0.6884 - val_loss: 0.6217 - val_accuracy: 0.6916\n",
      "Epoch 38/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.6079 - accuracy: 0.6908 - val_loss: 0.6205 - val_accuracy: 0.6864\n",
      "Epoch 39/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.6051 - accuracy: 0.6900 - val_loss: 0.6190 - val_accuracy: 0.6777\n",
      "Epoch 40/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.6013 - accuracy: 0.6925 - val_loss: 0.6119 - val_accuracy: 0.6916\n",
      "Epoch 41/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5998 - accuracy: 0.6910 - val_loss: 0.6115 - val_accuracy: 0.6882\n",
      "Epoch 42/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5985 - accuracy: 0.6937 - val_loss: 0.6122 - val_accuracy: 0.6777\n",
      "Epoch 43/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5968 - accuracy: 0.6912 - val_loss: 0.6119 - val_accuracy: 0.6882\n",
      "Epoch 44/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5967 - accuracy: 0.6908 - val_loss: 0.6150 - val_accuracy: 0.6882\n",
      "Epoch 45/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5955 - accuracy: 0.6927 - val_loss: 0.6167 - val_accuracy: 0.6725\n",
      "Epoch 46/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5943 - accuracy: 0.6912 - val_loss: 0.6168 - val_accuracy: 0.6812\n",
      "Epoch 47/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5927 - accuracy: 0.6948 - val_loss: 0.6106 - val_accuracy: 0.6829\n",
      "Epoch 48/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5922 - accuracy: 0.6914 - val_loss: 0.6082 - val_accuracy: 0.6882\n",
      "Epoch 49/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5912 - accuracy: 0.6939 - val_loss: 0.6055 - val_accuracy: 0.6969\n",
      "Epoch 50/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5910 - accuracy: 0.6931 - val_loss: 0.6022 - val_accuracy: 0.7160\n",
      "Epoch 51/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5909 - accuracy: 0.6912 - val_loss: 0.6103 - val_accuracy: 0.6829\n",
      "Epoch 52/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5905 - accuracy: 0.6945 - val_loss: 0.6043 - val_accuracy: 0.6899\n",
      "Epoch 53/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5880 - accuracy: 0.6972 - val_loss: 0.5984 - val_accuracy: 0.7073\n",
      "Epoch 54/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5882 - accuracy: 0.6972 - val_loss: 0.6093 - val_accuracy: 0.6794\n",
      "Epoch 55/200\n",
      "162/162 [==============================] - 6s 37ms/step - loss: 0.5878 - accuracy: 0.6968 - val_loss: 0.6063 - val_accuracy: 0.6829\n",
      "Epoch 56/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5876 - accuracy: 0.6954 - val_loss: 0.6047 - val_accuracy: 0.6951\n",
      "Epoch 57/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5876 - accuracy: 0.7003 - val_loss: 0.6001 - val_accuracy: 0.6986\n",
      "Epoch 58/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5862 - accuracy: 0.6958 - val_loss: 0.6171 - val_accuracy: 0.6760\n",
      "Epoch 59/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5865 - accuracy: 0.6983 - val_loss: 0.6070 - val_accuracy: 0.6742\n",
      "Epoch 60/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5852 - accuracy: 0.7028 - val_loss: 0.5991 - val_accuracy: 0.6986\n",
      "Epoch 61/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5844 - accuracy: 0.6995 - val_loss: 0.6030 - val_accuracy: 0.6899\n",
      "Epoch 62/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5856 - accuracy: 0.7014 - val_loss: 0.6030 - val_accuracy: 0.6916\n",
      "Epoch 63/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5841 - accuracy: 0.6995 - val_loss: 0.5995 - val_accuracy: 0.6951\n",
      "Epoch 64/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5832 - accuracy: 0.7009 - val_loss: 0.6002 - val_accuracy: 0.6951\n",
      "Epoch 65/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5816 - accuracy: 0.7020 - val_loss: 0.5957 - val_accuracy: 0.7038\n",
      "Epoch 66/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5812 - accuracy: 0.7041 - val_loss: 0.6037 - val_accuracy: 0.6794\n",
      "Epoch 67/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5808 - accuracy: 0.7038 - val_loss: 0.6033 - val_accuracy: 0.6777\n",
      "Epoch 68/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5789 - accuracy: 0.7065 - val_loss: 0.5989 - val_accuracy: 0.6986\n",
      "Epoch 69/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5765 - accuracy: 0.7119 - val_loss: 0.5988 - val_accuracy: 0.7003\n",
      "Epoch 70/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5760 - accuracy: 0.7071 - val_loss: 0.5990 - val_accuracy: 0.7021\n",
      "Epoch 71/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5748 - accuracy: 0.7094 - val_loss: 0.5994 - val_accuracy: 0.7038\n",
      "Epoch 72/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5732 - accuracy: 0.7140 - val_loss: 0.5917 - val_accuracy: 0.7160\n",
      "Epoch 73/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5703 - accuracy: 0.7138 - val_loss: 0.5921 - val_accuracy: 0.7143\n",
      "Epoch 74/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5701 - accuracy: 0.7160 - val_loss: 0.5964 - val_accuracy: 0.7073\n",
      "Epoch 75/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5685 - accuracy: 0.7150 - val_loss: 0.5896 - val_accuracy: 0.7091\n",
      "Epoch 76/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5660 - accuracy: 0.7169 - val_loss: 0.5948 - val_accuracy: 0.7073\n",
      "Epoch 77/200\n",
      "162/162 [==============================] - 6s 37ms/step - loss: 0.5640 - accuracy: 0.7214 - val_loss: 0.5893 - val_accuracy: 0.7143\n",
      "Epoch 78/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5626 - accuracy: 0.7181 - val_loss: 0.5804 - val_accuracy: 0.7265\n",
      "Epoch 79/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5592 - accuracy: 0.7212 - val_loss: 0.5845 - val_accuracy: 0.7056\n",
      "Epoch 80/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5583 - accuracy: 0.7231 - val_loss: 0.5865 - val_accuracy: 0.7178\n",
      "Epoch 81/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5577 - accuracy: 0.7268 - val_loss: 0.5833 - val_accuracy: 0.7021\n",
      "Epoch 82/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5535 - accuracy: 0.7280 - val_loss: 0.5883 - val_accuracy: 0.7091\n",
      "Epoch 83/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5523 - accuracy: 0.7216 - val_loss: 0.5773 - val_accuracy: 0.7265\n",
      "Epoch 84/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5518 - accuracy: 0.7350 - val_loss: 0.5723 - val_accuracy: 0.7352\n",
      "Epoch 85/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5471 - accuracy: 0.7315 - val_loss: 0.5753 - val_accuracy: 0.7282\n",
      "Epoch 86/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5473 - accuracy: 0.7367 - val_loss: 0.5763 - val_accuracy: 0.7300\n",
      "Epoch 87/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5481 - accuracy: 0.7377 - val_loss: 0.5706 - val_accuracy: 0.7213\n",
      "Epoch 88/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5424 - accuracy: 0.7392 - val_loss: 0.5828 - val_accuracy: 0.7125\n",
      "Epoch 89/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5401 - accuracy: 0.7412 - val_loss: 0.5788 - val_accuracy: 0.7125\n",
      "Epoch 90/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5388 - accuracy: 0.7406 - val_loss: 0.5717 - val_accuracy: 0.7282\n",
      "Epoch 91/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5369 - accuracy: 0.7443 - val_loss: 0.5772 - val_accuracy: 0.7195\n",
      "Epoch 92/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5364 - accuracy: 0.7418 - val_loss: 0.5721 - val_accuracy: 0.7160\n",
      "Epoch 93/200\n",
      "162/162 [==============================] - 6s 34ms/step - loss: 0.5337 - accuracy: 0.7456 - val_loss: 0.5672 - val_accuracy: 0.7247\n",
      "Epoch 94/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5326 - accuracy: 0.7460 - val_loss: 0.5647 - val_accuracy: 0.7387\n",
      "Epoch 95/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5305 - accuracy: 0.7456 - val_loss: 0.5757 - val_accuracy: 0.7387\n",
      "Epoch 96/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5329 - accuracy: 0.7491 - val_loss: 0.5687 - val_accuracy: 0.7300\n",
      "Epoch 97/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5303 - accuracy: 0.7470 - val_loss: 0.5730 - val_accuracy: 0.7265\n",
      "Epoch 98/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5283 - accuracy: 0.7516 - val_loss: 0.5598 - val_accuracy: 0.7334\n",
      "Epoch 99/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5274 - accuracy: 0.7565 - val_loss: 0.5727 - val_accuracy: 0.7230\n",
      "Epoch 100/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5252 - accuracy: 0.7518 - val_loss: 0.5615 - val_accuracy: 0.7334\n",
      "Epoch 101/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5249 - accuracy: 0.7513 - val_loss: 0.5583 - val_accuracy: 0.7369\n",
      "Epoch 102/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5248 - accuracy: 0.7513 - val_loss: 0.5633 - val_accuracy: 0.7300\n",
      "Epoch 103/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5247 - accuracy: 0.7561 - val_loss: 0.5655 - val_accuracy: 0.7317\n",
      "Epoch 104/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5252 - accuracy: 0.7553 - val_loss: 0.5706 - val_accuracy: 0.7317\n",
      "Epoch 105/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5205 - accuracy: 0.7584 - val_loss: 0.5603 - val_accuracy: 0.7265\n",
      "Epoch 106/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5206 - accuracy: 0.7590 - val_loss: 0.5603 - val_accuracy: 0.7369\n",
      "Epoch 107/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5217 - accuracy: 0.7542 - val_loss: 0.5638 - val_accuracy: 0.7387\n",
      "Epoch 108/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5192 - accuracy: 0.7577 - val_loss: 0.5704 - val_accuracy: 0.7456\n",
      "Epoch 109/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5204 - accuracy: 0.7604 - val_loss: 0.5584 - val_accuracy: 0.7387\n",
      "Epoch 110/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5192 - accuracy: 0.7604 - val_loss: 0.5670 - val_accuracy: 0.7352\n",
      "Epoch 111/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5203 - accuracy: 0.7596 - val_loss: 0.5518 - val_accuracy: 0.7317\n",
      "Epoch 112/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5159 - accuracy: 0.7579 - val_loss: 0.5553 - val_accuracy: 0.7300\n",
      "Epoch 113/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5173 - accuracy: 0.7579 - val_loss: 0.5588 - val_accuracy: 0.7352\n",
      "Epoch 114/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5189 - accuracy: 0.7590 - val_loss: 0.5526 - val_accuracy: 0.7387\n",
      "Epoch 115/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5167 - accuracy: 0.7573 - val_loss: 0.5652 - val_accuracy: 0.7439\n",
      "Epoch 116/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5170 - accuracy: 0.7575 - val_loss: 0.5551 - val_accuracy: 0.7422\n",
      "Epoch 117/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5157 - accuracy: 0.7575 - val_loss: 0.5542 - val_accuracy: 0.7352\n",
      "Epoch 118/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5148 - accuracy: 0.7563 - val_loss: 0.5698 - val_accuracy: 0.7439\n",
      "Epoch 119/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5153 - accuracy: 0.7619 - val_loss: 0.5591 - val_accuracy: 0.7439\n",
      "Epoch 120/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5159 - accuracy: 0.7598 - val_loss: 0.5649 - val_accuracy: 0.7439\n",
      "Epoch 121/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5160 - accuracy: 0.7588 - val_loss: 0.5701 - val_accuracy: 0.7422\n",
      "Epoch 122/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5120 - accuracy: 0.7592 - val_loss: 0.5593 - val_accuracy: 0.7491\n",
      "Epoch 123/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5128 - accuracy: 0.7600 - val_loss: 0.5610 - val_accuracy: 0.7456\n",
      "Epoch 124/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5125 - accuracy: 0.7619 - val_loss: 0.5600 - val_accuracy: 0.7474\n",
      "18/18 [==============================] - 1s 12ms/step\n",
      "Sn = 0.744409, Sp = 0.750958, Acc = 0.747387, MCC = 0.493693, AUC = 0.807903\n",
      "****************************** the 2 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 10s 44ms/step - loss: 0.5128 - accuracy: 0.7602 - val_loss: 0.5265 - val_accuracy: 0.7544\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5141 - accuracy: 0.7617 - val_loss: 0.5294 - val_accuracy: 0.7578\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5166 - accuracy: 0.7596 - val_loss: 0.5308 - val_accuracy: 0.7491\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5174 - accuracy: 0.7592 - val_loss: 0.5308 - val_accuracy: 0.7491\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5127 - accuracy: 0.7604 - val_loss: 0.5296 - val_accuracy: 0.7491\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5146 - accuracy: 0.7623 - val_loss: 0.5325 - val_accuracy: 0.7456\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5142 - accuracy: 0.7625 - val_loss: 0.5309 - val_accuracy: 0.7474\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5119 - accuracy: 0.7631 - val_loss: 0.5336 - val_accuracy: 0.7596\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5138 - accuracy: 0.7579 - val_loss: 0.5364 - val_accuracy: 0.7596\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5121 - accuracy: 0.7577 - val_loss: 0.5414 - val_accuracy: 0.7509\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5125 - accuracy: 0.7627 - val_loss: 0.5433 - val_accuracy: 0.7456\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5100 - accuracy: 0.7594 - val_loss: 0.5326 - val_accuracy: 0.7456\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5088 - accuracy: 0.7610 - val_loss: 0.5388 - val_accuracy: 0.7509\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5099 - accuracy: 0.7586 - val_loss: 0.5462 - val_accuracy: 0.7491\n",
      "18/18 [==============================] - 1s 10ms/step\n",
      "Sn = 0.729825, Sp = 0.768166, Acc = 0.749129, MCC = 0.498414, AUC = 0.821939\n",
      "****************************** the 3 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 10s 45ms/step - loss: 0.5100 - accuracy: 0.7589 - val_loss: 0.5098 - val_accuracy: 0.7627\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 6s 37ms/step - loss: 0.5099 - accuracy: 0.7668 - val_loss: 0.5101 - val_accuracy: 0.7574\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5125 - accuracy: 0.7626 - val_loss: 0.5139 - val_accuracy: 0.7557\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5096 - accuracy: 0.7643 - val_loss: 0.5214 - val_accuracy: 0.7452\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5095 - accuracy: 0.7594 - val_loss: 0.5148 - val_accuracy: 0.7609\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5072 - accuracy: 0.7676 - val_loss: 0.5314 - val_accuracy: 0.7539\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.5100 - accuracy: 0.7622 - val_loss: 0.5208 - val_accuracy: 0.7574\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5072 - accuracy: 0.7624 - val_loss: 0.5240 - val_accuracy: 0.7574\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5098 - accuracy: 0.7662 - val_loss: 0.5107 - val_accuracy: 0.7522\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5076 - accuracy: 0.7682 - val_loss: 0.5210 - val_accuracy: 0.7574\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5078 - accuracy: 0.7631 - val_loss: 0.5268 - val_accuracy: 0.7365\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5066 - accuracy: 0.7653 - val_loss: 0.5263 - val_accuracy: 0.7435\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5073 - accuracy: 0.7682 - val_loss: 0.5174 - val_accuracy: 0.7504\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5076 - accuracy: 0.7626 - val_loss: 0.5189 - val_accuracy: 0.7452\n",
      "18/18 [==============================] - 1s 10ms/step\n",
      "Sn = 0.784983, Sp = 0.703571, Acc = 0.745201, MCC = 0.490531, AUC = 0.834910\n",
      "****************************** the 4 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 10s 43ms/step - loss: 0.5035 - accuracy: 0.7672 - val_loss: 0.4861 - val_accuracy: 0.7696\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5089 - accuracy: 0.7676 - val_loss: 0.4855 - val_accuracy: 0.7696\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 6s 37ms/step - loss: 0.5111 - accuracy: 0.7697 - val_loss: 0.4827 - val_accuracy: 0.7818\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5091 - accuracy: 0.7635 - val_loss: 0.5010 - val_accuracy: 0.7661\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5081 - accuracy: 0.7672 - val_loss: 0.5119 - val_accuracy: 0.7557\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 6s 37ms/step - loss: 0.5075 - accuracy: 0.7645 - val_loss: 0.4920 - val_accuracy: 0.7801\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5078 - accuracy: 0.7670 - val_loss: 0.4933 - val_accuracy: 0.7679\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5063 - accuracy: 0.7635 - val_loss: 0.5020 - val_accuracy: 0.7592\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5079 - accuracy: 0.7620 - val_loss: 0.4876 - val_accuracy: 0.7661\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5073 - accuracy: 0.7674 - val_loss: 0.4971 - val_accuracy: 0.7661\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 6s 37ms/step - loss: 0.5065 - accuracy: 0.7664 - val_loss: 0.4972 - val_accuracy: 0.7609\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5043 - accuracy: 0.7672 - val_loss: 0.5088 - val_accuracy: 0.7574\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5074 - accuracy: 0.7624 - val_loss: 0.4868 - val_accuracy: 0.7749\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5051 - accuracy: 0.7657 - val_loss: 0.4872 - val_accuracy: 0.7661\n",
      "Epoch 15/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5010 - accuracy: 0.7722 - val_loss: 0.4945 - val_accuracy: 0.7522\n",
      "Epoch 16/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5048 - accuracy: 0.7645 - val_loss: 0.4843 - val_accuracy: 0.7749\n",
      "18/18 [==============================] - 1s 12ms/step\n",
      "Sn = 0.790210, Sp = 0.759582, Acc = 0.774869, MCC = 0.550033, AUC = 0.861772\n",
      "****************************** the 5 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 10s 43ms/step - loss: 0.4993 - accuracy: 0.7701 - val_loss: 0.4903 - val_accuracy: 0.7679\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4999 - accuracy: 0.7707 - val_loss: 0.4919 - val_accuracy: 0.7679\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 6s 34ms/step - loss: 0.5028 - accuracy: 0.7668 - val_loss: 0.4928 - val_accuracy: 0.7592\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 6s 37ms/step - loss: 0.5002 - accuracy: 0.7715 - val_loss: 0.4983 - val_accuracy: 0.7627\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5027 - accuracy: 0.7691 - val_loss: 0.4981 - val_accuracy: 0.7592\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4980 - accuracy: 0.7715 - val_loss: 0.4993 - val_accuracy: 0.7609\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4997 - accuracy: 0.7709 - val_loss: 0.4965 - val_accuracy: 0.7714\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4981 - accuracy: 0.7666 - val_loss: 0.4994 - val_accuracy: 0.7574\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.5014 - accuracy: 0.7740 - val_loss: 0.4967 - val_accuracy: 0.7679\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4986 - accuracy: 0.7713 - val_loss: 0.4972 - val_accuracy: 0.7731\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 6s 37ms/step - loss: 0.4984 - accuracy: 0.7717 - val_loss: 0.5104 - val_accuracy: 0.7574\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4953 - accuracy: 0.7769 - val_loss: 0.5053 - val_accuracy: 0.7557\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4961 - accuracy: 0.7713 - val_loss: 0.5029 - val_accuracy: 0.7592\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4977 - accuracy: 0.7728 - val_loss: 0.5057 - val_accuracy: 0.7609\n",
      "18/18 [==============================] - 1s 10ms/step\n",
      "Sn = 0.750000, Sp = 0.771626, Acc = 0.760908, MCC = 0.521785, AUC = 0.842268\n",
      "****************************** the 6 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 10s 44ms/step - loss: 0.4945 - accuracy: 0.7759 - val_loss: 0.4866 - val_accuracy: 0.7784\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4935 - accuracy: 0.7763 - val_loss: 0.4844 - val_accuracy: 0.7888\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4967 - accuracy: 0.7707 - val_loss: 0.4973 - val_accuracy: 0.7731\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 6s 37ms/step - loss: 0.4939 - accuracy: 0.7742 - val_loss: 0.4920 - val_accuracy: 0.7766\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4934 - accuracy: 0.7761 - val_loss: 0.4916 - val_accuracy: 0.7801\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4942 - accuracy: 0.7688 - val_loss: 0.4898 - val_accuracy: 0.7766\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4949 - accuracy: 0.7732 - val_loss: 0.4903 - val_accuracy: 0.7836\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4906 - accuracy: 0.7746 - val_loss: 0.4921 - val_accuracy: 0.7784\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.4934 - accuracy: 0.7750 - val_loss: 0.4910 - val_accuracy: 0.7888\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4922 - accuracy: 0.7715 - val_loss: 0.4915 - val_accuracy: 0.7818\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4953 - accuracy: 0.7717 - val_loss: 0.4968 - val_accuracy: 0.7714\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4915 - accuracy: 0.7752 - val_loss: 0.4999 - val_accuracy: 0.7749\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4932 - accuracy: 0.7744 - val_loss: 0.4927 - val_accuracy: 0.7836\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.4948 - accuracy: 0.7746 - val_loss: 0.4919 - val_accuracy: 0.7853\n",
      "Epoch 15/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4925 - accuracy: 0.7779 - val_loss: 0.4951 - val_accuracy: 0.7784\n",
      "18/18 [==============================] - 1s 11ms/step\n",
      "Sn = 0.857143, Sp = 0.699301, Acc = 0.778360, MCC = 0.563596, AUC = 0.852379\n",
      "****************************** the 7 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 10s 43ms/step - loss: 0.4898 - accuracy: 0.7763 - val_loss: 0.4671 - val_accuracy: 0.7941\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.4907 - accuracy: 0.7788 - val_loss: 0.4702 - val_accuracy: 0.7906\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.4906 - accuracy: 0.7777 - val_loss: 0.4721 - val_accuracy: 0.7888\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4965 - accuracy: 0.7715 - val_loss: 0.4738 - val_accuracy: 0.7784\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4916 - accuracy: 0.7755 - val_loss: 0.4763 - val_accuracy: 0.7836\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4922 - accuracy: 0.7691 - val_loss: 0.4781 - val_accuracy: 0.7696\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 6s 37ms/step - loss: 0.4919 - accuracy: 0.7755 - val_loss: 0.4725 - val_accuracy: 0.7784\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4905 - accuracy: 0.7769 - val_loss: 0.4738 - val_accuracy: 0.7836\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4955 - accuracy: 0.7755 - val_loss: 0.4769 - val_accuracy: 0.7784\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4890 - accuracy: 0.7765 - val_loss: 0.4780 - val_accuracy: 0.7836\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4929 - accuracy: 0.7769 - val_loss: 0.4794 - val_accuracy: 0.7801\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4905 - accuracy: 0.7771 - val_loss: 0.4750 - val_accuracy: 0.7801\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 6s 34ms/step - loss: 0.4910 - accuracy: 0.7784 - val_loss: 0.4751 - val_accuracy: 0.7784\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 6s 37ms/step - loss: 0.4879 - accuracy: 0.7761 - val_loss: 0.4775 - val_accuracy: 0.7853\n",
      "18/18 [==============================] - 1s 11ms/step\n",
      "Sn = 0.817204, Sp = 0.755102, Acc = 0.785340, MCC = 0.572746, AUC = 0.862007\n",
      "****************************** the 8 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 10s 43ms/step - loss: 0.4865 - accuracy: 0.7730 - val_loss: 0.4653 - val_accuracy: 0.8080\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4902 - accuracy: 0.7736 - val_loss: 0.4682 - val_accuracy: 0.8115\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4868 - accuracy: 0.7734 - val_loss: 0.4687 - val_accuracy: 0.8133\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4879 - accuracy: 0.7740 - val_loss: 0.4702 - val_accuracy: 0.8063\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4893 - accuracy: 0.7769 - val_loss: 0.4715 - val_accuracy: 0.8045\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.4900 - accuracy: 0.7755 - val_loss: 0.4823 - val_accuracy: 0.7993\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4910 - accuracy: 0.7783 - val_loss: 0.4734 - val_accuracy: 0.8133\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4900 - accuracy: 0.7753 - val_loss: 0.4711 - val_accuracy: 0.7993\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4884 - accuracy: 0.7719 - val_loss: 0.4720 - val_accuracy: 0.8185\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.4865 - accuracy: 0.7730 - val_loss: 0.4808 - val_accuracy: 0.7906\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4862 - accuracy: 0.7769 - val_loss: 0.4800 - val_accuracy: 0.8010\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4847 - accuracy: 0.7786 - val_loss: 0.4831 - val_accuracy: 0.7871\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4908 - accuracy: 0.7742 - val_loss: 0.4789 - val_accuracy: 0.7958\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4835 - accuracy: 0.7794 - val_loss: 0.4819 - val_accuracy: 0.7906\n",
      "18/18 [==============================] - 1s 10ms/step\n",
      "Sn = 0.837288, Sp = 0.741007, Acc = 0.790576, MCC = 0.581796, AUC = 0.861505\n",
      "****************************** the 9 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 10s 46ms/step - loss: 0.4816 - accuracy: 0.7827 - val_loss: 0.4805 - val_accuracy: 0.7784\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4848 - accuracy: 0.7773 - val_loss: 0.4796 - val_accuracy: 0.7818\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4822 - accuracy: 0.7759 - val_loss: 0.4846 - val_accuracy: 0.7836\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4825 - accuracy: 0.7819 - val_loss: 0.4833 - val_accuracy: 0.7906\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4823 - accuracy: 0.7812 - val_loss: 0.4867 - val_accuracy: 0.7714\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4843 - accuracy: 0.7788 - val_loss: 0.4847 - val_accuracy: 0.7853\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4840 - accuracy: 0.7821 - val_loss: 0.4910 - val_accuracy: 0.7853\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4814 - accuracy: 0.7800 - val_loss: 0.4876 - val_accuracy: 0.7801\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4838 - accuracy: 0.7812 - val_loss: 0.4927 - val_accuracy: 0.7784\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4822 - accuracy: 0.7759 - val_loss: 0.4880 - val_accuracy: 0.7749\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4838 - accuracy: 0.7784 - val_loss: 0.4887 - val_accuracy: 0.7696\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 6s 37ms/step - loss: 0.4792 - accuracy: 0.7856 - val_loss: 0.4926 - val_accuracy: 0.7784\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 6s 37ms/step - loss: 0.4829 - accuracy: 0.7821 - val_loss: 0.4888 - val_accuracy: 0.7749\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4792 - accuracy: 0.7827 - val_loss: 0.5064 - val_accuracy: 0.7906\n",
      "Epoch 15/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4789 - accuracy: 0.7810 - val_loss: 0.5034 - val_accuracy: 0.7836\n",
      "18/18 [==============================] - 1s 11ms/step\n",
      "Sn = 0.884058, Sp = 0.690236, Acc = 0.783595, MCC = 0.582670, AUC = 0.848912\n",
      "****************************** the 10 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 10s 43ms/step - loss: 0.4796 - accuracy: 0.7841 - val_loss: 0.4726 - val_accuracy: 0.7784\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4815 - accuracy: 0.7825 - val_loss: 0.4791 - val_accuracy: 0.7749\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4813 - accuracy: 0.7804 - val_loss: 0.4794 - val_accuracy: 0.7731\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4807 - accuracy: 0.7831 - val_loss: 0.4798 - val_accuracy: 0.7801\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4819 - accuracy: 0.7823 - val_loss: 0.4836 - val_accuracy: 0.7766\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4802 - accuracy: 0.7872 - val_loss: 0.4855 - val_accuracy: 0.7661\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 6s 35ms/step - loss: 0.4821 - accuracy: 0.7821 - val_loss: 0.4934 - val_accuracy: 0.7749\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4804 - accuracy: 0.7810 - val_loss: 0.4845 - val_accuracy: 0.7714\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4808 - accuracy: 0.7839 - val_loss: 0.4873 - val_accuracy: 0.7679\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4795 - accuracy: 0.7825 - val_loss: 0.4826 - val_accuracy: 0.7749\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 6s 37ms/step - loss: 0.4812 - accuracy: 0.7815 - val_loss: 0.4883 - val_accuracy: 0.7679\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4827 - accuracy: 0.7821 - val_loss: 0.4844 - val_accuracy: 0.7679\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4809 - accuracy: 0.7831 - val_loss: 0.4843 - val_accuracy: 0.7766\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 6s 36ms/step - loss: 0.4777 - accuracy: 0.7874 - val_loss: 0.4864 - val_accuracy: 0.7749\n",
      "18/18 [==============================] - 1s 8ms/step\n",
      "Sn = 0.798507, Sp = 0.754098, Acc = 0.774869, MCC = 0.551474, AUC = 0.854208\n",
      "10 fold result: [[0.74440894 0.75095785 0.74738676 0.49369263 0.80790276]\n",
      " [0.72982456 0.76816609 0.74912892 0.49841442 0.82193893]\n",
      " [0.78498293 0.70357143 0.7452007  0.49053148 0.8349098 ]\n",
      " [0.79020979 0.75958188 0.77486911 0.55003296 0.86177237]\n",
      " [0.75       0.77162629 0.7609075  0.52178526 0.84226814]\n",
      " [0.85714285 0.6993007  0.77835951 0.5635955  0.85237933]\n",
      " [0.8172043  0.75510204 0.78534031 0.57274641 0.86200717]\n",
      " [0.83728813 0.74100719 0.79057592 0.58179621 0.86150469]\n",
      " [0.88405797 0.69023569 0.78359511 0.58267043 0.84891182]\n",
      " [0.79850746 0.75409836 0.77486911 0.55147354 0.85420847]]\n",
      "Sn = 0.7994 ± 0.0478\n",
      "Sp = 0.7394 ± 0.0286\n",
      "Acc = 0.7690 ± 0.0161\n",
      "Mcc = 0.5407 ± 0.0348\n",
      "Auc = 0.8448 ± 0.0174\n",
      "Epoch 1/200\n",
      "180/180 [==============================] - 10s 40ms/step - loss: 0.4807 - accuracy: 0.7819 - val_loss: 0.4797 - val_accuracy: 0.7799\n",
      "Epoch 2/200\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.4793 - accuracy: 0.7828"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-05 10:14:15.452535: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 6s 33ms/step - loss: 0.4793 - accuracy: 0.7828 - val_loss: 0.4732 - val_accuracy: 0.7925\n",
      "Epoch 3/200\n",
      "180/180 [==============================] - 6s 33ms/step - loss: 0.4792 - accuracy: 0.7828 - val_loss: 0.4799 - val_accuracy: 0.7846\n",
      "Epoch 4/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4777 - accuracy: 0.7828 - val_loss: 0.4755 - val_accuracy: 0.7799\n",
      "Epoch 5/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4777 - accuracy: 0.7840 - val_loss: 0.4724 - val_accuracy: 0.7925\n",
      "Epoch 6/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4780 - accuracy: 0.7889 - val_loss: 0.4723 - val_accuracy: 0.7862\n",
      "Epoch 7/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4793 - accuracy: 0.7821 - val_loss: 0.4727 - val_accuracy: 0.7940\n",
      "Epoch 8/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4780 - accuracy: 0.7840 - val_loss: 0.4755 - val_accuracy: 0.7940\n",
      "Epoch 9/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4790 - accuracy: 0.7844 - val_loss: 0.4776 - val_accuracy: 0.7877\n",
      "Epoch 10/200\n",
      "180/180 [==============================] - 6s 31ms/step - loss: 0.4778 - accuracy: 0.7852 - val_loss: 0.4780 - val_accuracy: 0.7909\n",
      "Epoch 11/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4750 - accuracy: 0.7842 - val_loss: 0.4724 - val_accuracy: 0.7909\n",
      "Epoch 12/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4792 - accuracy: 0.7845 - val_loss: 0.4756 - val_accuracy: 0.7814\n",
      "Epoch 13/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4784 - accuracy: 0.7861 - val_loss: 0.4755 - val_accuracy: 0.7893\n",
      "Epoch 14/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4783 - accuracy: 0.7823 - val_loss: 0.4767 - val_accuracy: 0.7877\n",
      "Epoch 15/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4777 - accuracy: 0.7835 - val_loss: 0.4769 - val_accuracy: 0.7830\n",
      "Epoch 16/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4782 - accuracy: 0.7809 - val_loss: 0.4808 - val_accuracy: 0.7862\n",
      "Epoch 17/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4774 - accuracy: 0.7844 - val_loss: 0.4798 - val_accuracy: 0.7893\n",
      "Epoch 18/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4753 - accuracy: 0.7891 - val_loss: 0.4846 - val_accuracy: 0.7862\n",
      "Epoch 19/200\n",
      "180/180 [==============================] - 6s 31ms/step - loss: 0.4763 - accuracy: 0.7831 - val_loss: 0.4834 - val_accuracy: 0.7893\n",
      "Epoch 20/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4771 - accuracy: 0.7887 - val_loss: 0.4829 - val_accuracy: 0.7893\n",
      "Epoch 21/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4765 - accuracy: 0.7859 - val_loss: 0.4795 - val_accuracy: 0.7909\n",
      "Epoch 22/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4758 - accuracy: 0.7851 - val_loss: 0.4760 - val_accuracy: 0.7830\n",
      "Epoch 23/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4765 - accuracy: 0.7840 - val_loss: 0.4761 - val_accuracy: 0.7925\n",
      "Epoch 24/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4760 - accuracy: 0.7863 - val_loss: 0.4758 - val_accuracy: 0.7814\n",
      "Epoch 25/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4749 - accuracy: 0.7866 - val_loss: 0.4908 - val_accuracy: 0.7767\n",
      "Epoch 26/200\n",
      "180/180 [==============================] - 6s 32ms/step - loss: 0.4745 - accuracy: 0.7859 - val_loss: 0.4733 - val_accuracy: 0.7877\n",
      "20/20 [==============================] - 1s 9ms/step\n",
      "-----------------------------------------------test---------------------------------------\n",
      "Sn = 0.786164, Sp = 0.789308, Acc = 0.787736, MCC = 0.575475, AUC = 0.867044\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "tf.random.set_seed(1)  # for reproducibility\n",
    "# reading model\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 200\n",
    "\n",
    "# # Cross-validation\n",
    "n = 10\n",
    "k_fold = KFold(n_splits=n, shuffle=True, random_state=42)\n",
    "\n",
    "all_performance = []\n",
    "tprs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "for fold_count, (train_index, val_index) in enumerate(k_fold.split(train)):\n",
    "    print('*' * 30 + ' the ' + str(fold_count + 1) + ' fold ' + '*' * 30)\n",
    "    trains, val = train[train_index], train[val_index]\n",
    "    trains_label, val_label = train_label[train_index], train_label[val_index]\n",
    "    zaoting = EarlyStopping(monitor='val_loss', patience=13, mode='auto')\n",
    "    xuexilv = WarmupExponentialDecay(lr_base=0.0002,decay=0.00002,warmup_epochs=2)\n",
    "    callback_lists=[xuexilv,zaoting]\n",
    "    model.fit(x=trains, y=trains_label, validation_data=(val, val_label), epochs=EPOCHS,\n",
    "                batch_size=BATCH_SIZE, shuffle=True,\n",
    "                callbacks=callback_lists,\n",
    "                verbose=1)\n",
    "     # 保存模型\n",
    "\n",
    "    model.save('./warmup_embedding/model_fold' + str(fold_count+1) + '.h5')\n",
    "\n",
    "    del model\n",
    "\n",
    "    model = load_model('./warmup_embedding/model_fold' + str(fold_count+1) + '.h5')\n",
    "\n",
    "    val_pred = model.predict(val, verbose=1)\n",
    "\n",
    "    # Sn, Sp, Acc, MCC, AUC\n",
    "    Sn, Sp, Acc, MCC = show_performance(val_label[:, 1], val_pred[:, 1])\n",
    "    AUC = roc_auc_score(val_label[:, 1], val_pred[:, 1])\n",
    "    print('Sn = %f, Sp = %f, Acc = %f, MCC = %f, AUC = %f' % (Sn, Sp, Acc, MCC, AUC))\n",
    "\n",
    "    performance = [Sn, Sp, Acc, MCC, AUC]\n",
    "    all_performance.append(performance)\n",
    "    \n",
    "all_performance = np.array(all_performance)\n",
    "print('10 fold result:', all_performance)\n",
    "performance_mean = performance_mean(all_performance)\n",
    "\n",
    "model.fit(x=train, y=train_label, validation_data=(test, test_label), epochs=EPOCHS,\n",
    "                      batch_size=BATCH_SIZE, shuffle=True,\n",
    "                      callbacks=[EarlyStopping(monitor='val_loss', patience=20, mode='auto')],\n",
    "                      verbose=1)\n",
    "model.save('./warmup_embedding/model_test.h5')\n",
    "\n",
    "del model\n",
    "\n",
    "model = load_model('./warmup_embedding/model_test.h5')\n",
    "\n",
    "test_score = model.predict(test)\n",
    "\n",
    "\n",
    "# Sn, Sp, Acc, MCC, AUC\n",
    "Sn, Sp, Acc, MCC = show_performance(test_label[:,1], test_score[:,1])\n",
    "AUC = roc_auc_score(test_label[:,1], test_score[:,1])\n",
    "\n",
    "print('-----------------------------------------------test---------------------------------------')\n",
    "print('Sn = %f, Sp = %f, Acc = %f, MCC = %f, AUC = %f' % (Sn, Sp, Acc, MCC, AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09198350-6b5c-48b5-912e-039d21172b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
