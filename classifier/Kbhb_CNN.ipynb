{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22e08b37-4339-4208-937b-568765c5a1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 10:20:44.293295: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-06-12 10:20:44.709992: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-12 10:20:45.467873: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, Conv1D, GlobalAvgPool2D, GlobalAveragePooling1D, \\\n",
    "    Dropout, Dense, Activation, Concatenate, Multiply, MaxPool2D, Add,  \\\n",
    "    LSTM, Bidirectional, Conv2D, AveragePooling2D, BatchNormalization, Flatten, GlobalAveragePooling2D, \\\n",
    "    GlobalMaxPooling2D, Reshape, Permute, multiply, Lambda, add, subtract, MaxPooling2D, GRU, ReLU, MaxPooling1D \n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from keras.models import Model, load_model\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.layers import Embedding\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.regularizers import l1, l2\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from Bio import SeqIO\n",
    "mpl.use('TkAgg')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import math\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from keras import initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "825a50ff-e8b2-4c2c-84c9-89d240f77f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 10:20:51.638615: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11123 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:65:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # 不全部占满显存，按需分配当allow_growth设置为True时，分配器将不会指定所有的GPU内存，而是根据需求增长\n",
    "session = tf.compat.v1.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d7cd182-d2a8-4da6-b1e8-08157c786216",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_fasta(file_path):\n",
    "    '''File_path: Path to the fasta file\n",
    "       Returns: List of sequence\n",
    "    '''\n",
    "    one=list(SeqIO.parse(file_path,'fasta'))\n",
    "    return one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4f9871f-d04c-4270-ba6d-341dd4b89641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def protein_to_Kmer(seqs,K):\n",
    "    numeric_sequences = []\n",
    "    base_to_index = {'A': 0, 'C': 1, 'D': 2, 'E': 3,\n",
    "                     'F': 4, 'G': 5, 'H': 6, 'I': 7, 'K': 8, 'L': 9, 'M': 10,\n",
    "                     'N': 11, 'P': 12, 'Q': 13, 'R': 14, 'S': 15, 'T': 16, \n",
    "                     'V': 17, 'W': 18, 'Y': 19,'X': 20\n",
    "                     }\n",
    "    for dna_sequence in seqs:\n",
    "        numeric_sequence = []\n",
    "        for base in dna_sequence:\n",
    "            numeric_sequence.append(base_to_index[base])\n",
    "\n",
    "        kmer_sequence = []\n",
    "        for i in range(len(numeric_sequence) - (K - 1)):\n",
    "            kmer = numeric_sequence[i:i + K]\n",
    "            kmer_marge = [int(\"\".join(map(str, kmer)))]\n",
    "            kmer_sequence.append(kmer_marge)\n",
    "\n",
    "        numeric_sequences.append(kmer_sequence)\n",
    "    return numeric_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "277d90ae-8582-49dd-8639-de8771f5bd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the training set\n",
    "    \n",
    "train_pos_seqs = np.array(read_fasta('./data_Kbhb/train_15/Kbhb_pos_15_train.txt'))\n",
    "train_neg_seqs = np.array(read_fasta('./data_Kbhb/train_15/Kbhb_neg_15_train.txt'))\n",
    "\n",
    "train_seqs = np.concatenate( (train_pos_seqs, train_neg_seqs), axis=0 )\n",
    "\n",
    "train = np.array(protein_to_Kmer(train_seqs,1)).astype(np.float32)\n",
    "\n",
    "train_label = np.array( [1] * 2866 + [0] * 2866 ).astype( np.float32 )\n",
    "train_label = to_categorical( train_label, num_classes=2 )\n",
    "\n",
    "# Read the testing set\n",
    "test_pos_seqs = np.array(read_fasta('./data_Kbhb/train_15/Kbhb_pos_15_test.txt'))\n",
    "test_neg_seqs = np.array(read_fasta('./data_Kbhb/train_15/Kbhb_neg_15_test.txt'))\n",
    "\n",
    "test_seqs = np.concatenate((test_pos_seqs, test_neg_seqs), axis=0)\n",
    "\n",
    "test = np.array(protein_to_Kmer(test_seqs,1)).astype(np.float32)\n",
    "\n",
    "test_label = np.array([1] * 318 + [0] * 318).astype(np.float32)\n",
    "test_label = to_categorical(test_label, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61e53cb5-ee02-478d-a57d-f4191a2bc955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance evaluation\n",
    "def show_performance(y_true, y_pred):\n",
    "\n",
    "    TP, FP, FN, TN = 0, 0, 0, 0\n",
    "\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i] == 1:\n",
    "            if y_pred[i] > 0.5:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "        if y_true[i] == 0:\n",
    "            if y_pred[i] > 0.5:\n",
    "                FP += 1\n",
    "            else:\n",
    "                TN += 1\n",
    "\n",
    "\n",
    "    Sn = TP / (TP + FN + 1e-06)\n",
    "\n",
    "    Sp = TN / (FP + TN + 1e-06)\n",
    "\n",
    "    Acc = (TP + TN) / len(y_true)\n",
    "\n",
    "    MCC = ((TP * TN) - (FP * FN)) / np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN) + 1e-06)\n",
    "\n",
    "    return Sn, Sp, Acc, MCC\n",
    "\n",
    "def performance_mean(performance):\n",
    "    print('Sn = %.4f ± %.4f' % (np.mean(performance[:, 0]), np.std(performance[:, 0])))\n",
    "    print('Sp = %.4f ± %.4f' % (np.mean(performance[:, 1]), np.std(performance[:, 1])))\n",
    "    print('Acc = %.4f ± %.4f' % (np.mean(performance[:, 2]), np.std(performance[:, 2])))\n",
    "    print('Mcc = %.4f ± %.4f' % (np.mean(performance[:, 3]), np.std(performance[:, 3])))\n",
    "    print('Auc = %.4f ± %.4f' % (np.mean(performance[:, 4]), np.std(performance[:, 4])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c5a31fe-28cf-49d5-814b-c9fec6b09ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model\n",
    "def build_model(windows=15,embed_dim=64, weight_decay=1e-4,num_heads=8,ff_dim=64):\n",
    "\n",
    "    print('*' * 30 + 'CNN' + '*' * 30)\n",
    "    input_1 = Input(shape=(windows,))\n",
    "    # Word embedding coding\n",
    "    embedding = Embedding(21, embed_dim, input_length=15)\n",
    "    x_1 = embedding(input_1)\n",
    "    print(x_1.shape)\n",
    "    #transformer = TransformerBlock(embed_dim, num_heads, ff_dim)(x_1)\n",
    "    #print(transformer.shape)\n",
    "\n",
    "    x_1 = Conv1D(filters = 32, kernel_size = 1, padding = 'same', activation= 'relu')(x_1)\n",
    "    x_1 = MaxPooling1D(pool_size=2,strides=1,padding=\"SAME\")(x_1)\n",
    "    x_1 = Conv1D(filters = 32, kernel_size =  1, padding = 'same', activation= 'relu')(x_1)\n",
    "    x_1 = MaxPooling1D(pool_size=2,strides=1,padding=\"SAME\")(x_1)\n",
    "    print(x_1.shape)\n",
    "    \n",
    "    x = Flatten()(x_1)\n",
    "    x = Dense(units=2, activation='softmax')(x)\n",
    "\n",
    "\n",
    "    inputs = [input_1]\n",
    "    outputs = [x]\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs, name=\"Kbhb\")\n",
    "\n",
    "    optimizer = Adam(learning_rate=1e-4, epsilon=1e-7)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1471f8d-414c-41c1-92c3-70ffe813b251",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************CNN******************************\n",
      "(None, 15, 64)\n",
      "(None, 15, 32)\n",
      "****************************** the 1 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 5s 22ms/step - loss: 0.6909 - accuracy: 0.5417 - val_loss: 0.6894 - val_accuracy: 0.5470\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.6826 - accuracy: 0.5727 - val_loss: 0.6785 - val_accuracy: 0.6289\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.6659 - accuracy: 0.6458 - val_loss: 0.6608 - val_accuracy: 0.6202\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.6408 - accuracy: 0.6582 - val_loss: 0.6345 - val_accuracy: 0.6516\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.6187 - accuracy: 0.6687 - val_loss: 0.6216 - val_accuracy: 0.6551\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.6059 - accuracy: 0.6764 - val_loss: 0.6203 - val_accuracy: 0.6603\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5995 - accuracy: 0.6809 - val_loss: 0.6109 - val_accuracy: 0.6638\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5954 - accuracy: 0.6805 - val_loss: 0.6149 - val_accuracy: 0.6603\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5926 - accuracy: 0.6879 - val_loss: 0.6125 - val_accuracy: 0.6585\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5896 - accuracy: 0.6861 - val_loss: 0.6138 - val_accuracy: 0.6533\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5870 - accuracy: 0.6871 - val_loss: 0.6109 - val_accuracy: 0.6551\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5839 - accuracy: 0.6896 - val_loss: 0.6149 - val_accuracy: 0.6655\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5821 - accuracy: 0.6966 - val_loss: 0.6043 - val_accuracy: 0.6620\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5800 - accuracy: 0.6962 - val_loss: 0.6025 - val_accuracy: 0.6707\n",
      "Epoch 15/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5773 - accuracy: 0.6964 - val_loss: 0.6015 - val_accuracy: 0.6777\n",
      "Epoch 16/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5755 - accuracy: 0.6964 - val_loss: 0.5978 - val_accuracy: 0.6882\n",
      "Epoch 17/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5739 - accuracy: 0.7014 - val_loss: 0.6030 - val_accuracy: 0.6760\n",
      "Epoch 18/200\n",
      "162/162 [==============================] - ETA: 0s - loss: 0.5719 - accuracy: 0.7022"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-01 20:12:35.774044: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5719 - accuracy: 0.7022 - val_loss: 0.5985 - val_accuracy: 0.6951\n",
      "Epoch 19/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5700 - accuracy: 0.7024 - val_loss: 0.5931 - val_accuracy: 0.6986\n",
      "Epoch 20/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5687 - accuracy: 0.7010 - val_loss: 0.5972 - val_accuracy: 0.6969\n",
      "Epoch 21/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5670 - accuracy: 0.7051 - val_loss: 0.5948 - val_accuracy: 0.6986\n",
      "Epoch 22/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5659 - accuracy: 0.7055 - val_loss: 0.5926 - val_accuracy: 0.7003\n",
      "Epoch 23/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5650 - accuracy: 0.7078 - val_loss: 0.5944 - val_accuracy: 0.6969\n",
      "Epoch 24/200\n",
      "162/162 [==============================] - 3s 16ms/step - loss: 0.5632 - accuracy: 0.7076 - val_loss: 0.5906 - val_accuracy: 0.7073\n",
      "Epoch 25/200\n",
      "162/162 [==============================] - 1s 6ms/step - loss: 0.5625 - accuracy: 0.7071 - val_loss: 0.5902 - val_accuracy: 0.7125\n",
      "Epoch 26/200\n",
      "162/162 [==============================] - 3s 16ms/step - loss: 0.5610 - accuracy: 0.7080 - val_loss: 0.5954 - val_accuracy: 0.7003\n",
      "Epoch 27/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5602 - accuracy: 0.7069 - val_loss: 0.5974 - val_accuracy: 0.6969\n",
      "Epoch 28/200\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 0.5589 - accuracy: 0.7123 - val_loss: 0.5911 - val_accuracy: 0.7073\n",
      "Epoch 29/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5570 - accuracy: 0.7113 - val_loss: 0.5877 - val_accuracy: 0.7108\n",
      "Epoch 30/200\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 0.5566 - accuracy: 0.7115 - val_loss: 0.5887 - val_accuracy: 0.7125\n",
      "Epoch 31/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5549 - accuracy: 0.7133 - val_loss: 0.5939 - val_accuracy: 0.7091\n",
      "Epoch 32/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5545 - accuracy: 0.7129 - val_loss: 0.5904 - val_accuracy: 0.7160\n",
      "Epoch 33/200\n",
      "162/162 [==============================] - 3s 22ms/step - loss: 0.5537 - accuracy: 0.7168 - val_loss: 0.5903 - val_accuracy: 0.7143\n",
      "Epoch 34/200\n",
      "162/162 [==============================] - ETA: 0s - loss: 0.5527 - accuracy: 0.7129"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-01 20:13:25.750538: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 4s 23ms/step - loss: 0.5527 - accuracy: 0.7129 - val_loss: 0.5858 - val_accuracy: 0.7143\n",
      "Epoch 35/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5517 - accuracy: 0.7166 - val_loss: 0.5832 - val_accuracy: 0.7091\n",
      "Epoch 36/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5510 - accuracy: 0.7160 - val_loss: 0.5845 - val_accuracy: 0.7108\n",
      "Epoch 37/200\n",
      "162/162 [==============================] - 3s 22ms/step - loss: 0.5495 - accuracy: 0.7175 - val_loss: 0.5850 - val_accuracy: 0.7160\n",
      "Epoch 38/200\n",
      "162/162 [==============================] - 3s 22ms/step - loss: 0.5493 - accuracy: 0.7199 - val_loss: 0.5858 - val_accuracy: 0.7178\n",
      "Epoch 39/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5484 - accuracy: 0.7187 - val_loss: 0.5849 - val_accuracy: 0.7143\n",
      "Epoch 40/200\n",
      "162/162 [==============================] - 3s 22ms/step - loss: 0.5473 - accuracy: 0.7200 - val_loss: 0.5817 - val_accuracy: 0.7108\n",
      "Epoch 41/200\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 0.5466 - accuracy: 0.7226 - val_loss: 0.5804 - val_accuracy: 0.7160\n",
      "Epoch 42/200\n",
      "162/162 [==============================] - 3s 22ms/step - loss: 0.5456 - accuracy: 0.7239 - val_loss: 0.5804 - val_accuracy: 0.7178\n",
      "Epoch 43/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5455 - accuracy: 0.7187 - val_loss: 0.5829 - val_accuracy: 0.7108\n",
      "Epoch 44/200\n",
      "162/162 [==============================] - 3s 22ms/step - loss: 0.5444 - accuracy: 0.7226 - val_loss: 0.5882 - val_accuracy: 0.7108\n",
      "Epoch 45/200\n",
      "162/162 [==============================] - 3s 22ms/step - loss: 0.5438 - accuracy: 0.7214 - val_loss: 0.5911 - val_accuracy: 0.7125\n",
      "Epoch 46/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5431 - accuracy: 0.7253 - val_loss: 0.5903 - val_accuracy: 0.7160\n",
      "Epoch 47/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5422 - accuracy: 0.7257 - val_loss: 0.5832 - val_accuracy: 0.7143\n",
      "Epoch 48/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5421 - accuracy: 0.7230 - val_loss: 0.5805 - val_accuracy: 0.7073\n",
      "Epoch 49/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5408 - accuracy: 0.7253 - val_loss: 0.5793 - val_accuracy: 0.7125\n",
      "Epoch 50/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5401 - accuracy: 0.7239 - val_loss: 0.5751 - val_accuracy: 0.7178\n",
      "Epoch 51/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5398 - accuracy: 0.7222 - val_loss: 0.5839 - val_accuracy: 0.7160\n",
      "Epoch 52/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5390 - accuracy: 0.7251 - val_loss: 0.5790 - val_accuracy: 0.7108\n",
      "Epoch 53/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5384 - accuracy: 0.7292 - val_loss: 0.5750 - val_accuracy: 0.7195\n",
      "Epoch 54/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5376 - accuracy: 0.7278 - val_loss: 0.5858 - val_accuracy: 0.7230\n",
      "Epoch 55/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5370 - accuracy: 0.7301 - val_loss: 0.5834 - val_accuracy: 0.7213\n",
      "Epoch 56/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5366 - accuracy: 0.7278 - val_loss: 0.5808 - val_accuracy: 0.7160\n",
      "Epoch 57/200\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 0.5357 - accuracy: 0.7307 - val_loss: 0.5768 - val_accuracy: 0.7195\n",
      "Epoch 58/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5357 - accuracy: 0.7305 - val_loss: 0.5888 - val_accuracy: 0.7160\n",
      "Epoch 59/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5346 - accuracy: 0.7280 - val_loss: 0.5845 - val_accuracy: 0.7178\n",
      "Epoch 60/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5335 - accuracy: 0.7332 - val_loss: 0.5760 - val_accuracy: 0.7195\n",
      "Epoch 61/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5333 - accuracy: 0.7338 - val_loss: 0.5818 - val_accuracy: 0.7195\n",
      "Epoch 62/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5343 - accuracy: 0.7311 - val_loss: 0.5781 - val_accuracy: 0.7247\n",
      "Epoch 63/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5328 - accuracy: 0.7315 - val_loss: 0.5779 - val_accuracy: 0.7282\n",
      "Epoch 64/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5319 - accuracy: 0.7338 - val_loss: 0.5792 - val_accuracy: 0.7247\n",
      "Epoch 65/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5312 - accuracy: 0.7307 - val_loss: 0.5761 - val_accuracy: 0.7230\n",
      "Epoch 66/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5306 - accuracy: 0.7342 - val_loss: 0.5865 - val_accuracy: 0.7178\n",
      "18/18 [==============================] - 0s 5ms/step\n",
      "Sn = 0.670927, Sp = 0.773946, Acc = 0.717770, MCC = 0.443918, AUC = 0.777655\n",
      "****************************** the 2 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 5s 24ms/step - loss: 0.5315 - accuracy: 0.7373 - val_loss: 0.5672 - val_accuracy: 0.7073\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5307 - accuracy: 0.7377 - val_loss: 0.5701 - val_accuracy: 0.7108\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5300 - accuracy: 0.7377 - val_loss: 0.5684 - val_accuracy: 0.7073\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5293 - accuracy: 0.7363 - val_loss: 0.5726 - val_accuracy: 0.7143\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5282 - accuracy: 0.7398 - val_loss: 0.5712 - val_accuracy: 0.7056\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5283 - accuracy: 0.7390 - val_loss: 0.5712 - val_accuracy: 0.7021\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5271 - accuracy: 0.7344 - val_loss: 0.5754 - val_accuracy: 0.7125\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5264 - accuracy: 0.7383 - val_loss: 0.5721 - val_accuracy: 0.7038\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5263 - accuracy: 0.7414 - val_loss: 0.5763 - val_accuracy: 0.7125\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 0.5257 - accuracy: 0.7385 - val_loss: 0.5748 - val_accuracy: 0.7056\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5256 - accuracy: 0.7390 - val_loss: 0.5746 - val_accuracy: 0.6986\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5237 - accuracy: 0.7423 - val_loss: 0.5746 - val_accuracy: 0.6986\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5242 - accuracy: 0.7408 - val_loss: 0.5764 - val_accuracy: 0.7073\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5232 - accuracy: 0.7390 - val_loss: 0.5758 - val_accuracy: 0.7038\n",
      "18/18 [==============================] - 0s 5ms/step\n",
      "Sn = 0.722807, Sp = 0.685121, Acc = 0.703833, MCC = 0.408166, AUC = 0.768348\n",
      "****************************** the 3 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 6s 33ms/step - loss: 0.5280 - accuracy: 0.7383 - val_loss: 0.5313 - val_accuracy: 0.7330\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.5274 - accuracy: 0.7383 - val_loss: 0.5341 - val_accuracy: 0.7277\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 0.5263 - accuracy: 0.7401 - val_loss: 0.5342 - val_accuracy: 0.7277\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5260 - accuracy: 0.7408 - val_loss: 0.5347 - val_accuracy: 0.7260\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5252 - accuracy: 0.7405 - val_loss: 0.5359 - val_accuracy: 0.7208\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5247 - accuracy: 0.7389 - val_loss: 0.5407 - val_accuracy: 0.7260\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5240 - accuracy: 0.7416 - val_loss: 0.5382 - val_accuracy: 0.7243\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5239 - accuracy: 0.7428 - val_loss: 0.5384 - val_accuracy: 0.7225\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5236 - accuracy: 0.7412 - val_loss: 0.5387 - val_accuracy: 0.7260\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5226 - accuracy: 0.7437 - val_loss: 0.5391 - val_accuracy: 0.7190\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5220 - accuracy: 0.7430 - val_loss: 0.5393 - val_accuracy: 0.7190\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5211 - accuracy: 0.7443 - val_loss: 0.5423 - val_accuracy: 0.7173\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5210 - accuracy: 0.7443 - val_loss: 0.5404 - val_accuracy: 0.7190\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 3s 18ms/step - loss: 0.5202 - accuracy: 0.7467 - val_loss: 0.5404 - val_accuracy: 0.7225\n",
      "18/18 [==============================] - 0s 5ms/step\n",
      "Sn = 0.764505, Sp = 0.678571, Acc = 0.722513, MCC = 0.445017, AUC = 0.801767\n",
      "****************************** the 4 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 5s 24ms/step - loss: 0.5252 - accuracy: 0.7397 - val_loss: 0.4896 - val_accuracy: 0.7714\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5260 - accuracy: 0.7401 - val_loss: 0.4958 - val_accuracy: 0.7627\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 0.5246 - accuracy: 0.7430 - val_loss: 0.4956 - val_accuracy: 0.7627\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5241 - accuracy: 0.7406 - val_loss: 0.4909 - val_accuracy: 0.7661\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5234 - accuracy: 0.7393 - val_loss: 0.4943 - val_accuracy: 0.7661\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5232 - accuracy: 0.7410 - val_loss: 0.4999 - val_accuracy: 0.7609\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5227 - accuracy: 0.7406 - val_loss: 0.4989 - val_accuracy: 0.7609\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5223 - accuracy: 0.7397 - val_loss: 0.4996 - val_accuracy: 0.7609\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5222 - accuracy: 0.7449 - val_loss: 0.4953 - val_accuracy: 0.7644\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5216 - accuracy: 0.7418 - val_loss: 0.4954 - val_accuracy: 0.7644\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5215 - accuracy: 0.7426 - val_loss: 0.4957 - val_accuracy: 0.7644\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5200 - accuracy: 0.7430 - val_loss: 0.5020 - val_accuracy: 0.7609\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5202 - accuracy: 0.7461 - val_loss: 0.5022 - val_accuracy: 0.7627\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5191 - accuracy: 0.7432 - val_loss: 0.4980 - val_accuracy: 0.7627\n",
      "18/18 [==============================] - 0s 5ms/step\n",
      "Sn = 0.716783, Sp = 0.808362, Acc = 0.762653, MCC = 0.527406, AUC = 0.841817\n",
      "****************************** the 5 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 5s 23ms/step - loss: 0.5187 - accuracy: 0.7494 - val_loss: 0.5012 - val_accuracy: 0.7469\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5184 - accuracy: 0.7482 - val_loss: 0.5013 - val_accuracy: 0.7557\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5177 - accuracy: 0.7490 - val_loss: 0.5042 - val_accuracy: 0.7469\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 0.5167 - accuracy: 0.7463 - val_loss: 0.5088 - val_accuracy: 0.7382\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 3s 22ms/step - loss: 0.5169 - accuracy: 0.7488 - val_loss: 0.5062 - val_accuracy: 0.7452\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5164 - accuracy: 0.7488 - val_loss: 0.5068 - val_accuracy: 0.7504\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5155 - accuracy: 0.7517 - val_loss: 0.5091 - val_accuracy: 0.7435\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5153 - accuracy: 0.7509 - val_loss: 0.5096 - val_accuracy: 0.7469\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5145 - accuracy: 0.7517 - val_loss: 0.5110 - val_accuracy: 0.7435\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5139 - accuracy: 0.7507 - val_loss: 0.5154 - val_accuracy: 0.7365\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 0.5147 - accuracy: 0.7484 - val_loss: 0.5126 - val_accuracy: 0.7417\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5128 - accuracy: 0.7554 - val_loss: 0.5122 - val_accuracy: 0.7435\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5133 - accuracy: 0.7509 - val_loss: 0.5128 - val_accuracy: 0.7382\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5121 - accuracy: 0.7513 - val_loss: 0.5203 - val_accuracy: 0.7382\n",
      "18/18 [==============================] - 0s 5ms/step\n",
      "Sn = 0.816901, Sp = 0.660900, Acc = 0.738220, MCC = 0.483387, AUC = 0.824029\n",
      "****************************** the 6 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 5s 24ms/step - loss: 0.5116 - accuracy: 0.7484 - val_loss: 0.5176 - val_accuracy: 0.7469\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5115 - accuracy: 0.7505 - val_loss: 0.5205 - val_accuracy: 0.7504\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 0.5107 - accuracy: 0.7521 - val_loss: 0.5220 - val_accuracy: 0.7452\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5099 - accuracy: 0.7525 - val_loss: 0.5249 - val_accuracy: 0.7435\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5090 - accuracy: 0.7509 - val_loss: 0.5278 - val_accuracy: 0.7417\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5094 - accuracy: 0.7505 - val_loss: 0.5279 - val_accuracy: 0.7487\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5078 - accuracy: 0.7521 - val_loss: 0.5289 - val_accuracy: 0.7435\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5079 - accuracy: 0.7538 - val_loss: 0.5298 - val_accuracy: 0.7330\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5075 - accuracy: 0.7519 - val_loss: 0.5309 - val_accuracy: 0.7312\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5062 - accuracy: 0.7544 - val_loss: 0.5333 - val_accuracy: 0.7330\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5071 - accuracy: 0.7519 - val_loss: 0.5325 - val_accuracy: 0.7295\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5060 - accuracy: 0.7517 - val_loss: 0.5334 - val_accuracy: 0.7295\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5055 - accuracy: 0.7544 - val_loss: 0.5346 - val_accuracy: 0.7312\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5049 - accuracy: 0.7503 - val_loss: 0.5378 - val_accuracy: 0.7330\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Sn = 0.804878, Sp = 0.660839, Acc = 0.732984, MCC = 0.470681, AUC = 0.806949\n",
      "****************************** the 7 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 5s 24ms/step - loss: 0.5126 - accuracy: 0.7476 - val_loss: 0.4704 - val_accuracy: 0.7784\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5118 - accuracy: 0.7511 - val_loss: 0.4739 - val_accuracy: 0.7644\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5105 - accuracy: 0.7544 - val_loss: 0.4745 - val_accuracy: 0.7749\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.5105 - accuracy: 0.7519 - val_loss: 0.4753 - val_accuracy: 0.7714\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5092 - accuracy: 0.7534 - val_loss: 0.4785 - val_accuracy: 0.7661\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5095 - accuracy: 0.7517 - val_loss: 0.4798 - val_accuracy: 0.7644\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 0.5084 - accuracy: 0.7563 - val_loss: 0.4794 - val_accuracy: 0.7661\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 0.5081 - accuracy: 0.7546 - val_loss: 0.4802 - val_accuracy: 0.7696\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5085 - accuracy: 0.7515 - val_loss: 0.4808 - val_accuracy: 0.7661\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5069 - accuracy: 0.7546 - val_loss: 0.4816 - val_accuracy: 0.7714\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5070 - accuracy: 0.7523 - val_loss: 0.4824 - val_accuracy: 0.7679\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 0.5061 - accuracy: 0.7544 - val_loss: 0.4835 - val_accuracy: 0.7627\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 0.5060 - accuracy: 0.7573 - val_loss: 0.4839 - val_accuracy: 0.7679\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 0.5056 - accuracy: 0.7550 - val_loss: 0.4843 - val_accuracy: 0.7644\n",
      "18/18 [==============================] - 0s 5ms/step\n",
      "Sn = 0.774194, Sp = 0.755102, Acc = 0.764398, MCC = 0.529121, AUC = 0.846671\n",
      "****************************** the 8 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 5s 24ms/step - loss: 0.5032 - accuracy: 0.7593 - val_loss: 0.5036 - val_accuracy: 0.7452\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 3s 22ms/step - loss: 0.5026 - accuracy: 0.7608 - val_loss: 0.5066 - val_accuracy: 0.7400\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5020 - accuracy: 0.7606 - val_loss: 0.5082 - val_accuracy: 0.7382\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.5007 - accuracy: 0.7618 - val_loss: 0.5118 - val_accuracy: 0.7277\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5007 - accuracy: 0.7618 - val_loss: 0.5114 - val_accuracy: 0.7382\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5003 - accuracy: 0.7602 - val_loss: 0.5136 - val_accuracy: 0.7330\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.4993 - accuracy: 0.7600 - val_loss: 0.5141 - val_accuracy: 0.7347\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 3s 22ms/step - loss: 0.4998 - accuracy: 0.7635 - val_loss: 0.5150 - val_accuracy: 0.7260\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.4988 - accuracy: 0.7653 - val_loss: 0.5162 - val_accuracy: 0.7312\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.4984 - accuracy: 0.7631 - val_loss: 0.5172 - val_accuracy: 0.7295\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 3s 17ms/step - loss: 0.4983 - accuracy: 0.7631 - val_loss: 0.5180 - val_accuracy: 0.7277\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 1s 7ms/step - loss: 0.4968 - accuracy: 0.7651 - val_loss: 0.5197 - val_accuracy: 0.7243\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.4969 - accuracy: 0.7622 - val_loss: 0.5200 - val_accuracy: 0.7295\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.4962 - accuracy: 0.7653 - val_loss: 0.5229 - val_accuracy: 0.7155\n",
      "18/18 [==============================] - 0s 5ms/step\n",
      "Sn = 0.776271, Sp = 0.651079, Acc = 0.715532, MCC = 0.431281, AUC = 0.814096\n",
      "****************************** the 9 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 5s 24ms/step - loss: 0.4975 - accuracy: 0.7591 - val_loss: 0.5107 - val_accuracy: 0.7487\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.4965 - accuracy: 0.7629 - val_loss: 0.5124 - val_accuracy: 0.7435\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.4959 - accuracy: 0.7658 - val_loss: 0.5146 - val_accuracy: 0.7417\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.4952 - accuracy: 0.7639 - val_loss: 0.5182 - val_accuracy: 0.7400\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.4949 - accuracy: 0.7649 - val_loss: 0.5183 - val_accuracy: 0.7417\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 3s 22ms/step - loss: 0.4943 - accuracy: 0.7616 - val_loss: 0.5198 - val_accuracy: 0.7417\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.4936 - accuracy: 0.7635 - val_loss: 0.5251 - val_accuracy: 0.7365\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.4938 - accuracy: 0.7668 - val_loss: 0.5230 - val_accuracy: 0.7330\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 3s 22ms/step - loss: 0.4932 - accuracy: 0.7643 - val_loss: 0.5248 - val_accuracy: 0.7330\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 3s 22ms/step - loss: 0.4929 - accuracy: 0.7660 - val_loss: 0.5283 - val_accuracy: 0.7330\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.4927 - accuracy: 0.7651 - val_loss: 0.5275 - val_accuracy: 0.7295\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 0.4913 - accuracy: 0.7643 - val_loss: 0.5270 - val_accuracy: 0.7347\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.4914 - accuracy: 0.7670 - val_loss: 0.5281 - val_accuracy: 0.7312\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.4905 - accuracy: 0.7645 - val_loss: 0.5405 - val_accuracy: 0.7208\n",
      "18/18 [==============================] - 0s 5ms/step\n",
      "Sn = 0.818841, Sp = 0.629630, Acc = 0.720768, MCC = 0.455012, AUC = 0.809996\n",
      "****************************** the 10 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 5s 24ms/step - loss: 0.4950 - accuracy: 0.7620 - val_loss: 0.4862 - val_accuracy: 0.7888\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 0.4950 - accuracy: 0.7571 - val_loss: 0.4890 - val_accuracy: 0.7801\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.4937 - accuracy: 0.7593 - val_loss: 0.4908 - val_accuracy: 0.7784\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.4933 - accuracy: 0.7604 - val_loss: 0.4969 - val_accuracy: 0.7696\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.4928 - accuracy: 0.7606 - val_loss: 0.4947 - val_accuracy: 0.7749\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.4936 - accuracy: 0.7624 - val_loss: 0.4966 - val_accuracy: 0.7679\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.4919 - accuracy: 0.7622 - val_loss: 0.5027 - val_accuracy: 0.7696\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 0.4922 - accuracy: 0.7618 - val_loss: 0.4988 - val_accuracy: 0.7679\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.4915 - accuracy: 0.7645 - val_loss: 0.5000 - val_accuracy: 0.7749\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.4904 - accuracy: 0.7633 - val_loss: 0.5004 - val_accuracy: 0.7731\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 0.4910 - accuracy: 0.7641 - val_loss: 0.5026 - val_accuracy: 0.7696\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 0.4897 - accuracy: 0.7641 - val_loss: 0.5018 - val_accuracy: 0.7679\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.4899 - accuracy: 0.7645 - val_loss: 0.5032 - val_accuracy: 0.7714\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 0.4889 - accuracy: 0.7633 - val_loss: 0.5067 - val_accuracy: 0.7592\n",
      "18/18 [==============================] - 0s 5ms/step\n",
      "Sn = 0.783582, Sp = 0.737705, Acc = 0.759162, MCC = 0.520238, AUC = 0.836433\n",
      "10 fold result: [[0.67092652 0.77394636 0.71777003 0.44391753 0.77765537]\n",
      " [0.72280702 0.6851211  0.70383275 0.40816606 0.76834821]\n",
      " [0.76450512 0.67857143 0.72251309 0.44501729 0.80176743]\n",
      " [0.71678321 0.80836237 0.76265271 0.52740573 0.84181672]\n",
      " [0.81690141 0.66089965 0.7382199  0.48338714 0.82402895]\n",
      " [0.80487805 0.66083916 0.73298429 0.47068059 0.80694915]\n",
      " [0.77419355 0.75510204 0.76439791 0.52912145 0.84667057]\n",
      " [0.77627118 0.65107913 0.71553229 0.43128084 0.81409584]\n",
      " [0.81884058 0.62962963 0.72076789 0.45501169 0.8099961 ]\n",
      " [0.78358209 0.73770492 0.7591623  0.52023792 0.83643259]]\n",
      "Sn = 0.7650 ± 0.0455\n",
      "Sp = 0.7041 ± 0.0571\n",
      "Acc = 0.7338 ± 0.0205\n",
      "Mcc = 0.4714 ± 0.0404\n",
      "Auc = 0.8128 ± 0.0246\n",
      "Epoch 1/200\n",
      "180/180 [==============================] - 7s 32ms/step - loss: 0.4912 - accuracy: 0.7603 - val_loss: 0.5921 - val_accuracy: 0.6997\n",
      "Epoch 2/200\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.4898 - accuracy: 0.7645"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-01 20:22:54.377699: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 4s 19ms/step - loss: 0.4898 - accuracy: 0.7645 - val_loss: 0.5924 - val_accuracy: 0.6934\n",
      "Epoch 3/200\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.4890 - accuracy: 0.7699 - val_loss: 0.5951 - val_accuracy: 0.6840\n",
      "Epoch 4/200\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.4894 - accuracy: 0.7680 - val_loss: 0.5920 - val_accuracy: 0.6918\n",
      "Epoch 5/200\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.4892 - accuracy: 0.7643 - val_loss: 0.5920 - val_accuracy: 0.6950\n",
      "Epoch 6/200\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.4887 - accuracy: 0.7681 - val_loss: 0.5941 - val_accuracy: 0.6840\n",
      "Epoch 7/200\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.4885 - accuracy: 0.7652 - val_loss: 0.5931 - val_accuracy: 0.6918\n",
      "Epoch 8/200\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.4884 - accuracy: 0.7647 - val_loss: 0.5939 - val_accuracy: 0.6824\n",
      "Epoch 9/200\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.4874 - accuracy: 0.7671 - val_loss: 0.5954 - val_accuracy: 0.6855\n",
      "Epoch 10/200\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.4875 - accuracy: 0.7678 - val_loss: 0.5972 - val_accuracy: 0.6871\n",
      "Epoch 11/200\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.4860 - accuracy: 0.7709 - val_loss: 0.5955 - val_accuracy: 0.6824\n",
      "Epoch 12/200\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.4857 - accuracy: 0.7704 - val_loss: 0.5942 - val_accuracy: 0.6950\n",
      "Epoch 13/200\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.4854 - accuracy: 0.7667 - val_loss: 0.5965 - val_accuracy: 0.6840\n",
      "Epoch 14/200\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.4855 - accuracy: 0.7701 - val_loss: 0.5953 - val_accuracy: 0.6871\n",
      "Epoch 15/200\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.4859 - accuracy: 0.7708 - val_loss: 0.5955 - val_accuracy: 0.6950\n",
      "Epoch 16/200\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.4856 - accuracy: 0.7699 - val_loss: 0.5960 - val_accuracy: 0.6903\n",
      "Epoch 17/200\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.4849 - accuracy: 0.7688 - val_loss: 0.5978 - val_accuracy: 0.6871\n",
      "Epoch 18/200\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.4847 - accuracy: 0.7711 - val_loss: 0.6017 - val_accuracy: 0.6840\n",
      "Epoch 19/200\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.4844 - accuracy: 0.7657 - val_loss: 0.5994 - val_accuracy: 0.6871\n",
      "Epoch 20/200\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.4839 - accuracy: 0.7671 - val_loss: 0.5979 - val_accuracy: 0.6950\n",
      "Epoch 21/200\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.4839 - accuracy: 0.7701 - val_loss: 0.5971 - val_accuracy: 0.6887\n",
      "Epoch 22/200\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.4843 - accuracy: 0.7676 - val_loss: 0.5971 - val_accuracy: 0.6918\n",
      "Epoch 23/200\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.4833 - accuracy: 0.7671 - val_loss: 0.5970 - val_accuracy: 0.6871\n",
      "Epoch 24/200\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.4827 - accuracy: 0.7694 - val_loss: 0.5985 - val_accuracy: 0.6887\n",
      "20/20 [==============================] - 0s 4ms/step\n",
      "-----------------------------------------------test---------------------------------------\n",
      "Sn = 0.676101, Sp = 0.701258, Acc = 0.688679, MCC = 0.377478, AUC = 0.759335\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "tf.random.set_seed(1)  # for reproducibility\n",
    "# reading model\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 200\n",
    "\n",
    "# # Cross-validation\n",
    "n = 10\n",
    "k_fold = KFold(n_splits=n, shuffle=True, random_state=42)\n",
    "\n",
    "all_performance = []\n",
    "tprs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "for fold_count, (train_index, val_index) in enumerate(k_fold.split(train)):\n",
    "    print('*' * 30 + ' the ' + str(fold_count + 1) + ' fold ' + '*' * 30)\n",
    "    trains, val = train[train_index], train[val_index]\n",
    "    trains_label, val_label = train_label[train_index], train_label[val_index]\n",
    "    model.fit(x=trains, y=trains_label, validation_data=(val, val_label), epochs=EPOCHS,\n",
    "                batch_size=BATCH_SIZE, shuffle=True,\n",
    "                callbacks=[EarlyStopping(monitor='val_loss', patience=13, mode='auto')],\n",
    "                verbose=1)\n",
    "     # 保存模型\n",
    "\n",
    "    model.save('./models_duibi_CNN/model_fold' + str(fold_count+1) + '.h5')\n",
    "\n",
    "    del model\n",
    "\n",
    "    model = load_model('./models_duibi_CNN/model_fold' + str(fold_count+1) + '.h5')\n",
    "\n",
    "    val_pred = model.predict(val, verbose=1)\n",
    "\n",
    "    # Sn, Sp, Acc, MCC, AUC\n",
    "    Sn, Sp, Acc, MCC = show_performance(val_label[:, 1], val_pred[:, 1])\n",
    "    AUC = roc_auc_score(val_label[:, 1], val_pred[:, 1])\n",
    "    print('Sn = %f, Sp = %f, Acc = %f, MCC = %f, AUC = %f' % (Sn, Sp, Acc, MCC, AUC))\n",
    "\n",
    "    performance = [Sn, Sp, Acc, MCC, AUC]\n",
    "    all_performance.append(performance)\n",
    "    \n",
    "all_performance = np.array(all_performance)\n",
    "print('10 fold result:', all_performance)\n",
    "performance_mean = performance_mean(all_performance)\n",
    "\n",
    "model.fit(x=train, y=train_label, validation_data=(test, test_label), epochs=EPOCHS,\n",
    "                      batch_size=BATCH_SIZE, shuffle=True,\n",
    "                      callbacks=[EarlyStopping(monitor='val_loss', patience=20, mode='auto')],\n",
    "                      verbose=1)\n",
    "model.save('./models_duibi_CNN/model_test.h5')\n",
    "\n",
    "del model\n",
    "\n",
    "model = load_model('./models_duibi_CNN/model_test.h5')\n",
    "\n",
    "test_score = model.predict(test)\n",
    "\n",
    "\n",
    "# Sn, Sp, Acc, MCC, AUC\n",
    "Sn, Sp, Acc, MCC = show_performance(test_label[:,1], test_score[:,1])\n",
    "AUC = roc_auc_score(test_label[:,1], test_score[:,1])\n",
    "\n",
    "print('-----------------------------------------------test---------------------------------------')\n",
    "print('Sn = %f, Sp = %f, Acc = %f, MCC = %f, AUC = %f' % (Sn, Sp, Acc, MCC, AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db473950-99e3-40e2-84f8-98440d859ccf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************************CNN******************************\n",
      "(None, 15, 64)\n",
      "(None, 15, 32)\n",
      "****************************** the 1 fold ******************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 10:21:42.424058: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11123 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:65:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 10:21:44.983619: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8800\n",
      "2024-06-12 10:21:48.460856: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-12 10:21:48.463997: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:231] Falling back to the CUDA driver for PTX compilation; ptxas does not support CC 8.6\n",
      "2024-06-12 10:21:48.464029: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:234] Used ptxas at ptxas\n",
      "2024-06-12 10:21:48.464110: W tensorflow/compiler/xla/stream_executor/gpu/redzone_allocator.cc:318] UNIMPLEMENTED: ptxas ptxas too old. Falling back to the driver to compile.\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2024-06-12 10:21:48.916420: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-06-12 10:21:48.946203: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c705730aa0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-06-12 10:21:48.946225: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 3090, Compute Capability 8.6\n",
      "2024-06-12 10:21:48.967282: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-06-12 10:21:49.100523: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-12 10:21:49.139894: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2024-06-12 10:21:49.214015: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-12 10:21:49.463028: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-12 10:21:51.049783: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/162 [..............................] - ETA: 24:35 - loss: 0.6902 - accuracy: 0.5312"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 10:21:51.706229: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-12 10:21:51.805827: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9/162 [>.............................] - ETA: 5s - loss: 0.6931 - accuracy: 0.5069"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 10:21:51.947145: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 19/162 [==>...........................] - ETA: 4s - loss: 0.6928 - accuracy: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 10:21:52.373187: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n",
      "2024-06-12 10:21:52.542703: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 14s 32ms/step - loss: 0.6892 - accuracy: 0.5603 - val_loss: 0.6859 - val_accuracy: 0.5662\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.6772 - accuracy: 0.6026 - val_loss: 0.6690 - val_accuracy: 0.6481\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.6550 - accuracy: 0.6506 - val_loss: 0.6466 - val_accuracy: 0.6429\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.6299 - accuracy: 0.6574 - val_loss: 0.6226 - val_accuracy: 0.6655\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.6123 - accuracy: 0.6679 - val_loss: 0.6122 - val_accuracy: 0.6760\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.6025 - accuracy: 0.6749 - val_loss: 0.6115 - val_accuracy: 0.6725\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - ETA: 0s - loss: 0.5966 - accuracy: 0.6799"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 10:22:15.843425: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5966 - accuracy: 0.6799 - val_loss: 0.6013 - val_accuracy: 0.6829\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5927 - accuracy: 0.6853 - val_loss: 0.6063 - val_accuracy: 0.6812\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5896 - accuracy: 0.6886 - val_loss: 0.6033 - val_accuracy: 0.6847\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5865 - accuracy: 0.6890 - val_loss: 0.6059 - val_accuracy: 0.6829\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5841 - accuracy: 0.6908 - val_loss: 0.6014 - val_accuracy: 0.7038\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5809 - accuracy: 0.6929 - val_loss: 0.6063 - val_accuracy: 0.6777\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5795 - accuracy: 0.6941 - val_loss: 0.5963 - val_accuracy: 0.7056\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5775 - accuracy: 0.6933 - val_loss: 0.5932 - val_accuracy: 0.7056\n",
      "Epoch 15/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5750 - accuracy: 0.6995 - val_loss: 0.5927 - val_accuracy: 0.7021\n",
      "Epoch 16/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5733 - accuracy: 0.6958 - val_loss: 0.5882 - val_accuracy: 0.7108\n",
      "Epoch 17/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5716 - accuracy: 0.7014 - val_loss: 0.5944 - val_accuracy: 0.7056\n",
      "Epoch 18/200\n",
      "162/162 [==============================] - ETA: 0s - loss: 0.5697 - accuracy: 0.7032"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 10:22:50.711066: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5697 - accuracy: 0.7032 - val_loss: 0.5885 - val_accuracy: 0.7108\n",
      "Epoch 19/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5675 - accuracy: 0.7049 - val_loss: 0.5830 - val_accuracy: 0.7160\n",
      "Epoch 20/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5662 - accuracy: 0.7040 - val_loss: 0.5870 - val_accuracy: 0.7125\n",
      "Epoch 21/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5645 - accuracy: 0.7047 - val_loss: 0.5845 - val_accuracy: 0.7056\n",
      "Epoch 22/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5632 - accuracy: 0.7055 - val_loss: 0.5818 - val_accuracy: 0.7125\n",
      "Epoch 23/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5623 - accuracy: 0.7100 - val_loss: 0.5840 - val_accuracy: 0.7056\n",
      "Epoch 24/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5605 - accuracy: 0.7098 - val_loss: 0.5804 - val_accuracy: 0.7160\n",
      "Epoch 25/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5596 - accuracy: 0.7119 - val_loss: 0.5791 - val_accuracy: 0.7143\n",
      "Epoch 26/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5580 - accuracy: 0.7136 - val_loss: 0.5851 - val_accuracy: 0.7108\n",
      "Epoch 27/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5573 - accuracy: 0.7096 - val_loss: 0.5862 - val_accuracy: 0.7091\n",
      "Epoch 28/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5558 - accuracy: 0.7158 - val_loss: 0.5792 - val_accuracy: 0.7108\n",
      "Epoch 29/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5540 - accuracy: 0.7150 - val_loss: 0.5758 - val_accuracy: 0.7143\n",
      "Epoch 30/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5537 - accuracy: 0.7206 - val_loss: 0.5768 - val_accuracy: 0.7125\n",
      "Epoch 31/200\n",
      "162/162 [==============================] - 3s 17ms/step - loss: 0.5521 - accuracy: 0.7204 - val_loss: 0.5822 - val_accuracy: 0.7073\n",
      "Epoch 32/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5516 - accuracy: 0.7189 - val_loss: 0.5786 - val_accuracy: 0.7108\n",
      "Epoch 33/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5507 - accuracy: 0.7218 - val_loss: 0.5797 - val_accuracy: 0.7125\n",
      "Epoch 34/200\n",
      "162/162 [==============================] - ETA: 0s - loss: 0.5499 - accuracy: 0.7228"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 10:23:41.258136: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5499 - accuracy: 0.7228 - val_loss: 0.5744 - val_accuracy: 0.7160\n",
      "Epoch 35/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5487 - accuracy: 0.7228 - val_loss: 0.5712 - val_accuracy: 0.7213\n",
      "Epoch 36/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5481 - accuracy: 0.7228 - val_loss: 0.5726 - val_accuracy: 0.7143\n",
      "Epoch 37/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5467 - accuracy: 0.7247 - val_loss: 0.5738 - val_accuracy: 0.7230\n",
      "Epoch 38/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5465 - accuracy: 0.7233 - val_loss: 0.5749 - val_accuracy: 0.7230\n",
      "Epoch 39/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5457 - accuracy: 0.7247 - val_loss: 0.5727 - val_accuracy: 0.7213\n",
      "Epoch 40/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5445 - accuracy: 0.7237 - val_loss: 0.5688 - val_accuracy: 0.7247\n",
      "Epoch 41/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5440 - accuracy: 0.7282 - val_loss: 0.5680 - val_accuracy: 0.7247\n",
      "Epoch 42/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5429 - accuracy: 0.7263 - val_loss: 0.5689 - val_accuracy: 0.7265\n",
      "Epoch 43/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5427 - accuracy: 0.7257 - val_loss: 0.5701 - val_accuracy: 0.7213\n",
      "Epoch 44/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5418 - accuracy: 0.7307 - val_loss: 0.5772 - val_accuracy: 0.7160\n",
      "Epoch 45/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5412 - accuracy: 0.7299 - val_loss: 0.5776 - val_accuracy: 0.7125\n",
      "Epoch 46/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5407 - accuracy: 0.7299 - val_loss: 0.5777 - val_accuracy: 0.7108\n",
      "Epoch 47/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5396 - accuracy: 0.7276 - val_loss: 0.5724 - val_accuracy: 0.7178\n",
      "Epoch 48/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5397 - accuracy: 0.7295 - val_loss: 0.5683 - val_accuracy: 0.7230\n",
      "Epoch 49/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5384 - accuracy: 0.7303 - val_loss: 0.5661 - val_accuracy: 0.7300\n",
      "Epoch 50/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5380 - accuracy: 0.7307 - val_loss: 0.5634 - val_accuracy: 0.7334\n",
      "Epoch 51/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5375 - accuracy: 0.7336 - val_loss: 0.5733 - val_accuracy: 0.7125\n",
      "Epoch 52/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5369 - accuracy: 0.7313 - val_loss: 0.5679 - val_accuracy: 0.7230\n",
      "Epoch 53/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5364 - accuracy: 0.7305 - val_loss: 0.5629 - val_accuracy: 0.7369\n",
      "Epoch 54/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5359 - accuracy: 0.7319 - val_loss: 0.5747 - val_accuracy: 0.7143\n",
      "Epoch 55/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5350 - accuracy: 0.7313 - val_loss: 0.5748 - val_accuracy: 0.7143\n",
      "Epoch 56/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5348 - accuracy: 0.7330 - val_loss: 0.5703 - val_accuracy: 0.7213\n",
      "Epoch 57/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5342 - accuracy: 0.7352 - val_loss: 0.5657 - val_accuracy: 0.7265\n",
      "Epoch 58/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5339 - accuracy: 0.7305 - val_loss: 0.5789 - val_accuracy: 0.7108\n",
      "Epoch 59/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5330 - accuracy: 0.7352 - val_loss: 0.5728 - val_accuracy: 0.7195\n",
      "Epoch 60/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5318 - accuracy: 0.7336 - val_loss: 0.5647 - val_accuracy: 0.7247\n",
      "Epoch 61/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5318 - accuracy: 0.7344 - val_loss: 0.5703 - val_accuracy: 0.7213\n",
      "Epoch 62/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5329 - accuracy: 0.7326 - val_loss: 0.5689 - val_accuracy: 0.7230\n",
      "Epoch 63/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5317 - accuracy: 0.7361 - val_loss: 0.5679 - val_accuracy: 0.7213\n",
      "Epoch 64/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5309 - accuracy: 0.7330 - val_loss: 0.5678 - val_accuracy: 0.7230\n",
      "Epoch 65/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5301 - accuracy: 0.7332 - val_loss: 0.5640 - val_accuracy: 0.7265\n",
      "Epoch 66/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5297 - accuracy: 0.7363 - val_loss: 0.5746 - val_accuracy: 0.7178\n",
      "18/18 [==============================] - 0s 4ms/step\n",
      "Sn = 0.667732, Sp = 0.777778, Acc = 0.717770, MCC = 0.444759, AUC = 0.790802\n",
      "****************************** the 2 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 0.5299 - accuracy: 0.7398 - val_loss: 0.5625 - val_accuracy: 0.7056\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5292 - accuracy: 0.7375 - val_loss: 0.5654 - val_accuracy: 0.7003\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5286 - accuracy: 0.7383 - val_loss: 0.5647 - val_accuracy: 0.7125\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5278 - accuracy: 0.7390 - val_loss: 0.5685 - val_accuracy: 0.6934\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5270 - accuracy: 0.7389 - val_loss: 0.5668 - val_accuracy: 0.7056\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5273 - accuracy: 0.7389 - val_loss: 0.5668 - val_accuracy: 0.7073\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5262 - accuracy: 0.7387 - val_loss: 0.5707 - val_accuracy: 0.6986\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5258 - accuracy: 0.7406 - val_loss: 0.5682 - val_accuracy: 0.7108\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5260 - accuracy: 0.7367 - val_loss: 0.5706 - val_accuracy: 0.6969\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5255 - accuracy: 0.7371 - val_loss: 0.5704 - val_accuracy: 0.6986\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5256 - accuracy: 0.7412 - val_loss: 0.5698 - val_accuracy: 0.7108\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5237 - accuracy: 0.7414 - val_loss: 0.5704 - val_accuracy: 0.7125\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5242 - accuracy: 0.7385 - val_loss: 0.5705 - val_accuracy: 0.7056\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5234 - accuracy: 0.7421 - val_loss: 0.5711 - val_accuracy: 0.7091\n",
      "18/18 [==============================] - 0s 4ms/step\n",
      "Sn = 0.715789, Sp = 0.702422, Acc = 0.709059, MCC = 0.418224, AUC = 0.772865\n",
      "****************************** the 3 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 6s 30ms/step - loss: 0.5282 - accuracy: 0.7368 - val_loss: 0.5302 - val_accuracy: 0.7312\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5275 - accuracy: 0.7385 - val_loss: 0.5321 - val_accuracy: 0.7417\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5265 - accuracy: 0.7375 - val_loss: 0.5321 - val_accuracy: 0.7312\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5263 - accuracy: 0.7389 - val_loss: 0.5329 - val_accuracy: 0.7277\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5256 - accuracy: 0.7389 - val_loss: 0.5339 - val_accuracy: 0.7295\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5253 - accuracy: 0.7416 - val_loss: 0.5380 - val_accuracy: 0.7330\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5244 - accuracy: 0.7426 - val_loss: 0.5354 - val_accuracy: 0.7312\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5246 - accuracy: 0.7434 - val_loss: 0.5362 - val_accuracy: 0.7277\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5244 - accuracy: 0.7410 - val_loss: 0.5363 - val_accuracy: 0.7225\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5233 - accuracy: 0.7428 - val_loss: 0.5366 - val_accuracy: 0.7225\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 3s 17ms/step - loss: 0.5230 - accuracy: 0.7439 - val_loss: 0.5372 - val_accuracy: 0.7173\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5220 - accuracy: 0.7414 - val_loss: 0.5396 - val_accuracy: 0.7312\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5219 - accuracy: 0.7447 - val_loss: 0.5383 - val_accuracy: 0.7277\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5214 - accuracy: 0.7439 - val_loss: 0.5388 - val_accuracy: 0.7243\n",
      "18/18 [==============================] - 0s 5ms/step\n",
      "Sn = 0.778157, Sp = 0.667857, Acc = 0.724258, MCC = 0.449168, AUC = 0.803510\n",
      "****************************** the 4 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 5s 22ms/step - loss: 0.5261 - accuracy: 0.7393 - val_loss: 0.4906 - val_accuracy: 0.7696\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5272 - accuracy: 0.7368 - val_loss: 0.4964 - val_accuracy: 0.7679\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5259 - accuracy: 0.7374 - val_loss: 0.4964 - val_accuracy: 0.7714\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5255 - accuracy: 0.7387 - val_loss: 0.4921 - val_accuracy: 0.7766\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5249 - accuracy: 0.7403 - val_loss: 0.4952 - val_accuracy: 0.7679\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5246 - accuracy: 0.7387 - val_loss: 0.5015 - val_accuracy: 0.7661\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5242 - accuracy: 0.7401 - val_loss: 0.5011 - val_accuracy: 0.7661\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5239 - accuracy: 0.7387 - val_loss: 0.5015 - val_accuracy: 0.7696\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5239 - accuracy: 0.7420 - val_loss: 0.4968 - val_accuracy: 0.7714\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5234 - accuracy: 0.7395 - val_loss: 0.4971 - val_accuracy: 0.7714\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5234 - accuracy: 0.7424 - val_loss: 0.4978 - val_accuracy: 0.7696\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5218 - accuracy: 0.7451 - val_loss: 0.5042 - val_accuracy: 0.7644\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5220 - accuracy: 0.7401 - val_loss: 0.5028 - val_accuracy: 0.7592\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5210 - accuracy: 0.7422 - val_loss: 0.4995 - val_accuracy: 0.7696\n",
      "18/18 [==============================] - 0s 5ms/step\n",
      "Sn = 0.748252, Sp = 0.790941, Acc = 0.769634, MCC = 0.539706, AUC = 0.841317\n",
      "****************************** the 5 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 4s 21ms/step - loss: 0.5206 - accuracy: 0.7455 - val_loss: 0.5038 - val_accuracy: 0.7469\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5203 - accuracy: 0.7457 - val_loss: 0.5034 - val_accuracy: 0.7539\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5197 - accuracy: 0.7467 - val_loss: 0.5064 - val_accuracy: 0.7469\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5190 - accuracy: 0.7457 - val_loss: 0.5105 - val_accuracy: 0.7522\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5192 - accuracy: 0.7467 - val_loss: 0.5075 - val_accuracy: 0.7452\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5186 - accuracy: 0.7465 - val_loss: 0.5082 - val_accuracy: 0.7435\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5181 - accuracy: 0.7476 - val_loss: 0.5110 - val_accuracy: 0.7452\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5176 - accuracy: 0.7482 - val_loss: 0.5106 - val_accuracy: 0.7522\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5170 - accuracy: 0.7498 - val_loss: 0.5118 - val_accuracy: 0.7469\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5166 - accuracy: 0.7492 - val_loss: 0.5170 - val_accuracy: 0.7452\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5174 - accuracy: 0.7455 - val_loss: 0.5133 - val_accuracy: 0.7504\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5154 - accuracy: 0.7478 - val_loss: 0.5136 - val_accuracy: 0.7487\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5159 - accuracy: 0.7492 - val_loss: 0.5142 - val_accuracy: 0.7487\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5152 - accuracy: 0.7474 - val_loss: 0.5224 - val_accuracy: 0.7382\n",
      "Epoch 15/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5145 - accuracy: 0.7482 - val_loss: 0.5291 - val_accuracy: 0.7365\n",
      "18/18 [==============================] - 0s 5ms/step\n",
      "Sn = 0.841549, Sp = 0.633218, Acc = 0.736475, MCC = 0.484967, AUC = 0.821446\n",
      "****************************** the 6 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 4s 23ms/step - loss: 0.5144 - accuracy: 0.7500 - val_loss: 0.5140 - val_accuracy: 0.7574\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5149 - accuracy: 0.7490 - val_loss: 0.5177 - val_accuracy: 0.7504\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5138 - accuracy: 0.7476 - val_loss: 0.5181 - val_accuracy: 0.7557\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5132 - accuracy: 0.7505 - val_loss: 0.5201 - val_accuracy: 0.7592\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5126 - accuracy: 0.7484 - val_loss: 0.5227 - val_accuracy: 0.7469\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5127 - accuracy: 0.7517 - val_loss: 0.5232 - val_accuracy: 0.7469\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5112 - accuracy: 0.7474 - val_loss: 0.5235 - val_accuracy: 0.7504\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5117 - accuracy: 0.7515 - val_loss: 0.5246 - val_accuracy: 0.7574\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5113 - accuracy: 0.7511 - val_loss: 0.5255 - val_accuracy: 0.7557\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5101 - accuracy: 0.7501 - val_loss: 0.5264 - val_accuracy: 0.7504\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5108 - accuracy: 0.7501 - val_loss: 0.5269 - val_accuracy: 0.7539\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5098 - accuracy: 0.7503 - val_loss: 0.5278 - val_accuracy: 0.7539\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5096 - accuracy: 0.7511 - val_loss: 0.5289 - val_accuracy: 0.7417\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5087 - accuracy: 0.7540 - val_loss: 0.5309 - val_accuracy: 0.7417\n",
      "18/18 [==============================] - 0s 5ms/step\n",
      "Sn = 0.801394, Sp = 0.681818, Acc = 0.741710, MCC = 0.486753, AUC = 0.812870\n",
      "****************************** the 7 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 5s 24ms/step - loss: 0.5156 - accuracy: 0.7531 - val_loss: 0.4697 - val_accuracy: 0.7487\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5154 - accuracy: 0.7507 - val_loss: 0.4726 - val_accuracy: 0.7435\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5140 - accuracy: 0.7538 - val_loss: 0.4725 - val_accuracy: 0.7574\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5144 - accuracy: 0.7532 - val_loss: 0.4739 - val_accuracy: 0.7609\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5130 - accuracy: 0.7540 - val_loss: 0.4761 - val_accuracy: 0.7417\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5135 - accuracy: 0.7525 - val_loss: 0.4770 - val_accuracy: 0.7469\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5123 - accuracy: 0.7544 - val_loss: 0.4770 - val_accuracy: 0.7574\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5124 - accuracy: 0.7494 - val_loss: 0.4780 - val_accuracy: 0.7574\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5126 - accuracy: 0.7513 - val_loss: 0.4785 - val_accuracy: 0.7592\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5111 - accuracy: 0.7548 - val_loss: 0.4793 - val_accuracy: 0.7574\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5113 - accuracy: 0.7525 - val_loss: 0.4802 - val_accuracy: 0.7557\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 3s 17ms/step - loss: 0.5104 - accuracy: 0.7542 - val_loss: 0.4810 - val_accuracy: 0.7469\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5105 - accuracy: 0.7513 - val_loss: 0.4814 - val_accuracy: 0.7522\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5102 - accuracy: 0.7532 - val_loss: 0.4828 - val_accuracy: 0.7522\n",
      "18/18 [==============================] - 0s 5ms/step\n",
      "Sn = 0.777778, Sp = 0.727891, Acc = 0.752182, MCC = 0.505835, AUC = 0.846829\n",
      "****************************** the 8 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 0.5068 - accuracy: 0.7567 - val_loss: 0.5092 - val_accuracy: 0.7400\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5064 - accuracy: 0.7556 - val_loss: 0.5123 - val_accuracy: 0.7400\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5057 - accuracy: 0.7563 - val_loss: 0.5134 - val_accuracy: 0.7347\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 3s 21ms/step - loss: 0.5048 - accuracy: 0.7569 - val_loss: 0.5162 - val_accuracy: 0.7435\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5050 - accuracy: 0.7552 - val_loss: 0.5173 - val_accuracy: 0.7295\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5045 - accuracy: 0.7581 - val_loss: 0.5191 - val_accuracy: 0.7312\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5035 - accuracy: 0.7604 - val_loss: 0.5190 - val_accuracy: 0.7277\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5045 - accuracy: 0.7585 - val_loss: 0.5190 - val_accuracy: 0.7347\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5035 - accuracy: 0.7577 - val_loss: 0.5199 - val_accuracy: 0.7330\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5028 - accuracy: 0.7573 - val_loss: 0.5211 - val_accuracy: 0.7312\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5028 - accuracy: 0.7587 - val_loss: 0.5219 - val_accuracy: 0.7312\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5015 - accuracy: 0.7596 - val_loss: 0.5237 - val_accuracy: 0.7243\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5019 - accuracy: 0.7587 - val_loss: 0.5236 - val_accuracy: 0.7260\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5010 - accuracy: 0.7594 - val_loss: 0.5244 - val_accuracy: 0.7365\n",
      "18/18 [==============================] - 0s 4ms/step\n",
      "Sn = 0.789831, Sp = 0.679856, Acc = 0.736475, MCC = 0.473126, AUC = 0.813498\n",
      "****************************** the 9 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 0.5013 - accuracy: 0.7567 - val_loss: 0.5253 - val_accuracy: 0.7504\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.5001 - accuracy: 0.7558 - val_loss: 0.5259 - val_accuracy: 0.7522\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.4998 - accuracy: 0.7540 - val_loss: 0.5273 - val_accuracy: 0.7469\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.4992 - accuracy: 0.7569 - val_loss: 0.5320 - val_accuracy: 0.7487\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.4989 - accuracy: 0.7571 - val_loss: 0.5312 - val_accuracy: 0.7417\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.4983 - accuracy: 0.7587 - val_loss: 0.5324 - val_accuracy: 0.7504\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.4979 - accuracy: 0.7598 - val_loss: 0.5393 - val_accuracy: 0.7295\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.4984 - accuracy: 0.7546 - val_loss: 0.5352 - val_accuracy: 0.7469\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.4980 - accuracy: 0.7583 - val_loss: 0.5382 - val_accuracy: 0.7487\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.4977 - accuracy: 0.7587 - val_loss: 0.5404 - val_accuracy: 0.7400\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.4973 - accuracy: 0.7585 - val_loss: 0.5400 - val_accuracy: 0.7400\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.4961 - accuracy: 0.7606 - val_loss: 0.5385 - val_accuracy: 0.7417\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.4965 - accuracy: 0.7579 - val_loss: 0.5403 - val_accuracy: 0.7417\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.4952 - accuracy: 0.7606 - val_loss: 0.5541 - val_accuracy: 0.7190\n",
      "18/18 [==============================] - 0s 4ms/step\n",
      "Sn = 0.815217, Sp = 0.629630, Acc = 0.719023, MCC = 0.451058, AUC = 0.804702\n",
      "****************************** the 10 fold ******************************\n",
      "Epoch 1/200\n",
      "162/162 [==============================] - 4s 22ms/step - loss: 0.5003 - accuracy: 0.7567 - val_loss: 0.4959 - val_accuracy: 0.7627\n",
      "Epoch 2/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.5003 - accuracy: 0.7560 - val_loss: 0.4987 - val_accuracy: 0.7557\n",
      "Epoch 3/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.4991 - accuracy: 0.7575 - val_loss: 0.5007 - val_accuracy: 0.7574\n",
      "Epoch 4/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.4989 - accuracy: 0.7600 - val_loss: 0.5067 - val_accuracy: 0.7592\n",
      "Epoch 5/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.4984 - accuracy: 0.7587 - val_loss: 0.5044 - val_accuracy: 0.7592\n",
      "Epoch 6/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.4992 - accuracy: 0.7575 - val_loss: 0.5064 - val_accuracy: 0.7574\n",
      "Epoch 7/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.4978 - accuracy: 0.7567 - val_loss: 0.5122 - val_accuracy: 0.7574\n",
      "Epoch 8/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.4980 - accuracy: 0.7587 - val_loss: 0.5087 - val_accuracy: 0.7522\n",
      "Epoch 9/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.4974 - accuracy: 0.7583 - val_loss: 0.5103 - val_accuracy: 0.7574\n",
      "Epoch 10/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.4964 - accuracy: 0.7600 - val_loss: 0.5101 - val_accuracy: 0.7592\n",
      "Epoch 11/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.4970 - accuracy: 0.7593 - val_loss: 0.5124 - val_accuracy: 0.7592\n",
      "Epoch 12/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.4957 - accuracy: 0.7614 - val_loss: 0.5114 - val_accuracy: 0.7557\n",
      "Epoch 13/200\n",
      "162/162 [==============================] - 3s 19ms/step - loss: 0.4961 - accuracy: 0.7618 - val_loss: 0.5125 - val_accuracy: 0.7539\n",
      "Epoch 14/200\n",
      "162/162 [==============================] - 3s 20ms/step - loss: 0.4951 - accuracy: 0.7616 - val_loss: 0.5175 - val_accuracy: 0.7487\n",
      "18/18 [==============================] - 0s 5ms/step\n",
      "Sn = 0.783582, Sp = 0.718033, Acc = 0.748691, MCC = 0.500843, AUC = 0.825202\n",
      "10 fold result: [[0.66773163 0.77777777 0.71777003 0.44475873 0.79080215]\n",
      " [0.71578947 0.70242214 0.70905923 0.41822431 0.77286469]\n",
      " [0.77815699 0.66785714 0.72425829 0.44916785 0.80351048]\n",
      " [0.74825175 0.79094076 0.76963351 0.53970562 0.84131722]\n",
      " [0.84154929 0.63321799 0.73647469 0.48496669 0.82144598]\n",
      " [0.80139373 0.68181818 0.7417103  0.48675319 0.81287006]\n",
      " [0.77777777 0.72789115 0.7521815  0.50583546 0.84682905]\n",
      " [0.78983051 0.67985611 0.73647469 0.47312599 0.81349835]\n",
      " [0.81521739 0.62962963 0.71902269 0.45105819 0.80470161]\n",
      " [0.78358209 0.71803278 0.7486911  0.50084343 0.82520186]]\n",
      "Sn = 0.7719 ± 0.0476\n",
      "Sp = 0.7009 ± 0.0516\n",
      "Acc = 0.7355 ± 0.0175\n",
      "Mcc = 0.4754 ± 0.0338\n",
      "Auc = 0.8133 ± 0.0210\n",
      "Epoch 1/200\n",
      "180/180 [==============================] - 6s 29ms/step - loss: 0.4980 - accuracy: 0.7610 - val_loss: 0.5835 - val_accuracy: 0.6777\n",
      "Epoch 2/200\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.4966 - accuracy: 0.7589"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-12 10:32:34.217034: E tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:114] *** WARNING *** You are using ptxas 9.1.108, which is older than 11.1. ptxas before 11.1 is known to miscompile XLA code, leading to incorrect results or invalid-address errors.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 4s 20ms/step - loss: 0.4966 - accuracy: 0.7589 - val_loss: 0.5841 - val_accuracy: 0.6792\n",
      "Epoch 3/200\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.4956 - accuracy: 0.7610 - val_loss: 0.5855 - val_accuracy: 0.6840\n",
      "Epoch 4/200\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.4961 - accuracy: 0.7643 - val_loss: 0.5830 - val_accuracy: 0.6808\n",
      "Epoch 5/200\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.4964 - accuracy: 0.7606 - val_loss: 0.5830 - val_accuracy: 0.6777\n",
      "Epoch 6/200\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.4958 - accuracy: 0.7592 - val_loss: 0.5861 - val_accuracy: 0.6871\n",
      "Epoch 7/200\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.4956 - accuracy: 0.7608 - val_loss: 0.5844 - val_accuracy: 0.6855\n",
      "Epoch 8/200\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.4953 - accuracy: 0.7622 - val_loss: 0.5844 - val_accuracy: 0.6855\n",
      "Epoch 9/200\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.4946 - accuracy: 0.7594 - val_loss: 0.5863 - val_accuracy: 0.6855\n",
      "Epoch 10/200\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.4949 - accuracy: 0.7615 - val_loss: 0.5881 - val_accuracy: 0.6808\n",
      "Epoch 11/200\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.4933 - accuracy: 0.7608 - val_loss: 0.5859 - val_accuracy: 0.6808\n",
      "Epoch 12/200\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.4931 - accuracy: 0.7638 - val_loss: 0.5845 - val_accuracy: 0.6792\n",
      "Epoch 13/200\n",
      "180/180 [==============================] - 3s 17ms/step - loss: 0.4929 - accuracy: 0.7626 - val_loss: 0.5863 - val_accuracy: 0.6824\n",
      "Epoch 14/200\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.4929 - accuracy: 0.7613 - val_loss: 0.5860 - val_accuracy: 0.6824\n",
      "Epoch 15/200\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.4932 - accuracy: 0.7659 - val_loss: 0.5865 - val_accuracy: 0.6840\n",
      "Epoch 16/200\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.4935 - accuracy: 0.7624 - val_loss: 0.5877 - val_accuracy: 0.6840\n",
      "Epoch 17/200\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.4925 - accuracy: 0.7641 - val_loss: 0.5865 - val_accuracy: 0.6792\n",
      "Epoch 18/200\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.4923 - accuracy: 0.7613 - val_loss: 0.5908 - val_accuracy: 0.6808\n",
      "Epoch 19/200\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.4923 - accuracy: 0.7617 - val_loss: 0.5891 - val_accuracy: 0.6808\n",
      "Epoch 20/200\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.4917 - accuracy: 0.7624 - val_loss: 0.5876 - val_accuracy: 0.6840\n",
      "Epoch 21/200\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.4917 - accuracy: 0.7638 - val_loss: 0.5861 - val_accuracy: 0.6840\n",
      "Epoch 22/200\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.4921 - accuracy: 0.7610 - val_loss: 0.5868 - val_accuracy: 0.6855\n",
      "Epoch 23/200\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.4914 - accuracy: 0.7627 - val_loss: 0.5855 - val_accuracy: 0.6792\n",
      "Epoch 24/200\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.4908 - accuracy: 0.7648 - val_loss: 0.5870 - val_accuracy: 0.6855\n",
      "20/20 [==============================] - 0s 5ms/step\n",
      "-----------------------------------------------test---------------------------------------\n",
      "Sn = 0.660377, Sp = 0.710692, Acc = 0.685535, MCC = 0.371540, AUC = 0.767246\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "tf.random.set_seed(1)  # for reproducibility\n",
    "# reading model\n",
    "\n",
    "model = build_model()\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 200\n",
    "\n",
    "# # Cross-validation\n",
    "n = 10\n",
    "k_fold = KFold(n_splits=n, shuffle=True, random_state=42)\n",
    "\n",
    "all_performance = []\n",
    "tprs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "for fold_count, (train_index, val_index) in enumerate(k_fold.split(train)):\n",
    "    print('*' * 30 + ' the ' + str(fold_count + 1) + ' fold ' + '*' * 30)\n",
    "    trains, val = train[train_index], train[val_index]\n",
    "    trains_label, val_label = train_label[train_index], train_label[val_index]\n",
    "    model.fit(x=trains, y=trains_label, validation_data=(val, val_label), epochs=EPOCHS,\n",
    "                batch_size=BATCH_SIZE, shuffle=True,\n",
    "                callbacks=[EarlyStopping(monitor='val_loss', patience=13, mode='auto')],\n",
    "                verbose=1)\n",
    "     # 保存模型\n",
    "\n",
    "    model.save('./models_duibi_CNN/model_fold' + str(fold_count+1) + '.h5')\n",
    "\n",
    "    del model\n",
    "\n",
    "    model = load_model('./models_duibi_CNN/model_fold' + str(fold_count+1) + '.h5')\n",
    "\n",
    "    val_pred = model.predict(val, verbose=1)\n",
    "\n",
    "    # Sn, Sp, Acc, MCC, AUC\n",
    "    Sn, Sp, Acc, MCC = show_performance(val_label[:, 1], val_pred[:, 1])\n",
    "    AUC = roc_auc_score(val_label[:, 1], val_pred[:, 1])\n",
    "    print('Sn = %f, Sp = %f, Acc = %f, MCC = %f, AUC = %f' % (Sn, Sp, Acc, MCC, AUC))\n",
    "\n",
    "    performance = [Sn, Sp, Acc, MCC, AUC]\n",
    "    all_performance.append(performance)\n",
    "    \n",
    "all_performance = np.array(all_performance)\n",
    "print('10 fold result:', all_performance)\n",
    "performance_mean = performance_mean(all_performance)\n",
    "\n",
    "model.fit(x=train, y=train_label, validation_data=(test, test_label), epochs=EPOCHS,\n",
    "                      batch_size=BATCH_SIZE, shuffle=True,\n",
    "                      callbacks=[EarlyStopping(monitor='val_loss', patience=20, mode='auto')],\n",
    "                      verbose=1)\n",
    "model.save('./models_duibi_CNN/model_test.h5')\n",
    "\n",
    "del model\n",
    "\n",
    "model = load_model('./models_duibi_CNN/model_test.h5')\n",
    "\n",
    "test_score = model.predict(test)\n",
    "pd.DataFrame(test_score).to_csv('./models_duibi_CNN/test_label_pred.csv', index=False)\n",
    "\n",
    "# Sn, Sp, Acc, MCC, AUC\n",
    "Sn, Sp, Acc, MCC = show_performance(test_label[:,1], test_score[:,1])\n",
    "AUC = roc_auc_score(test_label[:,1], test_score[:,1])\n",
    "\n",
    "print('-----------------------------------------------test---------------------------------------')\n",
    "print('Sn = %f, Sp = %f, Acc = %f, MCC = %f, AUC = %f' % (Sn, Sp, Acc, MCC, AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f8b9229-43e2-4016-bd5f-b88182bf0e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'true_label': test_label[:,1],\n",
    "    'predicted_probability': test_score[:, 1]  # 提取正类的预测概率\n",
    "})\n",
    "df.to_csv('./models_duibi_CNN/predictions_with_probabilities_cnn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f6edde8-28b8-4b81-ab1b-9173868b686b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "729c5868-5c84-42a0-a8a6-23198c163263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算ROC曲线的TPR和FPR\n",
    "fpr, tpr, thresholds = roc_curve(val_label[:, 1], val_pred[:, 1])\n",
    "roc_auc = auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00dd6933-8662-43d2-8a93-084fda7c0cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算PR曲线的precision和recall\n",
    "precision, recall, _ = precision_recall_curve(val_label[:, 1], val_pred[:, 1])\n",
    "pr_auc = average_precision_score(val_label[:, 1], val_pred[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b108feae-f639-42ab-a9cc-6b18663e05fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_data = []\n",
    "pr_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c59a7351-b149-4566-a525-c8a111b047c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存ROC和PR数据\n",
    "roc_data.append({'fpr': fpr, 'tpr': tpr, 'auc': roc_auc})\n",
    "pr_data.append({'precision': precision, 'recall': recall, 'auc': pr_auc})\n",
    "    \n",
    "# 保存预测分数到CSV文件（可选，每折一个文件）\n",
    "df_scores = pd.DataFrame({\n",
    "    'True_Label': val_label[:, 1],\n",
    "    'Prediction_Score':  val_pred[:, 1]\n",
    "})\n",
    "df_scores.to_csv(f'./models_duibi_CNN/prediction_scores_fold_{fold_count+1}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593095e8-d0e7-43de-b7c3-5f024adb59a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算平均ROC和PR曲线\n",
    "mean_tpr = np.mean([data['tpr'] for data in roc_data], axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(np.mean([data['fpr'] for data in roc_data], axis=0), mean_tpr)\n",
    "std_auc = np.std([data['auc'] for data in roc_data])\n",
    "\n",
    "mean_precision = np.mean([data['precision'] for data in pr_data], axis=0)\n",
    "mean_recall = np.mean([data['recall'] for data in pr_data], axis=0)\n",
    "mean_ap = np.mean([data['auc'] for data in pr_data])\n",
    "std_ap = np.std([data['auc'] for data in pr_data])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
